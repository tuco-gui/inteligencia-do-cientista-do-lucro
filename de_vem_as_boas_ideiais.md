De onde vêm as boas ideias
Tradução:
Maria Luiza X. de A. Borges

DADOS DE COPYRIGHT
Sobre a obra:
A presente obra é disponibilizada pela equipe Le Livros e seus diversos parceiros, com o
objetivo de oferecer conteúdo para uso parcial em pesquisas e estudos acadêmicos, bem como
o simples teste da qualidade da obra, com o fim exclusivo de compra futura.
É expressamente proibida e totalmente repudíavel a venda, aluguel, ou quaisquer uso
comercial do presente conteúdo
Sobre nós:
O Le Livros e seus parceiros disponibilizam conteúdo de dominio publico e propriedade
intelectual de forma totalmente gratuita, por acreditar que o conhecimento e a educação devem
ser acessíveis e livres a toda e qualquer pessoa. Você pode encontrar mais obras em nosso
site: LeLivros.link ou em qualquer um dos sites parceiros apresentados neste link.
"Quando o mundo estiver unido na busca do conhecimento, e não mais lutando por
dinheiro e poder, então nossa sociedade poderá enfim evoluir a um novo nível."
Para Peter

Sumário
Introdução Recife, cidade, web
1. O possível adjacente
2. Redes líquidas
3. A intuição lenta
4. Serendipidade
5. Erro
6. Exaptação
7. Plataformas
Conclusão: O quarto quadrante
Apêndice
Notas e leitura adicional
Bibliografia
Agradecimentos
Índice remissivo
Introdução
Recife, cidade, web
... E enquanto o seu imaginar concebe
Formas desconhecidas, sua pena
Dá-lhes corpo e, ao ar inconsistente,
Dá local de morada e até um nome.
SHAKESPEARE, Sonho de uma noite de verão, V.1.14-17a
O paradoxo de Darwin
4 de abril de 1836. Em toda a extensão oriental do oceano Índico, os confiáveis ventos
nordeste da estação das monções começaram a dar lugar aos dias serenos de verão. Nas ilhas
Cocos, dois pequenos atóis compostos de 27 ilhas de coral quase mil quilômetros a leste da
Sumatra, as águas cor de esmeralda estão convidativamente plácidas e mornas, seu tom
realçado pela areia branca e brilhante de coral desintegrado. Num trecho de litoral em geral
protegido por uma arrebentação mais forte, a água está tão calma que Charles Darwin avança,
sob o vasto céu azul dos trópicos, até a borda do recife de coral vivo ao redor da ilha.
Passa horas parado ou remando em meio à magnificência do recife. Com 27 anos de idade,
a mais de 11 mil quilômetros de Londres, Darwin está à beira de um precipício, postado sobre
um pico submerso que se eleva através de um mar insondável. Está também à beira de uma
ideia sobre as forças que formaram aquele pico, uma ideia que se provaria a primeira grande
descoberta científica de sua carreira. E acaba de começar a explorar uma outra intuição, ainda
nebulosa e informe, que acabará conduzindo ao cume intelectual do século XIX.
À sua volta, as multidões do ecossistema do coral se agitam e tremeluzem. A simples
variedade fascina: peixe-borboleta, peixe-donzela, peixe-papagaio, peixe-napoleão, peixe-
anjo; anthias-dourado alimentando-se de plâncton sobre as couves-flores desabrochadas do
coral; os espigões e tentáculos dos ouriços-do-mar e das anêmonas. O espetáculo encanta os
olhos de Darwin, mas sua mente já divisa, por trás do esplendor superficial, um mistério mais
profundo. Em seu relato da viagem a bordo do Beagle, publicado quatro anos depois, ele
escreveria: “É desculpável encher-se de entusiasmo diante dos números infinitos de seres
orgânicos de que os mares dos trópicos, tão pródigos de vida, pululam; devo confessar,
contudo, que aqueles naturalistas que descreveram, em palavras muito conhecidas, as grutas
submarinas adornadas com milhares de belezas parecem ter se entregado a uma linguagem um
tanto exuberante.”
O que permanece no fundo de sua memória, nos dias e nas semanas que se seguem, não é a
beleza da gruta submarina, mas o “número infinito” de seres orgânicos. Em terra, a flora e a
fauna das ilhas Cocos são, na melhor das hipóteses, mesquinhas. Entre as plantas, há pouco
além de coqueiros, liquens e ervas daninhas. “A lista dos animais terrestres”, escreve ele, “é
ainda mais pobre que a das plantas”: um punhado de lagartos, quase nenhuma verdadeira ave
terrestre e aqueles imigrantes recentes de navios europeus, os ratos. “A ilha não tem nenhum
quadrúpede doméstico exceto o porco”, Darwin registra com desdém.
No entanto, a poucos passos desse habitat desolado, nas águas do recife de coral, floresce
uma diversidade épica que só encontra rival nas florestas úmidas. Isso é um verdadeiro
mistério. Por que deveriam as águas à beira de um atol sustentar tantas formas de vida? Se
extrairmos trezentos metros cúbicos de água de praticamente qualquer lugar do oceano Índico
e fizermos um inventário completo da vida que encontramos ali, a lista será quase tão pobre
quanto a enumeração dos animais terrestres das ilhas Cocos. Com sorte, poderíamos encontrar
uma dúzia de peixes. Já no recife com certeza encontraríamos pelo menos mil. Nas palavras
do próprio Darwin, topar com o ecossistema de um recife de coral no meio do oceano era
como encontrar um oásis fervilhante de vida no meio de um deserto. Hoje chamamos esse
fenômeno de “paradoxo de Darwin”: tantas formas de vida diferentes, ocupando uma série tão
vasta de nichos ecológicos, habitando águas que de outro modo seriam extremamente pobres
em nutrientes. Embora os recifes de coral constituam cerca de um décimo de 1% da superfície
da Terra, é neles que vive cerca de um quarto das espécies conhecidas de vida marinha.
Quando se encontrava na laguna em 1836, Darwin não tinha acesso a essas estatísticas, mas
nos quatro anos anteriores passados no Beagle vira o suficiente do mundo para saber que nas
águas apinhadas do recife havia algo peculiar.
No dia seguinte, Darwin se aventura no lado a barlavento do atol com o capitão do Beagle,
o vice-almirante James FitzRoy, e ali os dois veem ondas enormes quebrarem contra a
barreira branca de coral. Um espectador europeu comum, acostumado às águas mais calmas
do canal da Mancha ou do Mediterrâneo, teria se sentido naturalmente atraído pela
impressionante crista das ondas. (Os vagalhões, Darwin observa, são quase “iguais em força
aos que vemos durante um vendaval nas regiões temperadas, e nunca se aplacam”.) Mas o que
chama a atenção de Darwin é outra coisa – não a violenta ondulação da água, mas a força que
resiste a ela: os minúsculos organismos que construíram o próprio recife.
O oceano, jogando suas águas sobre o extenso recife, parece um inimigo todo-poderoso, invencível; no entanto, vemos que
ele encontra resistência, e é até conquistado, por meios que a princípio parecem extremamente fracos e ineficientes. Não é
que o oceano poupe a rocha de coral; os grandes fragmentos espalhados sobre o recife e empilhados na praia, dos quais
brotam os altos coqueiros, manifestam claramente a implacável força das ondas ... Porém, essas ilhotas de coral baixas,
insignificantes, aguentam e são vitoriosas, pois aqui um outro poder participa da luta como antagonista. As forças orgânicas
separam os átomos de carbonato de cal, um por um, dos vagalhões espumantes, e os unem numa estrutura simétrica. Ainda
que um furacão lhe arranque milhares de enormes fragmentos, que poder terá contra o trabalho acumulado de miríades de
arquitetos que se dedicam dia e noite, mês após mês?
Darwin sente-se atraído por esses minúsculos arquitetos porque acredita serem eles a
chave para a solução de um mistério que levou o Beagle às ilhas Cocos. No memorando do
almirantado que autoriza a viagem de cinco anos do navio, uma das principais diretrizes é a
investigação da formação dos atóis. O mentor de Darwin, o brilhante geólogo Charles Lyell,
havia sugerido pouco tempo antes que os atóis são criados por vulcões submarinos
arremessados para cima por poderosos movimentos da crosta terrestre. Na teoria de Lyell, a
forma circular característica de um atol emerge quando colônias de coral constroem recifes ao
longo da circunferência da cratera vulcânica. O pensamento de Darwin tinha sido
profundamente moldado pelo modo como Lyell compreendia o tempo profundo da
transformação geológica, mas postado ali na praia, vendo os vagalhões quebrarem contra o
coral, ele sabe que seu mentor está errado em relação à origem dos atóis. Essa não é uma
história de simples geologia, ele percebe. É uma história relacionada à persistência inovadora
da vida. E, enquanto matuta sobre a ideia, há um indício de outra coisa em sua mente, uma
teoria maior, mais abrangente, que poderia explicar o vasto âmbito das inovações da vida.
Formas desconhecidas vão, pouco a pouco, ganhando corpo.
Dias depois, de volta ao Beagle, Darwin abre seu diário e reflete sobre aquele choque
mesmerizante entre as ondas e o coral. Pressagiando uma linha que publicaria trinta anos mais
tarde na passagem mais famosa de A origem das espécies, escreve: “Mal posso explicar a
razão, mas parece-me haver grande magnificência na visão das costas exteriores desses atóis.”
Com o tempo, descobriria o porquê.
A cidade superlinear
Desde muito jovem, o cientista suíço Max Kleiber gostava de testar os limites da convenção.
Quando aluno de graduação em Zurique, nos anos 1910, passeava pelas ruas usando sandálias
e colarinho desabotoado, um traje chocante para a época. Quando serviu no exército suíço,
descobriu que seus superiores vinham trocando informações com os alemães, embora a Suíça
tivesse uma posição oficial de neutralidade na Primeira Guerra Mundial. Horrorizado,
simplesmente não compareceu quando reconvocado e acabou passando vários meses na
cadeia. Quando se decidiu por uma carreira nas ciências agrárias, farto das limitações da
sociedade de Zurique, traçou um caminho que seria seguido por incontáveis antibelicistas não
conformistas dados a usar sandálias nas décadas que se seguiriam: mudou-se para a
Califórnia.
Kleiber passou a trabalhar numa faculdade de agronomia mantida pela Universidade da
Califórnia em Davis, no coração do fértil vale Central. De início sua pesquisa teve por foco o
gado, medindo o impacto do tamanho do corpo sobre as taxas metabólicas, a velocidade com
que um organismo queima completamente a energia. Avaliava que as taxas metabólicas tinham
grande valor prático para a indústria pecuária, porque lhe permitiam prever com razoável
precisão não só a quantidade de alimento que sua criação demandaria como também a
quantidade de carne que ela produziria após o abate. Pouco depois de sua chegada em Davis,
Kleiber deparou com um padrão misterioso em sua pesquisa, uma estranheza matemática que
logo o levou a analisar uma variedade muito maior de criaturas em seu laboratório: ratos,
pombas-trocazes, pombos, cães e até seres humanos.
Cientistas e amantes de animais tinham observado havia muito que quanto maior a vida,
mais lenta ela se torna. Moscas vivem por horas ou dias; elefantes vivem por meio século. Os
corações das aves e dos pequenos mamíferos bombeiam sangue muito mais rápido que os das
girafas e das baleias-azuis. Mas a relação entre tamanho e velocidade não parecia ser linear.
Um cavalo podia ser quinhentas vezes mais pesado que um coelho, mas seus batimentos
cardíacos certamente não eram quinhentas vezes mais lentos. Depois de uma série colossal de
medições em seu laboratório em Davis, Kleiber descobriu que esse fenômeno escalar
obedecia a um roteiro matemático invariável chamado lei da potência ¾. Se você marcasse
num gráfico a massa versus o metabolismo numa grade logarítmica, o resultado seria uma
linha perfeitamente reta levando de ratos e pombos até touros e hipopótamos.
Os físicos estavam acostumados a descobrir belas equações como essa escondidas nos
fenômenos que estudavam, mas no mundo bem mais desordenado da biologia a elegância
matemática era uma raridade. Quanto mais espécies Kleiber e seus pares analisavam, porém,
mais clara se tornava a equação: o metabolismo aumenta na proporção do peso corporal
elevado à ¾ potência. A matemática é bastante simples: calcula-se a raiz quadrada de mil, que
é (aproximadamente) 31, e depois a raiz quadrada de 31, que é (de novo aproximadamente)
5,5. Isso significa que uma vaca, que é cerca de mil vezes mais pesada que uma marmota, terá,
em média, uma vida 5,5 vezes mais longa, e uma taxa cardíaca 5,5 vezes mais lenta que a dela.
Como o jornalista científico George Johnson observou certa vez, uma consequência
encantadora da lei de Kleiber é que o número de batimentos cardíacos ao longo da vida tende
a ser estável de uma espécie para outra. Os animais grandes apenas levam mais tempo para
esgotar sua cota.
Durante as décadas seguintes, a lei de Kleiber foi estendida à escala microscópica das
bactérias e do metabolismo celular; descobriu-se que até as plantas obedecem à proporção da
¾ potência em seus padrões de crescimento. Onde quer que a vida tenha aparecido, quando
quer que um organismo tenha precisado encontrar uma maneira de consumir e distribuir
energia através do corpo, a proporção da ¾ potência governou os padrões de seu
desenvolvimento.
Vários anos atrás, o físico teórico Geoffrey West decidiu investigar se a lei de Kleiber se
aplica a uma das maiores criações da vida: os superorganismos das cidades construídas pelo
homem. Será que o “metabolismo” da vida urbana se torna mais lento à medida que as cidades
crescem? Haveria um padrão subjacente ao crescimento e ao ritmo de vida de sistemas
metropolitanos? Trabalhando a partir do lendário Santa Fe Institute, que presidiu até 2009,
West reuniu uma equipe internacional de pesquisadores e conselheiros para coletar dados
sobre diversas cidades ao redor do mundo, medindo tudo, do crime ao consumo doméstico de
energia elétrica, do número de novas patentes às vendas de gasolina.
Quando por fim processaram toda essa informação, West e sua equipe ficaram encantados
ao descobrir que a proporção da ¾ potência governava o crescimento da energia e do
transporte da vida urbana. O número de postos de gasolina, a venda desse combustível, a área
de superfície das ruas, o comprimento dos cabos elétricos: todos esses fatores seguem
exatamente a mesma lei de potência que governa a velocidade com que a energia é despendida
em organismos biológicos. Se um elefante era apenas um camundongo em escala maior, uma
cidade era apenas um elefante ampliado.
Mas a descoberta mais fascinante da pesquisa de West veio dos dados que revelaram não
obedecer à lei de Kleiber. West e sua equipe descobriram outra lei de potência escondida em
seu imenso banco de dados de estatísticas urbanas. Todos os itens de informação factual que
envolviam criatividade e inovação – patentes, orçamentos de pesquisa e desenvolvimento,
profissões “supercriativas”, inventores – também seguiam uma lei da ¼ potência, de maneira
tão inteiramente previsível quanto a lei de Kleiber. Mas havia uma diferença fundamental: a
lei da ¼ potência que governava a inovação era positiva, não negativa. Uma cidade dez vezes
maior que a vizinha não era dez, mas dezessete vezes mais inovadora que ela. Uma metrópole
cinquenta vezes maior que uma cidade era 130 vezes mais inovadora.
A lei de Kleiber provou que, à medida que se torna maior, a vida se torna mais lenta. Mas o
modelo de West demonstrou que as cidades construídas pelo homem rompem os padrões da
vida biológica de uma maneira fundamental: à medida que crescem, as cidades geram ideias
num ritmo mais rápido. Isto é o que chamamos de “escalamento superlinear”: se a criatividade
aumentasse com o tamanho de maneira direta, linear, evidentemente encontraríamos mais
patentes e invenções numa cidade maior, mas o número de patentes e invenções per capita
seria estável. As leis de potência de West sugeriram algo muito mais intrigante: que, apesar de
todo o barulho, toda a aglomeração e a distração, o residente médio de uma metrópole com 5
milhões de habitantes era quase três vezes mais criativo que o residente médio de uma cidade
de 100 mil habitantes. “Grandes cidades não são como vilas apenas maiores”, escreveu Jane
Jacobs quase cinquenta anos atrás. A lei da ¼ potência positiva de West deu a essa intuição
um fundamento matemático. Alguma coisa no ambiente de uma grande cidade tornava seus
residentes significativamente mais inovadores que os de cidades menores. Mas o que era isso?
A regra dos 10/
A primeira transmissão nacional de um programa de televisão em cores, distribuída para 22
cidades nos Estados Unidos, ocorreu em 1o de janeiro de 1954, quando a NBC exibiu durante
uma hora o desfile do Torneio das Rosas. Para os que tiveram a sorte de ver o programa, o
efeito de uma imagem colorida em movimento numa pequena tela parece ter sido fascinante. O
New York Times, numa linguagem típica, qualificou-o de uma “verdadeira profusão de matiz e
profundidade”. “Concentrar tanta informação de cor dentro da moldura de uma pequena tela”,
escreveu o Times, “seria difícil até para o mais talentoso artista fazendo uma pintura ‘imóvel’.
Fazê-lo com imagens em constante movimento parecia pura mágica.” Lamentavelmente, a
“transmissão” do desfile do Torneio das Rosas só pôde ser vista em protótipos de aparelhos,
disponíveis apenas em showrooms da RCA. Programas em cores só se tornariam usuais no
horário nobre no final dos anos 1960. Após o advento da cor, as convenções básicas que
definiam a imagem televisiva permaneceriam inalteradas por décadas. Os mecanismos de
distribuição começaram a se diversificar com a introdução dos aparelhos de videocassete e da
TV a cabo no final dos anos 1970. Mas a imagem continuou a mesma.
Em meados dos anos 1980, vários executivos influentes da mídia e da tecnologia, junto
com alguns políticos visionários, tiveram a excelente ideia de aperfeiçoar a qualidade de
vídeo da televisão aberta. Fizeram-se discursos, formaram-se comitês, construíram-se
protótipos experimentais, mas só em 23 de julho de 1996 uma afiliada da CBS em Raleigh,
Carolina do Norte, iniciou a primeira transmissão pública de um sinal de televisão de alta
definição (HDTV), embora, como no caso da sequência do Torneio das Rosas, nenhum
consumidor comum tivesse um aparelho capaz de exibir essa “mágica”.b Em 1999, um
punhado de emissoras começou a transmitir sinais de HDTV, embora essa tecnologia só tenha
se tornado um grande fenômeno de consumo cinco anos depois. No dia 12 de junho de 2009,
data em que a Federal Communications Commission determinou que todas as estações de
televisão deixassem de transmitir o velho padrão analógico, mais de 10% dos lares
americanos tinham televisores que deixaram de funcionar.
Um dos grandes truísmos de nosso tempo é que vivemos numa era de aceleração
tecnológica; novos paradigmas continuam surgindo em quantidade crescente e a intervalos
cada vez menores. Essa aceleração reflete não apenas o fluxo de novos produtos, mas também
nossa crescente disposição para abraçar esses novos aparelhos estranhos e pô-los em uso. As
ondas chegam em frequências cada vez maiores, e estamos nos tornando, em números
crescentes, surfistas experientes, remando ao encontro delas no instante em que começam a
quebrar. Mas a história da HDTV sugere que essa aceleração está longe de ser uma lei
universal. Se medirmos a rapidez com que uma nova tecnologia avança de uma ideia original
até a adoção em massa, veremos que a HDTV viajou exatamente na mesma velocidade em que
a televisão em cores o fizera quatro décadas antes. A TV em cores levou dez anos para se
transformar de periférica em predominante, o mesmo tempo que a HDTV levou para alcançar
sucesso de massa duas gerações depois.
Na verdade, se consideramos o século XX em sua totalidade, os desenvolvimentos mais
importantes nos meios de comunicação de massa um-para-muitos acompanham a taxa de
inovação social com espantosa regularidade. Vamos chamar isso de regra dos 10/10: uma
década para construir uma nova plataforma e uma década para que ela encontre um público de
massa. O padrão tecnológico do rádio modulado em amplitude – o que chamamos hoje de
rádio AM – foi desenvolvido na primeira década do século XX. A primeira estação AM
comercial começou a transmitir em 1920, mas os aparelhos de rádio só se tornaram uma
presença indefectível nos lares americanos no fim dos anos 20. A Sony iniciou as pesquisas
para o primeiro gravador de videocassete em 1969, mas só pôs os primeiros Betamax à venda
sete anos depois, e os videocassetes só se tornaram uma necessidade doméstica em meados
dos anos 80. O DVD só substituiu estatisticamente o videocassete nos lares americanos em
2006, nove anos depois que os primeiros aparelhos apareceram no mercado. Telefones
celulares, computadores pessoais, aparelhos de navegação GPS – todos eles levaram um
período de tempo semelhante para passar de inovação a adoção em massa.
Considere, como cenário alternativo, a história de Chad Hurley, Steve Chen e Jawed
Karim, três ex-funcionários do site de pagamento on-line PayPal, que concluíram no início de
2005 que a web estava madura para um aperfeiçoamento no modo de lidar com vídeo e som.
O vídeo, é claro, não era nativo da web, que iniciara sua vida quinze anos antes como uma
plataforma que permitia a acadêmicos compartilhar documentos de hipertexto. Com o passar
dos anos, porém, os videoclipes haviam começado a ser transmitidos on-line, graças ao
advento de novos padrões como Quick-Time, Flash ou Windows Media Player. Mas os
mecanismos que permitiam às pessoas fazer upload de seus próprios vídeos e compartilhá-los
eram muito complicados para a maioria dos usuários comuns. Assim, Hurley, Chen e Karim
fizeram às pressas uma grosseira versão beta para um serviço que sanaria essas deficiências,
levantaram menos de 10 milhões de dólares em capital de risco, contrataram cerca de duas
dúzias de pessoas e lançaram o YouTube, um website que transformou por completo a maneira
como a informação em vídeo é compartilhada on-line. Dezesseis meses depois da fundação da
companhia, o serviço transmitia mais de 30 milhões de vídeo por dia. Dentro de dois anos, o
YouTube era um dos dez sites mais visitados na web. Antes de Hurley, Chen e Karim terem a
ideia de sua nova empresa, vídeos na web eram quase tão comuns quanto legendas na
televisão. O negócio na web era fazer coisas com textos, um upload de foto vez ou outra. O
YouTube transformou o vídeo on-line em coisa corriqueira.
Agora compare o modo como essas duas ideias – HDTV e YouTube – mudaram as regras
básicas de utilização para suas respectivas plataformas. A passagem da televisão analógica
para a HDTV é uma mudança de grau, não de categoria: há mais pixels, o som é mais
envolvente, as cores são mais vivas. Mas os consumidores assistem à HDTV exatamente da
mesma maneira como assistiam à antiquada TV analógica. Escolhem um canal, reclinam-se e
assistem. O YouTube, por outro lado, alterou de maneira radical as regras básicas do meio.
Para começar, transformou o ato de assistir a vídeos on-line em um fenômeno de massa. Mas
com o YouTube você não está limitado a se sentar e assistir a um espetáculo, tal como ocorre
com a televisão; pode fazer o upload de seus próprios vídeos, recomendar ou avaliar outros,
entrar numa conversa sobre eles. Com apenas alguns cliques fáceis, pode pegar um vídeo que
está sendo exibido no site de outra pessoa e colocá-lo no seu próprio site. A tecnologia
permitiu a entusiastas comuns programar efetivamente suas redes de televisão particulares,
reunindo videoclipes de todos os cantos do planeta.
Alguns dirão que isso é apenas uma questão de software, algo intrinsecamente mais
adaptável que hardware, como aparelhos de TV e telefones celulares. Mas, antes que a web se
tornasse usual em meados dos anos 90, o ritmo da inovação no campo do software seguia
exatamente o mesmo padrão de desenvolvimento 10/10 que vimos na difusão de outras
tecnologias do século XX. A interface gráfica do usuário, por exemplo, remonta a uma famosa
versão tecnológica feita pelo pioneiro da ciência da computação Doug Engelbart em 1968.
Durante a década de 1970, muitos de seus elementos essenciais – como a hoje onipresente
metáfora do desktop, a área de trabalho – foram desenvolvidos por pesquisadores na Xerox-
PARC. Porém, o primeiro produto comercial com uma interface gráfica do usuário plenamente
desenvolvida só foi lançado em 1981, na forma da estação de trabalho Xerox Star, seguida
pelo Macintosh em 1984, a primeira interface gráfica do usuário a alcançar um público
comum, ainda que seleto. Mas só com o lançamento do Windows 3.0 em 1990 – quase exatos
dez anos depois que o Xerox Star chegou ao mercado – interfaces gráficas do usuário se
tornaram a norma. O mesmo padrão ocorre na história do desenvolvimento de outros gêneros
de software, como processadores de texto, planilhas eletrônicas, ou clientes de e-mail. Todos
eles foram construídos a partir de bits, não de átomos, mas levaram o mesmo tempo que a
HDTV para passar de ideia a sucesso de massa.
Há muitas maneiras de medir a inovação, mas talvez o parâmetro mais elementar, pelo
menos no que diz respeito à tecnologia, gire em torno da tarefa que a tecnologia em questão
nos permite executar. Se tudo o mais for igual, um avanço que nos ajude a executar duas
tarefas antes impossíveis é duas vezes mais inovador que um que só nos permita fazer uma
coisa nova. Por esse critério, o YouTube foi significativamente mais inovador que a HDTV,
muito embora a HDTV tenha representado um problema técnico mais complicado. O YouTube
possibilita publicar, compartilhar, avaliar e discutir vídeos, além de assistir a eles mais
eficientemente. Já a HDTV nos permite assistir a mais pixels do que antes. Mas, mesmo com
todas essas camadas extras de inovação, o YouTube passou de ideia a adoção em massa em
menos de dois anos. Alguma coisa no ambiente da web havia permitido a Hurley, Chen e
Karim lançar uma boa ideia no mundo com assombrosa rapidez. Eles tomaram a regra dos
10/10 e a transformaram em 1/1.
ESTE É UM LIVRO sobre o espaço da inovação. Alguns ambientes sufocam novas ideias; outros
parecem gerá-las sem esforço. A cidade e a web foram motores de inovação desse tipo
porque, por razões históricas complexas, ambas são ambientes poderosamente propícios à
criação, à difusão e à adoção de boas ideias. Nenhum dos dois é perfeito, de maneira alguma.
(Pense na taxas de criminalidade nas grandes cidades ou na explosão de spams on-line.) Mas
tanto a cidade quanto a web possuem um inegável histórico em matéria de geração de
inovação.c Da mesma maneira, as “miríades de pequeninos arquitetos” do recife de coral de
Darwin criam um ambiente em que a inovação biológica pode florescer. Se quisermos
compreender de onde vêm as boas ideias, temos de pô-las em contexto. A ideia de Darwin que
transformou o mundo desdobrou-se dentro de seu cérebro, mas pense em todos os ambientes e
todas as ferramentas de que ele precisou para construí-la: um navio, um arquipélago, um
caderno, uma biblioteca, um recife de coral. Nosso pensamento molda os espaços que
habitamos, e os espaços retribuem o favor. O que procuro mostrar neste livro é que uma série
de propriedades e padrões compartilhados ocorre reiteradamente em ambientes de
excepcional fertilidade. Eu os reduzi a sete padrões, cada um dos quais ocupa um capítulo
separado. Quanto mais abraçarmos esses padrões – em nossos hábitos de trabalho e hobbies
pessoais, em nossos ambientes de trabalho, no projeto de novas ferramentas de software –,
mais capazes seremos de explorar nossa extraordinária capacidade de pensamento inovador.d
Esses padrões revelam ter uma longa história, muito mais antiga que a da maioria dos
sistemas que costumamos associar à inovação. É uma história particularmente rica, porque não
se limita apenas a criações humanas, como a internet ou a metrópole. A amplificação e a
adoção de inovação útil existem também ao longo de toda a história natural. Os recifes de
coral são por vezes chamados de “cidades do mar”, e parte do que este livro tem a dizer é que
precisamos levar essa metáfora a sério: o ecossistema do recife é tão inovador em sua
exploração daquelas águas pobres em nutrientes porque compartilha algumas características
definidoras com cidades reais. Na linguagem da teoria da complexidade, esses padrões de
inovação e criatividade são fractais: eles reaparecem em forma reconhecível quando
ampliamos e reduzimos porções de imagens, passando de molécula para neurônio, para pixel,
para calçada. Quer estejamos olhando para as inovações da vida baseada no carbono ou para
a explosão de novas ferramentas de software na web, as mesmas formas continuam a aparecer.
Quando a vida se torna criativa, tende a gravitar rumo a certos padrões recorrentes, quer
sejam emergentes e auto-organizativos, quer sejam deliberadamente fabricados por agentes
humanos.
Pode parecer estranho falar sobre campos de experiência tão diferentes como se fossem
intercambiáveis. Na verdade, porém, a todo instante damos saltos conceituais equivalentes da
biologia para a cultura, sem pestanejar. Não é uma figura de linguagem dizer que o padrão de
“competição” – um termo frequentemente associado à inovação – desempenha um papel
decisivo no comportamento dos mercados, na interação entre uma multidão de
espermatozoides e um óvulo e na batalha entre os organismos por fontes finitas de energia na
escala do ecossistema. Não estamos usando a metáfora da competição econômica para
descrever as lutas daqueles espermatozoides: o significado da palavra “competição” é amplo
(ou talvez profundo) o suficiente para abranger espermatozoides e empresas. O mesmo
princípio se aplica aos sete padrões que reuni aqui.
Viajar através desses diferentes ambientes e escalas não é mero turismo intelectual. Há
muito a ciência percebeu que podemos compreender melhor algo estudando seu
comportamento em diferentes contextos. Quando queremos responder a uma pergunta como
“Por que a web foi tão inovadora?”, evocamos naturalmente os pensamentos de seus criadores
e os ambientes de trabalho, as organizações e as redes de informação que eles usaram ao
construí-la. Revela-se, no entanto, que podemos responder a essa pergunta de maneira mais
completa se traçarmos analogias com padrões de inovação que vemos em ecossistemas como
o recife de coral de Darwin ou na estrutura do cérebro humano. Não faltam teorias para nos
instruir sobre como tornar nossas organizações mais criativas, ou para explicar por que as
florestas pluviais tropicais engendram tanta diversidade molecular. O que nos falta é uma
teoria unificada que descreva os atributos comuns compartilhados por todos esses sistemas de
inovação. Por que o recife de coral é uma máquina tão poderosa de inovação biológica? Por
que as cidades têm uma história tão extensa de criação de ideias? Por que Darwin foi capaz de
conceber uma teoria que havia escapado a tantos de seus brilhantes contemporâneos? Sem
dúvida há respostas parciais para essas perguntas que pertencem apenas a cada situação e a
cada escala: a história ecológica do recife; a sociologia da vida urbana; a biografia intelectual
de um cientista. Mas a proposta deste livro é que há outras respostas, mais interessantes, que
são aplicáveis a todas as três situações, e que, quando o problema é abordado dessa maneira
fractal, transdisciplinar, novas percepções tornam-se possíveis. Quando observamos as ideias
lampejarem nessas diferentes escalas, descobrimos padrões que as observações numa única
escala facilmente deixam escapar ou subestimam.
Chamo essa perspectiva privilegiada de zoom longo. Ela pode ser imaginada como uma
espécie de ampulheta.
À medida que descemos em direção ao centro da ampulheta, as escalas biológicas se
contraem, do tempo global e profundo da evolução às trocas microscópicas de neurônios ou
DNA. No centro da ampulheta, a perspectiva muda da natureza para a cultura, e as escalas se
expandem: de pensamentos individuais e ambientes de trabalho privados a cidades imensas e
redes globais de informação. Quando contemplamos a história da inovação da perspectiva
privilegiada do zoom longo, descobrimos que ambientes excepcionalmente produtivos exibem
padrões similares de criatividade em múltiplas escalas ao mesmo tempo. Não podemos
explicar a biodiversidade do recife de coral estudando apenas a genética do próprio coral. O
recife gera e sustenta tantas formas de vida diferentes graças a padrões que reaparecem nas
escalas das células, dos organismos e do próprio ecossistema mais amplo. As fontes de
inovação na cidade e na web são igualmente fractais. Nesse sentido, analisar a questão da
inovação da perspectiva do zoom longo não nos dá apenas novas metáforas, mas novos fatos.
O padrão da “competição” é um excelente exemplo. Todo manual de economia nos dirá que
a competição entre empresas concorrentes leva à inovação em seus produtos e serviços. Mas,
quando consideramos a inovação da perspectiva do zoom longo, a competição revela-se
menos importante para a história das boas ideias do que costumamos pensar. A análise da
inovação na escala de indivíduos e organizações – feita nos manuais comuns – distorce nossa
visão. Ela cria uma imagem da inovação que exagera o papel da pesquisa proprietáriae e da
competição que favorece a “sobrevivência dos mais aptos”. A abordagem do zoom longo nos
permite ver que abertura e conectividade podem, no final das contas, ser mais valiosas para a
inovação que mecanismos puramente competitivos. Esses padrões de inovação merecem
reconhecimento – em parte por ser importante em si compreender por que boas ideias surgem
historicamente, e em parte porque, ao abraçar esses padrões, podemos construir ambientes
mais eficientes no cultivo de boas ideias, quer sejam escolas, governos, plataformas de
software, seminários de poesia ou movimentos sociais. Poderemos pensar de maneira mais
criativa se abrirmos nossas mentes para os muitos ambientes conectados que tornam a
criatividade possível.
A literatura acadêmica sobre inovação e criatividade é rica em distinções sutis entre
inovações e invenções, entre diferentes formas de criatividade: artística, científica,
tecnológica. Escolhi deliberadamente a expressão mais ampla possível – boas ideias – para
sugerir a perspectiva transdisciplinar que estou tentando adotar. Nesta análise, as boas ideias
vão de plataformas de software a gêneros musicais, de paradigmas científicos a novos
modelos de governo. Minha premissa é que há tanto valor a ser encontrado na busca das
propriedades comuns entre todas essas diferentes formas de inovação e criatividade quanto na
documentação das diferenças que as separam. O poeta e o engenheiro (e o recife de coral)
podem parecer estar a um milhão de quilômetros um do outro em suas formas particulares de
conhecimento, mas, quando trazem boas ideias ao mundo, padrões semelhantes de
desenvolvimento e colaboração moldam esse processo.
Se há uma única máxima que percorre todos os argumentos deste livro, é que em geral
somos mais bem-sucedidos ao conectar ideias do que ao protegê-las. Como o próprio livre
mercado, a defesa da restrição do fluxo de inovação foi durante muito tempo reforçada por
apelos à ordem “natural” das coisas. Mas a verdade é que, ao examinarmos a inovação na
natureza e na cultura, percebemos que ambientes que constroem muros em torno de boas ideias
tendem a ser menos inovadores que ambientes mais abertos. Boas ideias podem não querer ser
livres, mas querem se conectar, se fundir, se recombinar. Querem se reinventar transpondo
fronteiras conceituais. Querem tanto se completar umas às outras quanto competir.
a Tradução de Barbara Heliodora. Rio de Janeiro, Lacerda, 2004. (N.T.)

b A complicada história das origens da HDTV poderia ser o tema de um livro inteiro, mas a versão condensada é mais ou

menos a que se segue. No início dos anos 1980, a rede de televisão pública japonesa NHK fez uma série de demonstrações do
protótipo de uma plataforma de televisão de alta definição para membros do Congresso dos EUA e outras autoridades do
governo. Isso ocorreu quando os temores americanos da ascendência econômica do Japão estavam no auge, uma época em
que televisores Sony já eram mais vendidos que aparelhos de marcas americanas veneráveis como RCA e Zenith. A ideia de

que os japoneses poderiam introduzir uma imagem de melhor qualidade no mercado dos EUA representou uma ameaça tanto
para as companhias americanas de aparelhos eletrônicos quanto, como ressaltou o então senador Al Gore após assistir à
demonstração da NHK, para as companhias de semicondutores que produziriam os chips para todos esses novos aparelhos de
TV. Meses depois, a Federal Communications Commission (FCC) tomou a decisão formal de investigar a possibilidade de
melhorar a qualidade da imagem da TV aberta e a cabo. Todas as forças se alinharam para o grande passo seguinte no meio
televisivo. Ronald Reagan, sempre capaz de compreender as possibilidades transformadoras da televisão, chegou a declarar que
o desenvolvimento de um padrão americano de HDTV era um assunto de “interesse nacional”.

O que se viu nos anos seguintes, porém, foi menos um Grande Salto Adiante que um interminável e sinuoso rastejar. Primeiro, a
FCC nomeou um comitê – o Advisory Committee on Advanced Television Service (ACATS) –, que solicitou e analisou 23
propostas diferentes ao longo do ano seguinte, e acabou por reduzi-las a seis diferentes sistemas, cada um usando um esquema
único para transmitir som e imagem de maior definição. Alguns eram analógicos, outros digitais. Alguns eram compatíveis com
os sistemas em uso; outros exigiriam que o consumidor adquirisse um equipamento mais avançado. Durante cinco anos, as
organizações responsáveis aperfeiçoaram e testaram suas várias plataformas, ao custo de centenas de milhões de dólares em
pesquisa e desenvolvimento. Esperava-se que todo o processo fosse concluído em 1993, quando estava previsto que o ACATS
realizaria uma série de testes finais para escolher um vencedor, mas esses testes revelaram-se apenas um preâmbulo: o único
consenso do comitê foi que o sistema digital era preferível ao analógico, o que reduziu ligeiramente o campo. Como cada um
dos candidatos restantes tinha defeitos suficientes para impedir o comitê de ungir um herdeiro legítimo, o ACATS propôs que
eles colaborassem na criação de um único padrão. Em 1995, esse grupo – chamado de Grande Aliança – chegou a um acordo
com relação a especificações para vídeo e áudio digitais de alta definição que a FCC adotou no ano seguinte.

c Ironicamente, esse fato pode estar relacionado a alguns de seus defeitos. É possível que os criminosos e os spammers

floresçam nesses espaços porque também permitem que sejam mais inovadores em suas atividades.

d Partes da argumentação que se segue serão familiares para qualquer pessoa que tenha passado a última década, ou as duas

últimas, explorando os novos campos de possibilidades da web. A última vez que escrevi sobre o assunto em um livro foi dez
anos atrás; desde então, surgiu uma maravilhosa comunidade de teóricos empreendedores, capaz de empurrar as fronteiras do
meio e ao mesmo tempo de refletir sobre o que esses avanços poderiam significar. Todos nós vimos em primeira mão o quanto
a web pode ser um espaço inovador e reunimos uma vasta quantidade de conhecimento local sobre as forças que tornam essa
inovação possível. Ao montar os sete padrões de inovação, tentei organizar esse conhecimento em categorias produtivas, e
espero ter proposto algumas ideias sobre o modo como a internet funciona que surpreendam os nativos. Mas até a cabeça mais
devotada ao crowdsourcing, ao microblogging e à Wikipédia tem dúvidas sobre até que ponto a experiência da web pode ser
transportada para ambientes de inovação do mundo real. O fato de os padrões funcionarem para o Google não significa que
sejam pertinentes para uma organização sem fins lucrativos com número insuficiente de empregados, para um fabricante de
autopeças ou para um governo municipal. Assim, uma maneira de pensar sobre as páginas que se seguem é enxergá-las como
uma defesa da ideia de que a mágica que vimos na web tem uma longa história anterior à internet e pode ser reproduzida em
outros ambientes.

e O termo é aplicado à pesquisa ou tecnologia desenvolvida por uma empresa ou entidade privada, envolvendo segredos

comerciais, e que só pode ser legalmente utilizada mediante a compra de uma licença explícita. (N.T.)

1. O possível adjacente
EM ALGUM MOMENTO NO FINAL DOS ANOS 1870, um obstetra parisiense chamado Stéphane
Tarnier tirou um dia de folga de seu trabalho na Maternité de Paris, a maternidade destinada às
mulheres pobres da cidade, e fez uma visita ao Paris Zoo, situado nas proximidades. Vagando
entre os elefantes, os répteis e os jardins clássicos do zoológico, dentro do Jardin des Plantes,
Tarnier deparou com chocadeiras de frangos. A visão dos pintos recém-saídos da casca do
ovo, cambaleando de um lado para outro no recinto cálido da chocadeira, fez surgir uma
associação em sua mente, e ele não demorou a contratar Odile Martin, a responsável pela
criação das aves domésticas no zoológico, para construir um dispositivo que desempenharia
uma função semelhante para recém-nascidos humanos. Pelos padrões modernos, a mortalidade
infantil era assombrosamente elevada no final do século XIX, mesmo numa cidade sofisticada
como Paris. Um a cada cinco bebês morria antes de aprender a engatinhar, e entre bebês
prematuros, com baixo peso ao nascer, o número dos que morriam era muito maior. Tarnier
sabia que a regulagem da temperatura era decisiva para manter essas crianças vivas, e sabia
que o establishment médico francês tinha uma arraigada obsessão por estatísticas. Por isso,
assim que sua nova incubadora para recém-nascidos foi instalada na Maternité, aquecendo as
frágeis crianças com garrafas de água quente sob caixas de madeira, ele iniciou um rápido
estudo de quinhentos bebês. Os resultados chocaram os médicos parisienses: enquanto 66%
dos bebês de baixo peso costumavam morrer dentro de semanas após o nascimento, apenas
38% daqueles mantidos na caixa incubadora de Tarnier tiveram o mesmo destino. Era possível
reduzir a taxa de mortalidade de prematuros quase à metade simplesmente tratando-os como
pintos recém-saídos da casca num zoológico.
A incubadora de Tarnier não foi o primeiro dispositivo empregado para aquecer recém-
nascidos, e a engenhoca que ele construiu com Martin seria significativamente aperfeiçoada
nas décadas subsequentes. No entanto, a análise estatística do obstetra deu à incubação de
recém-nascidos o impulso de que precisava: dentro de poucos anos, o conselho municipal de
Paris determinou que se instalassem incubadoras em todas as maternidades da cidade. Em
1896, um médico empreendedor chamado Alexandre Lion montou uma mostra de incubadoras
com recém-nascidos vivos – na Exposição de Berlim. Apelidado de Kinderbrutenstalt, ou
“chocadeira de crianças”, a mostra de Lion veio a ser o sucesso inesperado da exposição,
dando início a uma estranha tradição de mostras paralelas de incubadoras que persistiu boa
parte do século XX. (Coney Island teve uma exposição permanente de incubadoras para bebês
até o início dos anos 1940.) As incubadoras modernas, suplementadas com oxigenoterapia e
outros avanços, tornaram-se equipamento obrigatório em todos os hospitais americanos após o
fim da Segunda Guerra Mundial, dando início a um espetacular declínio de 75% nas taxas de
mortalidade infantil entre 1950 e 1998. Como as incubadoras atuam exclusivamente no início
da vida, seu benefício para a saúde pública – medido pelo número de anos extras que
proporciona – rivaliza com qualquer avanço médico do século XX. A radioterapia ou um
duplo bypass podem nos dar mais uma ou duas décadas, mas uma incubadora nos dá uma vida
inteira.
No mundo em desenvolvimento, porém, a história da mortalidade infantil continua
deplorável. Enquanto em toda a Europa e nos Estados Unidos as mortes de crianças estão
abaixo de dez por mil nascimentos, em países como a Libéria e a Etiópia morrem mais de cem
crianças a cada mil, muitas das quais bebês prematuros que teriam sobrevivido se tivessem
acesso a incubadoras. Mas os equipamentos modernos são complexos e caros. Uma
incubadora comum de um hospital americano pode custar mais de 40 mil dólares. Talvez o
preço, no entanto, seja o menor obstáculo a transpor. Equipamentos complexos quebram, e
quando isso acontece precisa-se de técnicos especializados para consertá-los e de peças de
reposição. No ano seguinte ao tsunami de 2004 no oceano Índico, o hospital da cidade
indonésia de Meulaboh recebeu oito incubadoras de uma série de organizações de assistência
internacional. No final de 2008, quando um professor do Massachusetts Institute of Technology
(MIT) chamado Timothy Prestero visitou o hospital, todas as oito estavam quebradas,
vitimadas por picos de energia e pela umidade tropical. A isso se somava a incapacidade da
equipe de ler o manual de reparo escrito em inglês. As incubadoras de Meulaboh eram um
exemplo representativo: alguns estudos sugerem que nada menos que 95% da tecnologia
médica doada a países em desenvolvimento quebra nos primeiros cinco anos de uso.
Prestero tinha especial interesse por essas incubadoras quebradas, porque a organização
que fundara, Design that Matters, vinha trabalhando havia anos num novo projeto para uma
incubadora mais confiável e menos dispendiosa, um projeto que reconhecia que tecnologias
médicas complexas tendiam a ter, no contexto de um mundo em desenvolvimento, uma duração
muito diferente da que tinham num hospital americano ou europeu. Projetar uma incubadora
para um país em desenvolvimento não era apenas uma questão de criar algo que funcionasse;
era também projetar algo que quebrasse de uma maneira não catastrófica. Como não era
possível assegurar um suprimento de peças sobressalentes ou técnicos de manutenção
habilitados, Prestero e sua equipe decidiram, em vez disso, construir uma incubadora feita de
peças já abundantes no mundo em desenvolvimento. A ideia surgiu com Jonathan Rosen, um
médico de Boston, que observou que até os menores vilarejos do mundo em desenvolvimento
pareciam ser capazes de manter automóveis em condições de funcionamento. Eles podiam não
ter aparelhos de ar-condicionado, laptops ou TV a cabo, mas conseguiam manter seus Toyota
4 Runners na estrada. Assim, Rosen procurou Prestero com uma ideia: que tal fazer uma
incubadora a partir de peças de automóvel?
Três anos depois que Rosen deu a ideia, a equipe da Design that Matters introduziu um
protótipo chamado NeoNurture. Por fora, parecia uma aerodinâmica incubadora moderna, mas
suas tripas eram automotivas. Faróis dianteiros do tipo sealed-beam forneciam o calor
decisivo; ventiladores de painel asseguravam a circulação de ar filtrado; campainhas de porta
faziam soar alarmes. Era possível prover o aparelho de energia por meio de um isqueiro
adaptado ou de uma bateria de motocicleta comum. Construir o NeoNurture com peças de
automóvel foi duplamente eficiente, porque aproveitava tanto a oferta das próprias peças
quanto o conhecimento local de conserto de automóveis. Ambos eram recursos abundantes no
contexto do mundo em desenvolvimento, como Rosen gostava de dizer. Não era preciso ser um
técnico médico habilitado para consertar o NeoNurture; não era preciso nem mesmo ler o
manual. Bastava saber substituir um farol dianteiro.
Boas ideias são como o aparelho NeoNurture. São, inevitavelmente, limitadas pelas peças
e habilidades que as cercam. Temos uma tendência natural a romantizar inovações
revolucionárias, imaginando ideias de grande importância que transcendem seus ambientes,
uma mente talentosa que de algum modo enxerga além dos detritos das velhas ideias e da
tradição engessada. Mas as ideias são trabalho de bricolagem; são fabricadas a partir desses
detritos. Tomamos as ideias que herdamos ou com que deparamos e as ajeitamos numa nova
forma. Gostamos de pensar em nossas ideias como uma incubadora de 40 mil dólares, saída
diretamente da fábrica, mas na realidade elas foram construídas com as peças sobressalentes
que por acaso se encontravam na garagem.
ANTES DE SUA MORTE PREMATURA EM 2002, o biólogo evolucionário Stephen Jay Gould
mantinha uma singular coleção de calçados que havia comprado durante suas viagens pelo
mundo em desenvolvimento, em feiras livres de Quito, Nairóbi e Délhi. Eram sandálias feitas
com pneus reciclados. Talvez não fossem grande coisa como manifestação de moda, mas
Gould lhes atribuía grande valor enquanto prova da “engenhosidade humana”. Ele as
considerava também uma metáfora dos padrões de inovação no mundo biológico. As
inovações da natureza também se baseiam em peças sobressalentes. A evolução avança
tomando recursos disponíveis e mesclando-os para criar novos usos. O teórico evolucionário
François Jacob captou isso em seu conceito da evolução como trabalho de um “remendão”,
não de um engenheiro; nossos corpos são também obras de bricolagem, peças velhas
concatenadas para formar algo radicalmente novo. “O princípio da transformação de pneus em
sandálias”, escreveu Gould, “opera em todas as escalas e tempos, permitindo iniciativas
peculiares e imprevisíveis a qualquer momento – para tornar a natureza tão inventiva quanto a
pessoa mais engenhosa que algum dia avaliou o potencial de um ferro-velho em Nairóbi.”
Podemos ver esse processo em curso na inovação primordial da própria vida. Ainda não
temos um consenso científico com relação aos detalhes das origens da vida. Alguns creem que
ela se originou nas bocas ferventes, metálicas, de vulcões submarinos; outros suspeitam dos
oceanos abertos; outros apontam para as lagoas de maré e brejos em que Darwin acreditava
que a vida primeiro se arraigou. Muitos cientistas respeitados acreditam que a vida pode ter
chegado do espaço cósmico, engastada num meteoro. Mas temos um quadro muito mais claro
da composição da atmosfera da Terra antes que a vida emergisse, graças a um campo chamado
química pré-biótica. A Terra sem vida era dominada por algumas moléculas básicas:
amoníaco, metano, água, dióxido de carbono, um pequeno número de aminoácidos e outros
compostos orgânicos simples. Cada uma dessas moléculas era capaz de uma série finita de
transformações e trocas com outras moléculas na sopa primordial: ocorria recombinação entre
metano e oxigênio para formar formaldeído e água, por exemplo.
Pense em todas essas moléculas iniciais, depois imagine todo o potencial de novas
combinações que elas poderiam formar de maneira espontânea, simplesmente colidindo umas
com as outras (ou talvez atingidas pela energia extra da queda de um raio). Se você pudesse
brincar de Deus e desencadear todas essas combinações, acabaria de posse da maior parte
dos elementos básicos da vida: as proteínas que formam as fronteiras das células; as
moléculas de açúcar decisivas para os ácidos nucleicos de nosso DNA. Mas não seria capaz
de dar início às reações químicas que iriam formar um mosquito, um girassol ou um cérebro
humano. O formaldeído é uma combinação de primeira ordem: é possível criá-lo diretamente
a partir das moléculas presentes na sopa primordial. Os elementos atômicos que constituem
um girassol são exatamente os mesmos disponíveis na Terra antes do surgimento da vida, mas
não se poderia criar espontaneamente um girassol naquele ambiente, porque ele se baseia em
toda uma série de inovações subsequentes, que demoraria bilhões de anos para se desenvolver
na Terra: cloroplastos para capturar a energia do sol, tecidos vasculares para permitir a
circulação de seiva através da planta, moléculas de DNA para transmitir à geração seguinte as
instruções para a construção do girassol.
O cientista Stuart Kauffman tem um nome sugestivo para o conjunto de todas essas
combinações de primeira ordem: “o possível adjacente”. A expressão capta tanto os limites
quanto o potencial criativo de mudança e inovação. No caso da química pré-biótica, o
possível adjacente define todas aquelas reações moleculares que eram diretamente
alcançáveis na sopa primordial. Girassóis, mosquitos e cérebros existem fora desse círculo de
possibilidade. O possível adjacente é uma espécie de futuro espectral, pairando nas bordas do
atual estado de coisas, um mapa de todas as maneiras segundo as quais o presente pode se
reinventar. Ele não é, contudo, um espaço infinito, ou um campo de jogo totalmente aberto. O
número de reações de primeira ordem potenciais é vasto, mas é finito, excluindo a maioria das
formas que hoje povoam a biosfera. O possível adjacente revela que a qualquer momento o
mundo é capaz de mudanças extraordinárias, mas apenas certas mudanças podem acontecer.
A estranha e bela verdade com relação ao possível adjacente é que seus limites se alargam
à medida que os exploramos. Cada combinação introduz novas combinações no possível
adjacente. Pense nele como uma casa que se expande num passe de mágica ao se abrir cada
nova porta. Você começa numa sala com quatro portas, cada uma levando a uma nova sala que
ainda não visitou. Essas quatro salas são o possível adjacente. Mas depois que você abre uma
dessas portas e entra na próxima sala, três novas portas aparecem, cada uma levando a outra
sala nova em folha a que você não poderia ter chegado a partir de seu ponto de partida
original. Continue abrindo portas, e por fim terá construído um palácio.
Os ácidos graxos básicos se organizarão naturalmente em esferas forradas com uma dupla
camada de moléculas, muito semelhante às membranas que definem as fronteiras das células
modernas. Uma vez que os ácidos graxos se combinam para formar essas esferas delimitadas,
uma nova ala do possível adjacente se abre, porque essas moléculas criam implicitamente uma
divisão fundamental entre o interior e o exterior da esfera. Essa divisão é a própria essência
de uma célula. Depois que temos um “interior”, podemos pôr coisas ali: alimento, organelas,
código genético. Pequenas moléculas podem atravessar a membrana e então se combinar com
outras moléculas para formar entidades maiores, grandes demais para escapar de volta através
das fronteiras da protocélula. Ao formarem espontaneamente essas membranas de duas
camadas, os primeiros ácidos graxos abriram uma porta para o possível adjacente, que levaria
finalmente ao código genético com base em nucleotídios e às usinas de energia dos
cloroplastos e mitocôndrias – os principais “habitantes” de todas as células modernas.
O mesmo padrão reaparece ao longo de toda a evolução da vida. Na verdade, uma maneira
de pensar sobre a trajetória da evolução é como uma exploração contínua do possível
adjacente. Quando dinossauros como o Velociraptor desenvolveram um novo osso chamado
carpo semilunar (o nome vem de sua forma de meia-lua), passaram a poder girar o punho com
muito mais flexibilidade. A curto prazo, isso lhes deu mais destreza como predadores, mas
também abriu uma porta para o possível adjacente que levaria por fim, muitos milhões de anos
depois, à evolução de asas e ao voo. Quando desenvolveram polegares opositores, nossos
ancestrais abriram todo um novo campo cultural do possível adjacente: a criação e o uso de
ferramentas e armas finamente manufaturadas.
Uma das coisas que me parecem muito inspiradoras na ideia do possível adjacente de
Kauffman é o continuum que ela sugere entre sistemas naturais e feitos pelo homem. Ele
introduziu o conceito em parte para ilustrar uma fascinante e antiquíssima tendência
compartilhada pela história tanto natural quanto humana: esse incessante empurrar das
barricadas do possível adjacente. “Obviamente algo aconteceu nos últimos 4,8 bilhões de
anos”, escreve ele. “A biosfera expandiu-se, realmente explodiu de maneira mais ou menos
persistente, em direção ao possível adjacente em constante expansão. ... É bastante curioso
que esse fato claramente verdadeiro raras vezes seja comentado, e que não tenhamos nenhuma
teoria particular para essa expansão.” Se você fosse um átomo de carbono 4 bilhões de anos
atrás, havia poucas centenas de configurações moleculares em que poderia tropeçar. Hoje,
esse mesmo átomo de carbono, cujas propriedades atômicas não mudaram um único
nanograma, pode ajudar a construir esperma de baleia, ou uma sequoia-gigante, ou um vírus
H1N1, além de uma lista quase infinita de formas de vida baseadas no carbono que não faziam
parte do possível adjacente da Terra pré-biótica. Acrescente a isso uma lista igualmente
espantosa de invenções humanas que se baseiam no carbono – cada um dos objetos de plástico
do planeta, por exemplo –, e verá quanto o reino do possível adjacente se expandiu desde que
aqueles ácidos graxos se organizaram por si mesmos na primeira membrana.
A HISTÓRIA DA VIDA E DA CULTURA HUMANA pode ser contada, portanto, como a história da
sondagem gradual, mas incessante, do possível adjacente, cada inovação abrindo novos
caminhos a explorar. Mas alguns sistemas são mais competentes que outros na exploração
desses espaços de possibilidade. Em última análise, o mistério do paradoxo de Darwin que
nos serviu de ponto de partida gira em torno da seguinte questão: por que o ecossistema de um
recife de coral deveria ser tão audacioso em sua exploração do possível adjacente – tantas
formas de vida diferentes compartilhando um espaço tão pequeno –, enquanto as águas
circundantes do oceano carecem dessa maravilhosa diversidade? De maneira semelhante, os
ambientes das grandes cidades possibilitam muito mais exploração comercial do possível
adjacente que cidades pequenas ou aldeias, permitindo que negociantes e empresários se
especializem em campos que seriam insustentáveis em centros populacionais menores. A web
explorou o possível adjacente de seu meio de maneira muito mais rápida que qualquer outra
tecnologia de comunicação na história. No início de 1994, era um meio apenas de texto,
páginas de palavras conectadas por hyperlinks. Dentro de poucos anos, porém, o espaço de
possibilidades começou a se expandir. A web se tornou um meio que nos permite fazer
transações financeiras, o que a transformou num shopping center, numa casa de leilões e num
cassino. Pouco depois, tornou-se um verdadeiro meio de mão dupla, no qual era tão fácil
publicar o próprio texto quanto ler os dos outros, engendrando formas que o mundo nunca
vira: enciclopédias escritas pelos usuários, a blogosfera, os sites de redes sociais. O YouTube
fez da web um dos mais influentes mecanismos de distribuição de vídeos no planeta. E agora
mapas digitais estão desencadeando suas próprias revoluções cartográficas.
Podemos ver as impressões digitais do possível adjacente em um dos mais notáveis
padrões de toda a história intelectual, o que os especialistas chamam de “múltiplo”: um
cientista ou inventor em algum lugar do mundo tem uma ideia brilhante, mas, quando vai a
público e revela seu achado extraordinário, descobre que três outras mentes haviam chegado,
de maneira independente, à mesma ideia no ano anterior. As manchas solares foram
descobertas simultaneamente em 1611 por quatro cientistas que viviam em quatro diferentes
países. A primeira bateria elétrica foi inventada tanto por Dean von Kleist quanto por Cuneus
de Leyden em 1745 e 1746. Joseph Priestley e Carl Wilhelm Scheele isolaram o oxigênio
entre 1772 e 1774. A lei da conservação de energia foi formulada separadamente quatro vezes
no final da década de 1840. A importância evolucionária da mutação genética foi proposta por
S. Korschinsky em 1899 e depois por Hugo de Vries em 1901, enquanto o impacto dos raios X
sobre as taxas de mutação foi descoberto de maneira independente por dois estudiosos em
1927. O telefone, o telégrafo, a máquina a vapor, a fotografia, o tubo de vácuo, o rádio – quase
todos os avanços tecnológicos essenciais da vida moderna têm um múltiplo escondido em
algum lugar na história de sua origem.
No início dos anos 1920, dois pesquisadores da Universidade Columbia, William Ogburn e
Dorothy Thomas, decidiram investigar quantos múltiplos poderiam encontrar, e acabaram
publicando seu levantamento num influente ensaio com o delicioso título “Are Inventions
Inevitable?” (As invenções são inevitáveis?). Ogburn e Thomas encontraram 148 casos de
inovação independente, a maioria das quais ocorreu na mesma década. Ao ler a lista agora,
ficamos impressionados não só com o número de casos, mas com o grau em que a lista é
indistinguível de uma história não filtrada das grandes ideias. Os múltiplos foram evocados
para sustentar teorias nebulosas sobre o zeitgeist, mas eles têm uma explicação muito mais
bem-fundamentada. Boas ideias não surgem do nada; são construídas a partir de um grupo de
partes existentes, cuja combinação se expande (e, às vezes, se contrai) ao longo do tempo.
Algumas dessas partes são conceituais: maneiras de resolver problemas ou novas definições
do que constitui um problema, para começar. Algumas delas são, literalmente, partes
mecânicas. Para sair em busca do oxigênio, Priestley e Scheele precisaram do arcabouço
teórico de que o ar era em si algo digno de estudo e de que era constituído por diferentes
gases, duas ideias que só começaram a ser aceitas na segunda metade do século XVIII. Mas
precisaram também das balanças avançadas que lhes permitiam medir as minúsculas
mudanças no peso provocadas pela oxidação, tecnologia que só tinha algumas décadas de
idade em 1774. Quando essas partes se tornaram disponíveis, a descoberta do oxigênio entrou
na esfera do possível adjacente. O isolamento do oxigênio, como se diz, estava “no ar”, mas
apenas porque um conjunto específico de descobertas anteriores havia tornado esse
experimento imaginável.
O POSSÍVEL ADJACENTE tem a ver tanto com limites quanto com aberturas. Na linha do tempo de
uma biosfera em expansão, a todo momento há portas que ainda não podem ser abertas. Na
cultura humana, gostamos de pensar nas ideias revolucionárias como acelerações súbitas na
linha do tempo, quando um gênio salta cinquenta anos adiante e inventa algo que as mentes
normais, aprisionadas no momento presente, não poderiam descobrir. Mas a verdade é que os
avanços tecnológicos (e científicos) raramente escapam do possível adjacente; a história do
progresso cultural é, quase sem exceção, a história de uma porta que leva a outra, permitindo a
exploração de uma sala do palácio de cada vez. Mas, como evidentemente a mente humana
não é limitada pelas leis finitas da atração molecular, de vez em quando alguém tem uma ideia
que nos teletransporta para certas salas adiante, saltando alguns passos exploratórios no
possível adjacente. Mas essas ideias quase sempre resultam em fracassos de curto prazo,
exatamente por terem dado um salto à frente. Temos uma expressão para qualificá-las:
dizemos que estão “à frente de seu tempo”.
Tomemos a lendária “máquina analítica” projetada no século XIX pelo inventor britânico
Charles Babbage, considerado pela maioria dos historiadores da tecnologia o pai da
computação moderna, embora talvez devesse ser chamado de bisavô da computação moderna,
pois o mundo levou várias gerações para alcançar sua ideia. Na verdade, Babbage está no
panteão por duas invenções, nenhuma das quais conseguiu construir em vida. A primeira foi a
“máquina de diferenças”, uma engenhoca de extrema complexidade, que pesava quinze
toneladas e tinha mais de 25 mil peças mecânicas, projetada para calcular funções
polinomiais, essenciais para a elaboração das tabelas trigonométricas para a navegação. Se
Babbage tivesse de fato concluído seu projeto, a máquina de diferenças teria sido a
calculadora mecânica mais avançada do mundo. Quando o Museu de Ciências de Londres
construiu um dos projetos de Babbage para comemorar o centenário de sua morte, a máquina
produziu resultados exatos até a 31ª casa decimal numa questão de segundos. Tanto a
velocidade quanto a precisão do aparelho teriam excedido qualquer outra coisa possível na
época de Babbage por várias ordens de magnitude.
A despeito de toda a sua complexidade, contudo, a máquina de diferenças estava
inteiramente dentro do possível adjacente da tecnologia vitoriana. A segunda metade do século
XIX assistiu a um fluxo constante de aperfeiçoamentos do cálculo mecânico, muitos deles
baseados na arquitetura de Babbage. O inventor suíço Per Georg Scheutz construiu uma
máquina de diferenças que funcionava, lançada na Exposition Universelle de 1855; duas
décadas depois o projeto de Scheutz, do tamanho de um piano, havia sido reduzido ao tamanho
de uma máquina de costura. Em 1884, um inventor americano chamado William S. Burroughs
fundou a American Arithmometer Company para vender calculadoras produzidas em massa
para empresas de todo o país. (Quase um século mais tarde, a fortuna gerada por essas
máquinas ajudaria a financiar a carreira literária, para não falar do consumo de drogas, de seu
neto e xará.) O projeto da máquina de diferenças de Babbage foi, sem dúvida, uma obra de
gênio, mas não transcendeu o possível adjacente de seu tempo.
Não se pode dizer o mesmo da outra ideia brilhante de Babbage: a máquina analítica, o
grande projeto não concluído de sua carreira, no qual labutou durante os últimos trinta anos de
sua vida. A máquina era tão complicada que nunca saiu da planta, com exceção de uma
pequena parte que Babbage construiu pouco antes de morrer em 1871. Ela foi – pelo menos no
papel – o primeiro computador programável do mundo. O fato de ser programável significava
que a máquina era essencialmente adaptável; não tinha sido projetada para um conjunto
específico de tarefas, como a máquina de diferenças, que fora otimizada para equações
polinomiais. Como todos os computadores modernos, a máquina analítica era capaz de se
metamorfosear, reinventando-se com base nas instruções evocadas por sua programação. (A
brilhante matemática Ada Lovelace, filha única do Lord Byron, escreveu vários conjuntos de
instruções para a máquina analítica de Babbage, ainda movida a vapor, o que lhe valeu o título
de primeiro programador do mundo.) O projeto de Babbage para a máquina antecipou a
estrutura básica dos computadores contemporâneos: “programas” deveriam ser introduzidos
por meio de cartões perfurados, inventados décadas antes para controlar teares têxteis;
instruções e dados eram mantidos num “depósito”, o equivalente ao que chamamos hoje de
memória de acesso aleatório ou RAM; e cálculos eram executados por meio de um sistema
que Babbage chamou de “mill” (moinho), usando uma linguagem da era industrial para
descrever o que atualmente conhecemos como unidade central de processamento ou CPU.
Em 1837 Babbage já havia esboçado a maior parte desse sistema, mas o primeiro
verdadeiro computador a usar essa arquitetura programável só apareceu mais de cem anos
depois. Enquanto a máquina de diferenças engendrou uma série imediata de refinamentos e
aplicações práticas, a máquina analítica desapareceu do mapa para todos os efeitos. Muitos
dos insights pioneiros que Babbage tivera nos anos 1830 teriam de ser redescobertos de forma
independente pelos visionários da ciência da computação na época da Segunda Guerra
Mundial.
Por que a máquina analítica revelou-se tamanho beco sem saída no curto prazo, se as ideias
de Babbage eram tão brilhantes? A maneira elegante de responder a essa pergunta é dizer que
tais ideias escapavam dos limites do possível adjacente. Mas talvez seja melhor exprimir isso
em termos mais prosaicos: Babbage simplesmente não dispunha das peças sobressalentes
certas. Mesmo que ele tivesse construído uma máquina segundo suas especificações, não é
certo que ela teria funcionado, porque ele estava na verdade esboçando um equipamento para
a era eletrônica quando a revolução mecânica movida a vapor ainda estava em curso.
Diferentemente de todos os computadores modernos, a máquina de Babbage deveria ser
inteiramente composta de engrenagens e interruptores mecânicos, assombrosos em número e
na complexidade de seu projeto. A informação fluiria através do sistema como um constante
balé de objetos de metal a mudar de posição em movimentos cuidadosamente coreografados.
Além de ter manutenção dificílima, a máquina estava fadada a ser irremediavelmente lenta.
Babbage gabou-se para Ada Lovelace que acreditava que sua invenção seria capaz de
multiplicar dois números de vinte dígitos em três minutos. Mesmo que estivesse certo –
Babbage não seria o primeiro empreendedor tecnológico a exagerar o desempenho de seu
produto –, o tempo de processamento teria tornado a execução de programas mais
complicados torturantemente lenta. Os primeiros computadores da era digital podiam realizar
o mesmo cálculo em questão de segundos. Um iPhone completa milhões de cálculos como esse
no mesmo tempo. Computadores programáveis precisavam de tubos de vácuo, ou, melhor
ainda, de circuitos integrados, nos quais a informação flui como pequeninos pulsos de
atividade elétrica, e não como engrenagens metálicas movidas a vapor, enferrujadas e
estrepitosas.
Podemos ver um padrão comparável – num ritmo vastamente acelerado – na história do
YouTube. Se Hurley, Chen e Karim tivessem tentado pôr a ideia do YouTube em prática dez
anos antes, em 1995, ela teria sido um fiasco espetacular, porque nos primórdios da web um
site para compartilhamento de vídeos não estava no seu possível adjacente. Em primeiro
lugar, a grande maioria dos usuários possuía conexões discadas penosamente lentas, que
podiam por vezes levar minutos para fazer o download de uma imagem pequena. (O download
de um clipe médio do YouTube, com dois minutos de duração, teria demandado nada menos
que uma hora com os modems de 14,4bps comuns na época). Outra explicação para o sucesso
imediato do YouTube é que seus criadores puderam basear o serviço de vídeos na plataforma
Flash da Adobe, o que significava que podiam se concentrar na facilitação do
compartilhamento e discussão dos clipes, não precisando gastar milhões de dólares para
desenvolver todo um novo padrão de vídeo a partir do zero. Mas o próprio Flash só foi
lançado no final de 1996, e nem sequer suportava vídeos até 2002.
Para usar nossa analogia da microbiologia, inventar uma máquina de diferenças na década
de 1830 foi como a tentativa de um conjunto de ácidos graxos de formar a membrana de uma
célula. A máquina de diferenças foi, sem dúvida, um salto adiante, mas, por mais avançada
que fosse, ainda estava nos limites do possível adjacente, e foi por isso que tantas iterações
práticas baseadas no projeto de Babbage emergiram nas décadas subsequentes. Mas tentar
criar a máquina analítica em 1850 – como teria sido tentar criar o YouTube em 1995 – foi o
equivalente a uma tentativa daqueles ácidos graxos de se auto-organizarem na forma de um
ouriço-do-mar. A ideia estava certa, mas o ambiente ainda não estava pronto para ela.
TODOS NÓS VIVEMOS dentro de nossas próprias versões do possível adjacente. Em nossa vida
profissional, em nossas atividades criativas, nas organizações que nos empregam, nas
comunidades que habitamos – em todos esses diferentes ambientes, estamos cercados por
novas configurações potenciais, novos meios de escapar da rotina. Estamos, cada um de nós,
cercados pelos equivalentes conceituais daquelas peças sobressalentes de Toyota, todas à
espera de serem recombinadas em algo mágico, algo novo. Não precisam ser os avanços
épicos da biodiversidade nem a invenção de um computador programável. A abertura de uma
nova porta pode levar a uma descoberta científica capaz de transformar o mundo, mas pode
levar também a uma estratégia mais eficaz para ensinar alunos do segundo ano fundamental, ou
a uma ideia original para o marketing do aspirador de pó que sua empresa está prestes a
lançar. O truque é descobrir maneiras de explorar os limites de possibilidade ao nosso redor.
Isso pode ser tão simples quanto alterar o ambiente físico em que trabalhamos, ou cultivar um
tipo específico de rede social, ou manter certos hábitos na maneira como procuramos e
armazenamos informação.
Lembre-se da pergunta com que iniciamos: que tipo de ambiente gera boas ideias? A
resposta mais simples que podemos lhe dar é esta: ambientes inovadores são melhores para
ajudar seus habitantes a explorar o possível adjacente, porque apresentam uma amostra ampla
e diversa de peças sobressalentes – mecânicas ou conceituais – e estimulam novos modos de
recombiná-las. Ambientes que bloqueiam ou limitam essas novas combinações – punindo a
experimentação, obscurecendo certas áreas de possibilidade, tornando o estado atual tão
satisfatório que ninguém se dá o trabalho de explorar suas bordas – irão, em geral, originar e
difundir menos inovações que aqueles que estimulam a exploração. A infinita variedade da
vida que tanto impressionou Darwin, postado diante das águas calmas das ilhas Cocos, existe
porque o recife de coral tem uma competência extraordinária para reciclar e reinventar as
peças sobressalentes de seu ecossistema.
Há um momento famoso na história da quase catastrófica missão Apollo 13 –
maravilhosamente captado no filme de Ron Howard – em que os engenheiros que controlam a
missão se dão conta de que precisam improvisar um filtro de dióxido de carbono, ou os
astronautas vão envenenar a atmosfera do módulo lunar com suas próprias exalações antes de
retornarem à Terra. Eles têm purificadores de carbono em abundância a bordo, mas esses
filtros se destinavam à espaçonave original, agora danificada, e não se ajustam ao sistema de
ventilação do módulo lunar que estão usando como salva-vidas para voltar para casa. O
controle da missão reúne rapidamente o que é chamado de um “tiger team” de engenheiros
para enfrentar agressivamente o problema e criar um inventário imediato de todos os
equipamentos disponíveis no módulo lunar naquele momento. No filme, Deke Slayton, chefe
da Flight Crews Operations, joga uma pilha de equipamentos bagunçados numa mesa de
conferência: mangueiras, tubos, sacolas, fitas de vedação e outras peças variadas. Ele levanta
o filtro de carbono. “Temos de encontrar uma maneira de fazer esse filtro se encaixar num
buraco feito para isto”, diz e aponta para as peças sobressalentes na mesa, “sem usar nada
além daquilo.”
A parafernália espacial sobre a mesa define o possível adjacente para o problema da
construção de um purificador de carbono num módulo lunar. (O dispositivo que acabaram
inventando, apelidado de “caixa de correio”, funcionou perfeitamente.) Os tubos e os
esguichos das mangueiras são como as moléculas de amoníaco e metano dos primórdios da
Terra, ou as engrenagens mecânicas de Babbage, ou aquelas peças de Toyota que aquecem uma
incubadora: são os componentes estruturais que criam – e limitam – o espaço de
possibilidades para a solução de um problema específico. De certa maneira, para os
engenheiros do Controle da Missão isso foi mais fácil do que costuma ser. Em geral
problemas desafiadores não definem seu possível adjacente de uma maneira tão clara, tão
tangível. Parte da origem de uma boa ideia consiste em descobrir que peças sobressalentes
são essas e em assegurar que não estamos apenas reciclando os mesmos velhos ingredientes. É
para isso, portanto, que os seis padrões que se seguem vão nos conduzir, porque todos eles
envolvem, de uma maneira ou de outra, táticas para a reunião de um grupo mais eclético de
ideias de componentes estruturais, peças sobressalentes que podem ser reagrupadas em
configurações novas e úteis. O segredo para ter boas ideias não é ficar sentado em glorioso
isolamento, tentando ter grandes pensamentos. O truque é juntar mais peças sobre a mesa.
2. Redes líquidas
USAMOS COLOQUIALMENTE INÚMERAS METÁFORAS diferentes para descrever boas ideias:
falamos de centelhas, lampejos, dizemos que uma lâmpada se acende em nossa mente, temos
sopros e iluminações, estalos e epifanias. Alguma coisa nesses conceitos empurra nossa
linguagem para o excesso retórico, nossa verbosidade esforçando-se para reproduzir a
inovação que descreve.
No entanto, por mais floreadas que sejam essas metáforas, nenhuma delas exprime o que de
fato é uma ideia no nível mais elementar.
Uma boa ideia é uma rede. Uma constelação específica de neurônios – milhares deles – se
acende, uns em sincronia com os outros, pela primeira vez em nosso cérebro, e uma ideia
pipoca em nossa consciência. Uma nova ideia é uma rede de células explorando o possível
adjacente de conexões que elas podem estabelecer na nossa mente. Isso é verdade, quer a
ideia em questão seja uma nova maneira de resolver um complexo problema de física, quer
seja a linha que encerra um romance, ou uma característica para um software. Se formos tentar
explicar o mistério da origem das ideias, teremos de começar nos livrando deste equívoco
comum: uma ideia não é algo único. Mais parece um enxame.
Quando pensamos sobre ideias em seu estado natural de redes neurais, duas precondições
decisivas ficam claras. Primeiro, o simples tamanho da rede: não se pode ter uma epifania
com apenas três neurônios se acendendo. A rede precisa ser densamente povoada. Nosso
cérebro tem cerca de 100 bilhões de neurônios, um número bastante impressionante, mas todos
eles seriam inúteis para criar ideias (assim como para todas as outras realizações do cérebro
humano) se não fossem capazes de estabelecer essas conexões complexas uns com os outros.
Um neurônio médio conecta-se com mil outros neurônios espalhados pelo cérebro, o que
significa que o cérebro humano adulto contém 100 trilhões de conexões neuronais distintas,
fazendo dele a maior e mais complexa rede existente na Terra. (Em comparação, há algo na
ordem de 40 bilhões de páginas na web. Supondo uma média de dez links por página, significa
que você e eu andamos por aí tendo, dentro de nossos crânios, uma rede de alta densidade
muitas ordens de magnitude maior que toda a World Wide Web.)
A segunda precondição é que a rede seja plástica, capaz de adotar novas configurações.
Uma rede densa que não consegue formar novos padrões é, por definição, incapaz de mudar,
de investigar nas bordas do possível adjacente. Quando uma nova ideia surge em nossa
cabeça, a sensação de novidade que torna essa experiência tão mágica tem um correspondente
direto nas células de nosso cérebro: um conjunto inteiramente novo de neurônios se reuniu
para tornar o pensamento possível. Essas conexões são formadas por nossos genes e pela
experiência pessoal: algumas delas ajudam a regular nossos batimentos cardíacos e disparam
reações reflexas; outras evocam vívidas lembranças sensoriais dos biscoitos que comíamos
quando crianças; outras ainda nos ajudam a inventar o conceito de um computador
programável. As conexões são a chave da sabedoria, e é por isso que a teoria de que
perdemos neurônios após atingir a idade adulta é irrelevante. O que importa em nossa mente
não é só o número de neurônios, mas a miríade de conexões que se formam entre eles.
É claro que tudo que ocorre em nosso cérebro é, tecnicamente falando, uma rede. A simples
lembrança de cortar as unhas do pé envolve uma rede de neurônios se acendendo de certa
maneira ordenada. Mas isso não a transforma numa epifania. Verifica-se que as redes que
geram boas ideias têm certas configurações características. O cérebro que cria comporta-se de
uma maneira diferente daquele que está desempenhando uma tarefa repetitiva. Os neurônios se
comunicam de maneiras diferentes. As redes assumem formas distintas.
A questão é como impelir nosso cérebro para essas redes mais criativas. Acontece que a
resposta é maravilhosamente fractal: para tornar nossa mente mais inovadora, temos de inseri-
la em ambientes que compartilhem daquele mesmo tipo característico de rede; isto é, em redes
de ideias ou pessoas que imitem as redes neurais de uma mente que explora os limites do
possível adjacente. Certos ambientes acentuam a capacidade natural do cérebro de estabelecer
novos elos de associação. Mas esses padrões de associação são muito mais velhos que o
cérebro humano, mais velhos até que os neurônios. Eles nos levam de volta, mais uma vez, à
origem da própria vida.
ATÉ ONDE SABEMOS, “vida baseada no carbono” é uma expressão redundante: a vida seria
impossível sem o átomo de carbono. A maioria dos astrobiólogos – cientistas que estudam a
possibilidade de vida em outro lugar no universo – acredita que, se algum dia viermos a
descobrir evidências convincentes de vida extraterrestre, seja em Marte, seja em alguma
galáxia distante, ela revelará ser também baseada no carbono.
Por que estamos tão convencidos do papel essencial do carbono na criação dos seres
vivos? A resposta tem a ver com as propriedades fundamentais do próprio átomo de carbono.
Quatro elétrons de valência residem em sua camada mais externa, o que, por razões
complicadas, o torna singularmente hábil para fazer conexões com outros átomos, em
particular os de hidrogênio, nitrogênio, oxigênio, fósforo, enxofre – e, de maneira decisiva,
com outros átomos de carbono. Esses seis átomos constituem 99% do peso seco de todos os
organismos vivos na face da Terra. As quatro ligações de valência dão ao carbono uma forte
propensão a formar cadeias complexas e anéis de polímeros: tudo, desde a informação
genética armazenada em ácidos nucleicos até os blocos constitutivos de proteína e a
armazenagem de energia de carboidratos e gorduras. (A tecnologia moderna explorou o
potencial gerador do átomo de carbono por meio dos polímeros artificiais que chamamos de
plásticos.) Embora sejam responsáveis por apenas 0,03% da composição total da crosta
terrestre, os átomos de carbono constituem quase 20% de nossa massa corporal. Essa
abundância realça a propriedade incomparável que os caracteriza: seu poder combinatório. O
carbono é um conector.
Essas conexões são essenciais para o funcionamento rotineiro da vida: cadeias de ácidos
nucleicos instruindo aminoácidos a se agrupar nas longas fileiras de proteínas, movidos pela
energia armazenada dos carboidratos. Mas as propriedades conectivas do carbono foram
essenciais para as inovações da própria vida. Sem o talento inato do carbono para formar
novas moléculas complexas com outros átomos, é difícil imaginar como os primeiros
organismos teriam se desenvolvido. Aqueles elétrons de quatro valências permitiram à Terra
pré-biótica explorar seu próprio possível adjacente, esquadrinhando a longa lista de
combinações moleculares potenciais até encontrar uma série de reações químicas estáveis que
floresceu nos primeiros organismos. Sem as férteis ligações do carbono, a Terra teria
provavelmente permanecido uma sopa de elementos sem vida, um planeta de química morta.
As habilidades conectivas do carbono situam-se no centro de um dos experimentos
científicos mais famosos do século XX. Em 1953, dois professores da Universidade de
Chicago, Stanley L. Miller e Harold C. Urey, criaram um sistema fechado de tubos e frascos
de vidro que simulava as condições primitivas da Terra pré-biótica. Os principais
ingredientes eram metano (CH 4 ), amoníaco (NH 3 ), hidrogênio (H 2 ) e água (H 2 O). Só o metano
continha átomos de carbono. Um frasco conectado à sopa química continha um par de
eletrodos, que Miller e Urey usaram para simular relâmpagos, provocando uma série de
rápidas faíscas entre eles. Eles conduziram o experimento durante sete dias consecutivos, e ao
completar o primeiro ciclo descobriram que mais de 10% do carbono havia se recombinado
espontaneamente em muitos dos compostos orgânicos essenciais à vida: açúcares, lipídios,
ácidos nucleicos. Miller afirmou na época que “o mero ato de provocar a faísca num
experimento pré-biótico básico” produzia metade dos 22 aminoácidos. Alguns anos atrás, uma
equipe reexaminou os frascos originais dos experimentos de Miller e Urey e constatou que em
uma das versões – que simulava o ambiente em torno de um vulcão submarino – todos os 22
aminoácidos haviam sido criados.
Nos cinquenta anos transcorridos desde que Miller e Urey provocaram sua faísca
primordial, apareceram centenas de teorias rivais para explicar os estágios primitivos da
vida, algumas enfatizando o desenvolvimento inicial da autorreplicação, outras o
desenvolvimento do metabolismo; algumas são baseadas no intenso calor dos respiradouros
submarinos, outras na colisão de cometas que carregavam vida com a superfície da Terra.
Todas essas teorias, porém, têm um tema em comum: o poder combinatório do átomo de
carbono. Alguns pesquisadores e autores de ficção científica especularam sobre um cenário
alternativo, em que a vida surge a partir do átomo de silício. O silício situa-se imediatamente
abaixo do carbono na tabela periódica e também possui quatro elétrons na camada de
valência. Mas falta-lhe a versatilidade única do carbono, sua capacidade de formar as
ligações duplas e triplas que criam as longas cadeias e anéis de ácidos graxos e açúcares.
Além disso, o silício precisa de mais energia que o carbono para formar ligações. É digno de
nota que a Terra possui cerca de cem vezes mais silício que carbono; foi no elemento mais
raro, no entanto, que a Mãe Natureza decidiu basear a vida.
A vida baseada no silício talvez seja impossível por uma outra razão: as ligações de silício
se dissolvem de imediato na água. A maior parte das teorias sobre a origem da vida depende
de H 2 O não apenas porque hidrogênio e oxigênio são elementos importantes em muitos
compostos orgânicos, mas também porque o ambiente de água líquida facilitou os
“experimentos químicos” primitivos que levaram ao surgimento da vida. Em certo sentido, o
experimento de Miller e Urey foi uma tentativa de testar de maneira mais rigorosa uma
intuição que Charles Darwin tivera um século antes sobre as origens aquosas da vida. Numa
carta ao botânico Joseph Hooker, Darwin conjecturou que a vida emergira pela primeira vez
“numa lagoazinha tépida, com todas as espécies de sais de amoníaco e fosfóricos, luz, calor,
eletricidade”. A maior parte das teorias sobre as origens da vida incorpora algumas variações
da “sopa primordial”: um ambiente em que novas combinações poderiam ocorrer graças ao
torvelinho e fluxo de líquido. O carbono pode ser um conector hábil, mas, sem um meio que
lhe permita colidir ao acaso com outros elementos, essas capacidades conectivas seriam
provavelmente desperdiçadas. Todas aquelas espetaculares cadeias de polímeros
permaneceriam irrealizadas, escondidas atrás das portas trancadas do possível adjacente.
Como o carbono, a molécula de H 2 O possui várias propriedades excepcionais que tornam
o meio de água em seu estado líquido singularmente adequado para sustentar a vida primitiva.
As ligações de hidrogênio que se formam entre diferentes moléculas de água são cerca de dez
vezes mais fortes que ligações equivalentes em líquidos “normais”, o que confere ao meio
várias propriedades decisivas. Em primeiro lugar, a água permanece na forma líquida numa
amplitude de temperatura muito maior que a de qualquer outra substância, graças em parte
àquelas ligações de hidrogênio, o que impediu que os oceanos evaporassem nos primeiros
dias da vida na Terra. A água tem também uma capacidade diabólica para dissolver coisas.
(Até o ouro, famoso por ser inerte, é solúvel na água do mar, se lhe dermos tempo suficiente.)
A combinação da fluidez e da capacidade solvente da água lhe confere maravilhosa habilidade
para criar novas redes de elementos, à medida que eles se agitam através do meio sempre
cambiante, colidindo uns com os outros de maneiras imprevisíveis. Ao mesmo tempo, a força
das ligações de hidrogênio significa que novas combinações dotadas de alguma estabilidade –
muitas delas ancoradas em torno de átomos de carbono – podem perdurar e encontrar
conexões adicionais na sopa.
Assim, quando voltamos os olhos para o mecanismo original de inovação na Terra,
encontramos duas propriedades essenciais. Primeiro, uma capacidade de estabelecer novas
conexões com o maior número possível de outros elementos. Segundo, um ambiente
“randomizante”, que estimula colisões entre todos os elementos do sistema. Na Terra, ao
menos, a história da criatividade da vida começa com uma rede líquida de alta densidade:
átomos de carbono ávidos por conexões colidindo com outros elementos na sopa primordial.
As moléculas que eles formaram estabelecem o ponto em que a química e a física deram lugar
à biologia. Ao se auto-organizarem, os primeiros lipídios abriram uma porta que levaria por
fim à membrana celular; quando se formaram os primeiros nucleotídios, abriu-se uma ala do
possível adjacente que finalmente traçou um caminho para o DNA. Eles foram os primeiros
sinais da boa ideia da vida.
ALGUMAS DÉCADAS ATRÁS, o cientista da computação Christopher Langton observou que os
sistemas inovadores tendem a gravitar em direção à “borda do caos”: a zona fértil entre o
excesso de ordem e o excesso de anarquia. (Esta ideia é também central para o conceito do
possível adjacente de Stuart Kauffman.) Por vezes Langton usa a metáfora de diferentes
estados da matéria – gasoso, líquido, sólido – para descrever essas qualidades da rede. Pense
no comportamento de moléculas em cada uma dessas três condições. Na forma de gás, o caos
impera; novas configurações são possíveis, mas a todo instante são rompidas e despedaçadas
pela natureza volátil do ambiente. Enquanto sólido, acontece o contrário: os padrões têm
estabilidade, mas são incapazes de mudança. Uma rede líquida, porém, cria um ambiente mais
promissor para o sistema explorar o possível adjacente. Novas configurações podem emergir
por meio de conexões aleatórias formadas entre as moléculas, mas o sistema não é tão instável
a ponto de destruir num instante as próprias criações. Aqueles átomos de carbono conectivos a
rodopiar na sopa primordial constituíam uma rede líquida de alta densidade. Os 100 bilhões
de neurônios que temos em nosso cérebro formam outro tipo de rede líquida: densamente
interconectada, sempre explorando novos padrões, mas também capaz de preservar estruturas
úteis por longos períodos de tempo.
Há uma previsão (ainda que numa perspectiva retroativa) escondida nessa ideia da rede
líquida, bem como na premissa de que ambientes inovadores compartilham padrões
característicos em diferentes escalas. A previsão é que, quando os seres humanos se
organizassem pela primeira vez em povoados semelhantes a redes líquidas, um grande
florescimento de inovações se seguiria imediatamente. Por muito tempo, os seres humanos
primitivos viveram no equivalente cultural das redes gasosas: pequenos bandos de caçadores-
coletores se deslocando de um lugar para outro, quase sem nenhum contato entre grupos. Mas
o surgimento da agricultura mudou tudo. Pela primeira vez, os seres humanos começaram a
formar grupos que reuniam milhares, ou dezenas de milhares de pessoas. Após milênios
vivendo no agrupamento íntimo de uma família extensa, passaram a compartilhar um espaço
apinhado de estranhos. Com esse crescimento da população ocorreu um aumento decisivo no
número de conexões que podiam ser formadas dentro do grupo. Boas ideias podiam encontrar
caminho mais facilmente para outros cérebros e neles se enraizar. Novas formas de
colaboração tornaram-se possíveis. Os economistas têm uma expressão significativa para o
tipo de compartilhamento que ocorre nesses ambientes densamente povoados:
“transbordamento de informação”. Quando compartilhamos uma cultura urbana com milhares
de outras pessoas, as boas ideias tendem a fluir de mente em mente, mesmo quando seus
criadores tentam guardá-las em segredo. “Transbordamento” é a palavra certa; ela capta a
liquidez essencial da informação em povoados densos. Como espécie, o Homo sapiens vinha
tendo um desempenho bastante bom nos milhões de anos que levaram ao nascimento da
agricultura: seus membros tinham inventado a linguagem oral, a arte, ferramentas sofisticadas
para caçar e a prática de cozinhar. Mas até se estabelecerem em cidades, não haviam
descoberto uma maneira de viver dentro de uma rede líquida de alta densidade.
O que aconteceu quando o fizeram? Para compreender a magnitude da mudança,
precisamos analisá-la em perspectiva, medindo a velocidade da inovação antes que as
primeiras cidades fossem estabelecidas. Vamos assim condensar 70 mil anos de inovação
numa única linha do tempo, terminando por volta de 2000 a.C., alguns milênios depois da
formação das primeiras cidades de verdade.
Olhar para o passado sob essa perspectiva torna uma coisa clara: em algum momento,
menos de mil anos depois que as primeiras cidades apareceram, os seres humanos inventaram
uma maneira inteiramente nova de inventar. Há uma forte correlação entre aqueles povoados
densos e o espetacular e repentino aumento na taxa de inovação social. Mas haverá uma
relação causal entre uma coisa e outra? O diagrama por si só não pode nos responder,
tampouco sabemos o suficiente sobre as histórias específicas dessas inovações para
comprovar o quanto o contexto urbano foi essencial para sua criação. Mas as evidências
circunstanciais são fortes.
É bem provável que algum caçador-coletor engenhoso tenha deparado com as propriedades
limpadoras da mistura de cinzas com gordura animal, ou sonhado em construir aquedutos
naquelas longas eras que antecederam o surgimento das cidades, mas simplesmente não temos
nenhum registro dessa epifania. Só que o problema é exatamente a falta de registro. Numa rede
caótica, de baixa densidade, ideias surgem e desaparecem. Nas redes densas das primeiras
cidades, boas ideias têm uma propensão natural a entrar em circulação. Elas transbordam e,
através desse transbordamento, são preservadas para as gerações futuras. Por razões que
veremos, redes líquidas de alta densidade tornam mais fácil a ocorrência da invenção, mas
também servem à função essencial de armazenar essas inovações. Antes da escrita, dos
livros, da Wikipédia, a rede líquida das cidades preservava a sabedoria acumulada da cultura
humana.
O padrão se repetiu na explosão de inovação comercial e artística que ocorreu nas cidades
densamente povoadas espalhadas pelas colinas do norte da Itália, o berço do Renascimento
europeu. Mais uma vez, a ascensão de redes urbanas desencadeou um impressionante aumento
no fluxo de boas ideias. Não é à toa que o norte da Itália era a região mais urbanizada da
Europa durante os séculos XIV e XV. Mas, num sentido fundamental, o padrão da inovação do
Renascimento difere do das primeiras cidades: Michelangelo, Brunelleschi e Da Vinci tinham
origem em uma cultura medieval que sofria de um excesso de ordem. Se tribos dispersas de
caçadores-coletores são o equivalente cultural de um estado gasoso, caótico, uma cultura em
que a informação era transmitida em grande parte por escribas monásticos situava-se no
extremo oposto. Um claustro é um sólido. Ao romper esses grilhões da informação e permitir
que as ideias circulassem de maneira mais livre através de uma população mais ampla e
conectada, os grandes inovadores italianos incutiram vida nova no espírito europeu.
Há muito os historiadores notaram a conexão entre o florescimento artístico e científico do
Renascimento e a formação do capitalismo mercantil na região, que obviamente envolveu seu
próprio conjunto de inovações nos negócios bancários, na contabilidade e nos seguros. Não há
dúvida de que o capitalismo acelerou o crescimento das cidades italianas e criou excedentes
de riqueza que foram depois utilizados para patrocinar artistas e arquitetos como
Michelangelo e Brunelleschi. Mas a relação entre capitalismo e inovação é mais sutil do que
muitas vezes supomos. Sim, livres mercados introduzem novas formas de competição e
acumulação de capital que podem impelir a criação e a adoção de novas ideias. Mas os
mercados não deveriam ser definidos apenas em termos de motivação de lucro. Considere a
invenção de uma das ferramentas conceituais fundamentais do capitalismo: a contabilidade de
dupla entrada, que Goethe chamou de uma das “mais admiráveis criações do espírito
humano”. Ora, a pedra angular de toda a contabilidade financeira, a inovação da dupla
entrada, que consiste em registrar todo evento financeiro em dois livros (um refletindo débito,
o outro, crédito), permitiu aos comerciantes acompanharem a saúde financeira de seu negócio
com uma precisão sem paralelo. Codificada pela primeira vez pelo monge franciscano e
matemático Luca Pacioli em 1494, o método da dupla entrada tinha sido usado havia pelo
menos dois séculos por banqueiros e comerciantes italianos. Não sabemos se ele nasceu na
mente de um único protocontador visionário, ou se a ideia irrompeu ao mesmo tempo nas
mentes de múltiplos empresários, ou se foi transmitida por pioneiros islâmicos que poderiam
ter experimentado a técnica séculos antes. Sejam quais forem suas raízes, a técnica tornou-se
usual pela primeira vez nas capitais comerciais da Itália – Gênova, Veneza e Florença –
quando os comerciantes do início do Renascimento compartilharam intuições sobre a melhor
maneira de administrar suas finanças. O que torna a história da dupla entrada tão fascinante é
o simples fato de que, apesar do imenso valor da técnica para uma empresa capitalista,
ninguém parece ter reivindicado sua autoria. Um dos instrumentos essenciais na criação do
capitalismo moderno parece ter sido desenvolvido de maneira coletiva, circulando através
das redes líquidas das cidades italianas. A contabilidade de dupla entrada tornou muito mais
fácil controlar o que se possuía, mas ninguém era dono da própria contabilidade de dupla
entrada. A ideia era poderosa demais para não transbordar para outras mentes próximas.
A contabilidade de dupla entrada ilustra um princípio essencial do surgimento dos
mercados: quando os sistemas econômicos passam das estruturas feudais para as formas
nascentes do capitalismo moderno, tornam-se menos hierárquicos e mais interconectados. Uma
sociedade organizada em torno de mercados, em vez de castelos ou claustros, distribui a
autoridade para tomar decisões por uma rede muito mais ampla de mentes individuais. A
capacidade de inovação do mercado deriva, em parte, dessa matemática muitíssimo
elementar: por mais inteligentes que as “autoridades” possam ser, se o mercado as exceder em
número na proporção de mil para um, haverá mais boas ideias ocultas nele do que no castelo
feudal. Cidades e mercados recrutam mais mentes para o projeto coletivo de explorar o
possível adjacente. Enquanto houver transbordamento entre essas mentes, inovações úteis
terão maior probabilidade de aparecer e se espalhar entre a população em geral.
Ao pensar sobre inovações em rede dessa maneira, não me refiro especificamente a um
“cérebro global” ou uma “mente-colmeia”. Há de fato alguns problemas que são
maravilhosamente resolvidos por pensamento coletivo: a formação de bairros em cidades, os
sinais variáveis da avaliação de mercado, as complexas proezas de engenharia dos insetos
que vivem em sociedade. Mas, como muitos críticos ressaltaram – mais recentemente, o
cientista da computação e músico Jaron Lanier –, grandes coletividades raramente são capazes
de verdadeira criatividade ou inovação. (A expressão “mentalidade de rebanho” não existe à
toa.) Quando as primeiras cidades-mercado emergiram na Itália, elas não criaram de forma
mágica uma consciência de grupo mais elevada. O que fizeram foi simplesmente ampliar a
concentração de mentes que podiam descobrir e compartilhar boas ideias. Não se trata de
sabedoria da multidão, mas de sabedoria de alguém na multidão. A rede, ela própria, não é
inteligente; os indivíduos é que ficam mais inteligentes por estarem conectados a ela.
EM 1964, ARTHUR KOESTLER publicou seu estudo épico sobre as raízes da inovação, The Act of
Creation. O livro foi uma tentativa de explicar como surgem ideias revolucionárias na ciência
e nas artes. (Koestler incluiu também uma longa seção sobre o humor, a seu ver estreitamente
relacionado à inspiração mais erudita dos poetas e físicos.) O levantamento de Koestler
estende-se de Arquimedes a Einstein, de Milton a Joyce, e sua análise é sempre interessante,
muitas vezes brilhante. No entanto, ao longo de um levantamento tão vasto, um padrão
reaparece com notável regularidade. O ato de criação, no entender de Koestler, é algo que
ocorre exclusivamente na mente. Ele quase não se dedica à discussão dos muitos hábitats que
sustentam ou estimulam a inovação. Não há no índice do livro, por exemplo, uma única
referência àquela grande máquina de supercriatividade, a cidade. Koestler acreditava na
capacidade criativa que surge quando diferentes disciplinas intelectuais colidem. Mas parece
ter tido pouco interesse pelos ambientes que tornam essas colisões possíveis: ambientes
vivos, de trabalho, de mídia. Num nível básico, é verdade que as ideias ocorrem dentro de
mentes, mas essas mentes estão invariavelmente conectadas com redes externas que moldam o
fluxo de informação e inspiração a partir do qual grandes ideias são formadas.
Koestler por certo não está sozinho em seu interesse pelas raízes das grandes conquistas
científicas. O livro ainda mais influente de Thomas Kuhn, A estrutura das revoluções
científicas, havia sido publicado dois anos antes de The Act of Creation. Desde a publicação
dessas duas obras, inúmeras dissertações e ensaios acadêmicos exploraram a psicologia e a
sociologia do progresso científico. Alguns enfocaram relatos biográficos de cientistas
lendários em atividade; outros testaram teorias por meio de experimentos em laboratório que
simulavam o tipo de trabalho cognitivo envolvido na descoberta científica. Outros conduziram
extensas entrevistas com pesquisadores eminentes, pedindo-lhes para recordar os detalhes de
seus momentos de descoberta e mudanças de paradigmas pessoais.
No início dos anos 1990, Kevin Dunbar, psicólogo na McGill University, decidiu adotar
outra abordagem: em vez de ler biografias, desenvolver teorias em laboratório ou ouvir
cientistas relatarem seus maiores sucessos, decidiu observá-los enquanto trabalhavam. O
estilo de pesquisa de Dunbar estava mais próximo do reality show Big Brother que da
filosofia da ciência tradicional. Ele instalou câmeras em quatro dos mais importantes
laboratórios de biologia molecular e registrou o máximo possível de suas atividades. Realizou
também longas entrevistas em que os pesquisadores descreveram os últimos avanços em seus
experimentos e suas mudanças de hipóteses, tudo no tempo presente. As fitas de vídeo e as
entrevistas in medias res permitiram a Dunbar contornar uma das maiores deficiências dos
estudos tradicionais baseados em entrevistas retrospectivas: as pessoas tendem a condensar as
histórias das origens de suas melhores ideias em narrativas bem-arrumadas, esquecendo os
caminhos confusos, sinuosos, que na verdade trilharam rumo à inspiração. Dunbar qualificou
sua abordagem de in vivo, em contraposição à abordagem in vitro tradicionalmente adotada no
estudo da cognição científica. Em outras palavras, estudou a formação de ideias não no
ambiente artificial de uma placa de Petri, mas na natureza.
Dunbar e sua equipe transcreveram todas as interações e codificaram cada intercâmbio,
usando um esquema de classificação que lhes permitia acompanhar padrões no fluxo de
informação dentro do laboratório. Nas interações de grupo, por exemplo, as trocas entre
cientistas podiam ser formalmente codificadas como “esclarecimento”, “concordância e
desenvolvimento” ou “questionamento”. Mais importante, Dunbar acompanhou as mudanças
conceituais ocorridas no curso de cada projeto: um pesquisador que, frustrado por
dificuldades persistentes para alcançar um resultado de controle estável, de repente percebe
que o problema do controle poderia ser a base para todo um novo experimento; dois cientistas
envolvidos em diferentes projetos que conversam e reconhecem uma surpreendente e
importante relação entre seus trabalhos.
A revelação mais impressionante do estudo de Dunbar veio a ser a localização física onde
a maior parte das descobertas importantes ocorreu. No caso de uma ciência como a biologia
molecular, temos em nossas cabeças a imagem inevitável do cientista sozinho no laboratório,
curvado sobre um microscópio, que se depara com um novo achado importante. Mas o estudo
de Dunbar mostrou que esses estalos solitários eram algo raro. Na verdade, a maioria das
ideias importantes vinha à tona durante reuniões regulares no laboratório, em que cerca de
uma dúzia de pesquisadores se encontrava e, de maneira informal, apresentava e discutia seu
trabalho mais recente. Ao observar o mapa da formação de ideias criado por Dunbar, você
veria que o ponto de partida da inovação não era o microscópio. Era a mesa de reunião.
Dunbar pôs a nu uma série de interações que levavam de maneira invariável a descobertas
importantes durante conversas no laboratório. O ambiente de grupo ajudava a contextualizar
problemas, à medida que perguntas feitas por colegas forçavam os pesquisadores a pensar
sobre seus experimentos numa escala ou nível diferente. As interações do grupo desafiavam as
suposições dos pesquisadores sobre seus achados mais surpreendentes, tornando-os menos
propensos a descartá-los como erro experimental. Em sessões grupais de solução de
problemas, escreve Dunbar, “os resultados do raciocínio de uma pessoa tornavam-se o input
para o raciocínio de outra ... resultando em mudança significativa em todos os aspectos do
modo como a pesquisa era conduzida”. Analogias produtivas entre diferentes campos
especializados tinham maior probabilidade de emergir no ambiente de diálogo da reunião de
laboratório.
A pesquisa de Dunbar sugere uma ideia vagamente tranquilizadora: mesmo com todos os
avanços tecnológicos de um dos principais laboratórios de biologia molecular, a ferramenta
mais produtiva para gerar boas ideias continua a ser um círculo de seres humanos sentados em
volta de uma mesa, discutindo questões de trabalho. A reunião de laboratório cria um
ambiente em que novas combinações podem ocorrer e a informação pode transbordar de um
projeto para outro. Quando trabalhamos sozinhos num gabinete, olhando num microscópio,
nossas ideias podem ficar emperradas, presas aos nossos preconceitos iniciais. O fluxo social
da conversa em grupo transforma esse estado sólido privado numa rede líquida.
OS ENCONTROS CRIATIVOS na sala de reuniões de Dunbar nos lembram que a arquitetura de
nossos ambientes de trabalho pode ter um efeito transformador sobre a qualidade de nossas
ideias. A maneira mais rápida de congelar uma rede líquida é meter as pessoas em salas
individuais por trás de portas fechadas, por isso tantas companhias da era da web projetaram
seus ambientes de trabalho em volta de espaços comuns onde reuniões casuais e conversas
interdepartamentais acontecem sem nenhum planejamento formal. (Em um ensaio publicado na
New Yorker, Malcolm Gladwell descreveu essa tendência, de maneira magnífica, como uma
West Village-ification dos escritórios empresariais.) A ideia, claro, é conseguir o equilíbrio
certo entre ordem e caos. Inspirado pela intensa publicidade que cercou início do
telecommuting,a a agência TBWA/Chiat/Day experimentou criar um escritório “não
territorial”, em que as escrivaninhas e os cubículos foram eliminados, juntamente com as salas
individuais: os empregados não tinham lugar fixo no escritório e eram estimulados a se
agrupar com os colegas em novas configurações, dependendo dos projetos do dia. Com base
em todos os relatos, foi um fracasso colossal, exatamente por ter trocado a ordem excessiva
pelo caos.
Projetos de escritórios abertos um pouco menos ambiciosos têm sido cada vez mais
reprovados nos últimos anos, por uma razão imperativa: as pessoas não gostam de trabalhar
neles. Trabalhar num escritório aberto significa estar o tempo todo em público, o que revela
ter tantos inconvenientes quanto trabalhar apenas num laboratório particular. Talvez um
modelo melhor seja o lendário Building 20 do MIT, a estrutura temporária construída durante
a Segunda Guerra Mundial que conseguiu de certa forma durar 55 anos, em parte graças a sua
trajetória no fomento tanto de ideias quanto de organizações revolucionárias, como o
departamento de linguística de Noam Chomsky, a Bose Acoustics e a Digital Equipment
Corporation. Como o MIT escreveu num release de imprensa comemorativo dessa
extraordinária história: “Não destinado a nenhuma escola, departamento ou centro, parece que
sempre teve espaço para o projeto em germinação, o experimento do aluno de pós-graduação,
o centro de pesquisa interdisciplinar.”
A mágica do Building 20, bastante elogiada em How Buildings Learn de Stewart Brand,
está no equilíbrio entre ordem e caos encontrado pelo ambiente. Havia paredes, portas e salas,
como na maioria dos prédios acadêmicos. Mas as origens temporárias da estrutura – ela fora
erguida com a expectativa de ser derrubada cinco anos depois – significavam que esses
elementos podiam ser reconfigurados com poucos entraves burocráticos, à medida que novas
ideias criavam novos objetivos para o espaço.
Por serem estruturas fixas, os escritórios tendem, em sua maioria, a romper redes líquidas
de informação. Literalmente construídos de sólidos, muitas vezes representam o sólido
conceitual de um organograma formal, com seus departamentos e hierarquias nitidamente
definidos. O Building 20 resistiu a essas forças e não se engessou por um motivo simples: era
uma construção barata e seus ocupantes não tinham escrúpulos em derrubar uma parede ou
abrir um buraco no teto para adaptar o espaço a uma nova ideia. Mas os arquitetos e designers
de interiores estão aprendendo a construir ambientes de trabalho que facilitam redes líquidas
em estruturas mais permanentes.
Em novembro de 2007, a Microsoft inaugurou o novo centro de operações de sua divisão
de pesquisa, situado em Redmond, Washington: o Building 99. Concebido por uma designer da
Microsoft chamada Martha Clarkson após intensa colaboração com os faz-tudo e
pesquisadores multidisciplinares da divisão de pesquisa, o Building 99 foi criado desde o
início para ser reinventado pelo fluxo imprevisível da colaboração e da inspiração. Todos os
espaços do escritório são modulares, com paredes que podem ser facilmente reconfiguradas
para corresponder às necessidades dos empregados. Grandes “salas situacionais” abrigam
grupos dedicados a projetos de alta prioridade, com uma mistura de estações de trabalho
individuais, mesas de reunião e sofás. As superfícies, em sua maioria, são paredes em que se
pode escrever e apagar; assim, se alguém tem uma súbita inspiração a caminho da sala de
descanso, pode esboçar rapidamente uma ideia para seus colegas verem. A pequena cozinha
tradicional fechada, com uma cafeteira e uma geladeira, é substituída por “mixer stations”, isto
é, “pontos de encontro” abertos em que empregados se reúnem para trocar ideias ou bater
papo. Em certo sentido, Clarkson construiu primeiro os bebedouros, depois projetou um
prédio de escritórios em torno deles.
Duas décadas atrás, o psicólogo Mihaly Csikszentmihalyi propôs o conceito de “fluxo”
para descrever o estado interno de concentração energizada que caracteriza a mente em seus
momentos mais produtivos. É uma linda metáfora, exatamente por sugerir a fluidez essencial
de que boas ideias tantas vezes precisam. Fluxo não significa a intensidade singular de
focalizar “como um laser”, como costumamos dizer. E não é a iluminação milagrosa de um
súbito brainstorming. É algo mais parecido com a sensação de navegar ao longo de uma
torrente, sendo levado numa direção clara, mas ainda sacudido de maneiras surpreendentes
pelos redemoinhos e turbilhões da água em movimento.
Mas, quando nos detemos na entrada do Building 99, é impossível não pensar que esse
espaço foi projetado para evocar outro tipo de fluxo: o fluxo coletivo de mentes energizadas
formando redes líquidas em seus pontos de encontro e salas situacionais. O Building 99 –
como o Building 20 antes dele – é um espaço que vê o transbordamento da informação como
uma característica, não um defeito. Ele é construído para deixar vazar. Nisso compartilha
alguns valores essenciais com as redes líquidas das cidades densas. Não, um escritório
fechado de uma das corporações mais ricas do mundo nunca terá as colisões indefinidas e a
vitalidade da calçada de uma cidade. Mas esses são pontos extremos num continuum. O
importante numa estrutura como o Building 99 é o que ela aprendeu sobre fluxo com os
ambientes urbanos e com estruturas temporárias como o Building 20. O prédio de uma
empresa nunca recriará a Gênova do século XIV, nem tampouco o Greenwich Village do
século XX. No entanto, os projetos estão se movendo nessa direção, cada vez mais distante
dos palácios de cristal do “organization man”,b com seus escritórios nos cantos do prédio e
cubículos anônimos. E, com a maior fluidez – todas aquelas novas ideias se esbarrando umas
nas outras, em salas que se expandem e se contraem para atender às necessidades delas –, não
é difícil imaginar o espaço gerando um fluxo confiável de inovação nos próximos anos.
Explorar o possível adjacente pode ser tão simples quanto abrir uma porta. De vez em quando,
porém, é preciso deslocar uma parede.
a Esquema de trabalho em que a ida diária dos empregados para um escritório é substituída por comunicação à distância. (N.T.)

b Alusão à obra de William H. Whyte, The Organization Man, de 1956. (N.T.)

3. A intuição lenta
EM 10 DE JULHO DE 2001, Ken Williams, um agente de campo do FBI do Arizona, enviou uma
“comunicação eletrônica” aos seus superiores em Washington e Nova York, usando o sistema
Automated Case Support, o antiquado repositório eletrônico por meio do qual a agência
compartilhava informações sobre investigações em curso. O documento de seis páginas
começava com esta frase profética: “O objetivo desta comunicação é informar a agência e
Nova York sobre a possibilidade de um esforço coordenado da parte de Usama Bin Laden
(UBL) para enviar estudantes aos Estados Unidos para frequentar universidades e faculdades
de aviação civil.”
Era o hoje lendário “Phoenix memo”, um tiro de advertência disparado – e quase
totalmente ignorado – durante os preguiçosos meses de verão que antecederam o 11 de
Setembro. (Ironicamente, no próprio dia em que Williams enviou seu memorando, o New York
Times publicou na página de opinião um artigo intitulado “The Declining Terrorist Threat” [A
ameaça terrorista em declínio].) O agente havia sido inspirado a escrever o memorando por
um padrão que detectara durante o ano anterior: um “número excessivo” de pessoas de
“interesse investigativo” tinha se matriculado em várias escolas de pilotagem e faculdades de
aviação civil no Arizona. Ele entrevistara vários desses indivíduos, entre os quais Zakaria
Mustapha Soubra, um estudante de engenharia aeronáutica vindo do Reino Unido com um visto
para estudantes F-1. Soubra, que tinha fotografias de Bin Laden em casa, disse a Williams
acreditar que forças e embaixadas dos Estados Unidos atacadas no Golfo Pérsico e na África
tinham sido “alvos militares legítimos do Islã”. Williams também sugeriu que mais nove
estudantes da Argélia, do Quênia, da Índia, da Arábia Saudita e de outros países do Oriente
Médio haviam se matriculado em escolas de pilotagem e possuíam amplas ligações com
movimentos islâmicos radicais. Dois deles, ao que parece, eram conhecidos de Hani Hanjour,
que iria estar no controle do voo 77 da American Airlines quando ele se chocou com o
Pentágono na manhã de 11 de setembro.
Williams não foi capaz de prever o caráter imediato da ameaça; o memorando sugere haver
um plano a longo prazo que poderia “estabelecer um quadro de indivíduos que um dia estarão
trabalhando na comunidade da aviação civil no mundo todo. No futuro esses indivíduos
estarão em condições de conduzir atividades terroristas contra alvos da aviação civil.” Ele
pensou que a Al-Qaeda podia estar tramando uma infiltração paulatina da indústria da
aviação; não conseguiu imaginar os sequestros à força bruta prestes a acontecer exatos dois
meses depois. Mas suas recomendações foram extremamente válidas: o FBI deveria montar
uma lista completa de todas as escolas de pilotagem e outras instituições de aviação em todo o
país e identificar qualquer pessoa que tentasse obter um visto para frequentar uma delas.
Apesar de ter sido endereçado a vários departamentos de alto nível, entre os quais a
Radical Fundamentalist Unit (RFU), em Washington, D.C., chefiada por David Frasca, o
memorando de Williams logo entrou no que os investigadores apelidaram mais tarde de
“buraco negro” no quartel-general do FBI. Por quase três semanas permaneceu num limbo,
antes de ser finalmente encaminhado para um analista. Este o classificou como “rotineiro” em
vez de “urgente”. Outro agente em Nova York o qualificou de “especulativo e não muito
importante”. Embora em geral os analistas costumassem passar relatórios desse tipo a seus
superiores, ele nunca chegou a Frasca.
Quando a notícia do memorando vazou pela primeira vez em 2002, as autoridades do
serviço secreto e da polícia apressaram-se a desqualificar a advertência de Williams, dizendo
que não passara de um palpite. “Ele recomendou que iniciássemos um programa para observar
as escolas de pilotagem, o que foi aceito no quartel-general do FBI”, declarou o chefe do FBI
Robert Mueller. “A recomendação ainda não havia sido posta em prática em 11 de setembro.
A propósito, eu deveria dizer que, mesmo que tivéssemos seguido as sugestões naquele
momento, isso não nos teria permitido, em vista do que sabemos desde 11 setembro, evitar os
ataques daquele dia.”
É possível demonstrar que essas duas afirmações sobre o memorando Phoenix são
verdadeiras. O agente de campo teve uma intuição sobre grupos terroristas e escolas de
pilotagem, e essa intuição por si só não teria sido suficiente para evitar os ataques de 11 de
setembro. Mas desqualificá-la com base nisso é sem dúvida passar ao largo do problema.
Williams se deparou com uma ideia provocativa e surpreendente, ainda que incompleta. Se
essa intuição tivesse se conectado com outra ideia igualmente provocativa, a qual emergiu três
semanas mais tarde a oitocentos quilômetros de distância, o memorando Phoenix poderia ter
transformado a história do início do século XXI.
PODEMOS APRENDER MUITO sobre a história da inovação examinando grandes ideias que
mudaram o mundo. De fato, a maioria das histórias intelectuais está estruturada exatamente
dessa maneira, uma narrativa de grandes descobertas, momentos de insights e estalos que
tiveram um impacto transformador na sociedade humana. Como essas ideias foram, por
definição, bem-sucedidas, é tentador atribuir seu sucesso a causas intrínsecas: o puro brilho
delas próprias ou da mente que as descobriu. Mas essas causas intrínsecas podem facilmente
eclipsar o papel do ambiente na criação e na difusão dessas ideias. Por isso é igualmente útil
examinar as faíscas que fracassaram, as ideias que conseguiram chegar a uma região
promissora do possível adjacente, mas de alguma maneira malograram ali. O memorando
Phoenix foi exatamente um desses casos. Ele continha grande sabedoria e presciência – em
julho de 2001, Ken Williams estava provavelmente mais próximo da conspiração do 11 de
Setembro que qualquer outro ser humano no planeta, exceto os próprios perpetradores –, mas
essa informação acabou se provando inútil. Por quê?
A resposta simples é que ninguém implementou as recomendações de Williams, em parte
porque o próprio memorando não havia conseguido convencer os analistas de médio escalão
de sua importância, em parte porque uma falha na comunicação dentro do FBI impediu que ele
chegasse às autoridades máximas da Divisão de Contraterrorismo e da RFU. Mas, mesmo que
tivesse chegado a David Frasca em meados de julho e conseguido de algum modo persuadi-lo
de que Ken Williams atinara com algo importante, o memorando quase certamente não teria
sido capaz de deter a conspiração do 11 de Setembro. De fato, teriam sido necessários meses
para correlacionar todos os pedidos de visto com os registros de matrícula em escolas de
pilotagem em todo o país. Detectar padrões tão sutis em tempo real era a meta não realizada
do muito criticado projeto Total Information Awareness, liderado pelo almirante John
Poindexter nos anos que se seguiram imediatamente ao 11 de Setembro. Em 2001, porém, os
agentes do FBI mal conseguiam enviar e-mails uns para os outros, muito menos correlacionar
pedidos de visto com registros de frequência em escolas de pilotagem. Foi esse detalhe
técnico que permitiu a Robert Mueller afirmar que seguir as recomendações do memorando
Phoenix em nada teria ajudado a impedir os ataques. A busca de pedidos de visto, incomuns
entre alunos de escolas de pilotagem, poderia por certo ter levado o FBI aos sequestradores,
mas não havia nenhuma arquitetura de informação montada capaz de levar a cabo esse tipo de
investigação em questão de semanas. Assim, por esse padrão, a intuição de Ken Williams não
foi suficiente por si só para evitar o 11 de Setembro.
Mas o memorando Phoenix poderia perfeitamente ter sido útil para impedir os ataques,
caso tivesse seguido um padrão recorrente ao longo de toda a história das ideias que
transformaram o mundo. Era uma intuição que precisava colidir com outra.
EXATAMENTE UM MÊS DEPOIS que Ken Williams enviou seu memorando, Zacarias Moussaoui
matriculou-se na Pan Am International Flight Academy nos arredores de St. Paul, Minnesota,
onde começou a ser treinado para pilotar um Boing 747-400 num simulador de voo. Instrutores
e outros funcionários da escola de pilotagem sentiram uma desconfiança imediata em relação a
esse novo aluno, que pagou os 8.300 dólares pelo curso completo em dinheiro vivo.
Moussaoui demonstrava um interesse excessivo pela operação das portas da cabine de
comando e pelas comunicações com a torre de controle, embora afirmasse não ter nenhum
interesse em pilotar um avião real algum dia. Os funcionários da Pan Am entraram em contato
com o FBI, e, após uma rápida verificação de seus antecedentes, Moussaoui foi preso no dia
16 de agosto, num motel, por violações da lei de imigração. Um interrogatório convenceu os
agentes de campo, chefiados por Harry Samit e Greg Jones, de que Moussaoui representava
uma ameaça ativa e poderia ser parte de uma conspiração mais ampla. O escritório do FBI em
Minnesota iniciou então uma tentativa frenética, e por fim malograda, de obter um mandado de
busca para examinar os arquivos do laptop de Moussaoui. No dia 21 de agosto, o
requerimento de um mandado de busca foi formalmente negado, sob a alegação de que as
evidências de uma causa provável eram “duvidosas”, apenas mais um palpite vindo do
interior. Durante a semana seguinte, o escritório de Mineápolis implorou em vão ao quartel-
general permissão para ter acesso ao laptop de Moussaoui. Em certa altura o agente Jones
advertiu que Moussaoui poderia “tentar pilotar alguma coisa em direção ao World Trade
Center”. O mandado de busca só seria concedido na tarde de 11 de setembro, depois que a
visão de Jones se revelara mais do que presciente.
Esta é a história de duas intuições. A intuição de Ken Williams de que uma conspiração
envolvendo múltiplos fundamentalistas islâmicos radicais poderia ser interceptada mediante o
controle de pedidos de visto e registros de matrículas em escolas de pilotagem; e a intuição
dos agentes de campo de Mineápolis de que Moussaoui queria jogar um avião contra o World
Trade Center. (Esta última nasceu, é claro, de uma outra intuição: a dos instrutores de voo da
escola da Pan Am de que Zacarias Moussaoui não estava sendo sincero com relação a seu
interesse em usar um simulador de 747.) Por si sós, elas de fato não passavam de intuições e
tinham uma validade realmente duvidosa. Mas, quando consideramos as duas juntas, seu poder
de persuasão é poderosamente ampliado. Ligar os pontos entre elas teria com certeza
fornecido causa provável suficiente para justificar o exame dos conteúdos do laptop de
Zacarias Moussaoui. E, se os agentes tivessem examinado os pertences dele, teriam
descoberto conexões diretas com onze sequestradores do 11 de Setembro, bem como números
de transferência eletrônica via Western Union que permitiriam rastrear pagamentos recentes
feitos por Ramzi bin al-Shibh, um dos principais coordenadores do ataque. Não podemos
saber ao certo se apenas essa informação teria levado as autoridades a tempo até Mohamed
Atta, ou se um interrogatório mais agressivo de Moussaoui poderia ter extraído dele uma
confissão que desenredaria o plano. Isso está, sem dúvida, na esfera das possibilidades. O
inegável é que no final de agosto de 2001 a única esperança real de impedir os ataques residia
na conexão dessas duas intuições.
A faísca malograda do memorando Phoenix sugere uma resposta para o mistério do
escalamento superlinear nas cidades e na web. Uma metrópole compartilha uma característica
fundamental com a web: ambos os ambiente são redes líquidas e densas em que a informação
flui facilmente ao longo de caminhos múltiplos e imprevisíveis. Essas interconexões
alimentam grandes ideias, porque as grandes ideias em geral vêm ao mundo mal-acabadas,
mais intuições que revelações. Insights genuínos dificilmente acontecem; é desafiador
imaginar um plano terrorista para jogar aviões de passageiros contra prédios, ou inventar um
computador programável. Por isso, a maioria das grandes ideias se configura primeiro de uma
forma parcial, incompleta. Elas têm a semente de algo profundo, mas falta-lhes um elemento
decisivo que pode transformar o palpite em algo de fato poderoso. E muitas vezes esse
elemento que falta está em algum outro lugar, vivendo sob a forma de uma intuição na cabeça
de outra pessoa. As redes líquidas criam um ambiente em que essas ideias parciais podem se
conectar; formam uma espécie de agência de encontros para intuições promissoras. Elas
facilitam a disseminação de boas ideias, é claro, mas também fazem algo mais sublime:
ajudam a completar ideias.
O verdadeiro problema da intuição de Ken Williams não foi ter falhado em imaginar os
detalhes exatos ou a iminência da conspiração do 11 de Setembro, nem o fato de que as
recomendações feitas por ele teriam sido incapazes de evitar os atentados, caso tivessem sido
seguidas. O problema foi ambiental: em vez de circular através de uma rede densa, o
memorando Phoenix foi jogado no buraco negro do sistema Automated Case Support. Em vez
de encontrar novas conexões, ele foi depositado no equivalente a um arquivo trancado.
Intuições que não se conectam estão fadadas a continuar sendo intuições.
HÁ, PORÉM, UMA DIFERENÇA FUNDAMENTAL entre as intuições do Phoenix e de Minnesota: o
tempo. Os instrutores de voo tiveram um mau pressentimento em relação a Moussaoui numa
questão de horas; alguma coisa no comportamento do rapaz e nas perguntas que fazia parecia
simplesmente inquietante. Ken Williams, por outro lado, desenvolveu sua intuição sobre a
ameaça ligada às escolas de pilotagem ao longo de anos de investigação. O memorando
Phoenix não foi o resultado de um mero palpite, mas uma ideia que ganhou forma pouco a
pouco ao longo do tempo, um padrão detectado após inúmeras horas de observação e
investigação.
A intuição de Minnesota vem sendo intelectualmente valorizada nos últimos anos: o instinto
visceral, a avaliação imediata de uma situação pelo “cérebro emocional”, que desafia os
cálculos da lógica – mas que, não obstante, vem a se revelar misteriosamente precisa. O
interesse por esse tipo de intuição remonta aos anos 1980 e aos experimentos de António
Damásio com pacientes com lesões cerebrais cuja incapacidade de fazer julgamentos
instantâneos produzia como resposta comportamentos irracionais. O best-seller de Malcolm
Gladwell Blink: a decisão num piscar de olhos concentra-se de maneira quase exclusiva no
poder (e no perigo ocasional) do palpite instantâneo: o historiador da arte que percebe num
segundo que uma escultura antiga é falsa; o policial do Departamento de Polícia de Nova York
que faz o desastroso julgamento instantâneo de que um suspeito está sacando uma arma,
quando na verdade ele está pegando a carteira.
Mas os julgamentos intuitivos instantâneos – por mais poderosos que sejam – são raridades
na história das ideias que transformaram o mundo. A maioria das intuições que se transformam
em inovações importantes se desdobra ao longo de intervalos de tempo muito mais longos.
Elas começam como uma sensação vaga, difícil de descrever, de que há uma solução
interessante para um problema que ainda não foi proposta, e persistem nas sombras da mente,
por vezes durante décadas, reunindo novas conexões e ganhando força. E então, um dia, se
transformam em algo mais substancial; por vezes despertadas por um novo acúmulo de
informações, ou por outra intuição que perdura numa outra mente, ou por uma associação
interna que finalmente completa o pensamento. Como precisam de muito tempo para se
desenvolver, essas intuições lentas são criaturas frágeis, que se perdem com facilidade em
meio às necessidades mais prementes do dia a dia. Mas esse longo período de incubação é
também a sua força, porque insights verdadeiros exigem que pensemos alguma coisa que
ninguém pensou exatamente da mesma maneira antes. Julgamentos instantâneos muitas vezes
são apenas isso – julgamentos. Esse sujeito é ou não confiável? Aquela escultura é uma
falsificação? Uma ideia nova é algo maior que isso: é uma nova maneira de considerar um
problema ou o reconhecimento de uma nova oportunidade inexplorada até aquele momento.
Descobertas desse tipo em geral levam tempo para se desenvolver. Quando o cientista do
século XVIII Joseph Priestley decidiu isolar um raminho de hortelã num vidro hermeticamente
fechado em um engenhoso experimento que provou que as plantas geravam oxigênio – uma das
descobertas que fundaram a moderna ciência dos ecossistemas –, baseavase numa intuição
cultivada por vinte anos, desde sua obsessão de infância por capturar aranhas em frascos de
vidro. Ele tivera a intuição de que havia algo de interessante no modo como os organismos
pereciam quando os isolávamos em recipientes fechados, algo que apontava para uma verdade
maior. E manteve essa intuição viva até ser capaz de lhe atribuir um significado. Não é que
tenha perseguido com obstinação uma única linha de investigação. Durante aqueles vinte anos,
Priestley se interessou por uma dúzia de áreas diferentes, inventou centenas de novos
experimentos em seu laboratório caseiro, envolveu-se em longas conversas com importantes
intelectuais da época. Uma minúscula porcentagem desse tempo foi dedicada diretamente ao
problema da respiração das plantas. Ele apenas o manteve vivo no fundo de sua mente. Manter
uma intuição lenta é menos uma questão de transpiração que de cultivo. Há que lhe dar
alimento suficiente para mantê-la crescendo e plantá-la em solo fértil, onde suas raízes
possam fazer novas conexões. Depois, basta lhe dar tempo para florescer.
AO OLHAR PARA O PASSADO, a visão turva tende a desfigurar as intuições lentas, fazendo-as
parecer momentos de estalo. Inventores, cientistas, empresários, artistas – todos gostam de
contar as histórias de suas grandes descobertas como epifanias, em parte pelo caráter
emocionante da narrativa desse momento em que uma lâmpada se acende, proporcionando
súbita iluminação, e em parte porque é mais difícil transmitir a preguiçosa evolução em
segundo plano da intuição lenta. Mas, se examinarmos com atenção os registros fósseis da
inteligência, a intuição lenta é a regra, não a exceção.
Numa passagem famosa de sua Autobiografia, Darwin descreve a grande revelação que
teve quando, ainda jovem, tentava compreender a evolução da vida.
Em outubro de 1838, isto é, quinze meses depois de começar minha investigação sistemática, li por acaso, por diversão, o
ensaio de Malthus sobre população, e, estando bem-preparado para compreender a luta pela sobrevivência que se dá em
toda parte, graças à contínua observação de animais e plantas, ocorreu-me de imediato que, sob essas circunstâncias,
variações favoráveis tenderiam a ser preservadas, e as desfavoráveis, destruídas. O resultado disso seria a formação de
novas espécies. Eu conseguira ali, por fim, uma teoria com que trabalhar.
Esta é a versão da maçã de Newton na esfera da evolução: Malthus cai da árvore, bate na
cabeça de Darwin e – voilà – nasce a seleção natural. Em parte, o atrativo dessa história de
eureca deriva da simples elegância da própria teoria. Diferentemente de descobertas
científicas de maior complexidade técnica, parece de certa maneira apropriado que o
algoritmo evolucionário básico de fato tenha pipocado na mente num momento de
reconhecimento. (Consta que o maior defensor de Darwin, T.H. Huxley, teria exclamado, ao
ouvir a tese da seleção natural pela primeira vez: “É uma incrível burrice não pensar nisso.”)
O relato de Darwin também possui uma simetria estranhamente poética, porque anos depois,
quando chegou de maneira independente à teoria da seleção natural, Alfred Russel Wallace
afirmou que sua descoberta também havia sido inspirada por Malthus.
Por quase um século, a epifania malthusiana foi a história canônica das raízes do
darwinismo. No início dos anos 1970, porém, o psicólogo e historiador das ideias Howard
Gruber decidiu reexaminar os copiosos cadernos de Darwin naquele período, reconstruindo a
complexa dança de especulação, ordenação de fatos e debate interno que conduziu à
descoberta que ele fez no outono de 1838. O que Gruber encontrou nos cadernos foi uma
história muito diferente da que Darwin conta na Autobiografia. Todos os elementos essenciais
da teoria da evolução estão presentes muito antes da epifania malthusiana, que nos cadernos
datam explicitamente de 28 de setembro de 1838. Darwin compreendia a importância da
variação; a relação entre seleção natural e artificial; a disputa pela sobrevivência entre
diferentes espécies; as claras relações fisiológicas entre espécies; a escala épica do tempo
evolucionário. Todos esses conceitos-chave são longamente discutidos nos cadernos a partir
de 1837. Não é apenas que ele possuísse as peças do quebra-cabeça mas não conseguisse
juntá-las na configuração correta. Em várias passagens notáveis, escritas muitos meses antes
do insight malthusiano, ele parecia estar descrevendo a teoria da seleção natural quase pronta
e acabada. Exatamente um ano antes de ler Malthus, ele pergunta, num inglês taquigráfico: “Se
no curso das eras cada animal produz 10 mil variedades (influenciado talvez pelas
circunstâncias) e só aquelas preservadas que são bem-adaptadas?” Para cimentar uma teoria
em construção da seleção natural, basta apenas modificar a fórmula muito ligeiramente,
esclarecendo que a preservação de formas “bem-adaptadas” decorre de seu sucesso
reprodutivo. No entanto, de certa forma Darwin não compreende que tem a solução na palma
das mãos e continua sua investigação por mais um ano antes de “conseguir uma teoria com que
trabalhar”.
Mesmo depois do insight malthusiano, Darwin parece incapaz de compreender todas as
consequências da teoria que estabeleceu. As entradas do diário no dia 28 de setembro são
adequadamente entusiasmadas e parecem de fato se engalfinhar com os elementos
fundamentais da teoria:
Povoar é aumento em razão geométrica num intervalo de tempo MUITO MAIS CURTO que 25 anos ... O motivo final de
todo esse apinhamento deve ser escolher a estrutura apropriada e adaptá-la à mudança – fazer isso pela forma, o que
Malthus mostra ser o efeito final (por meio, contudo, da volição) dessa superpopulação sobre a energia do homem. Podemos
dizer que há uma força como 100 mil cunhas tentando forçar todo tipo de estrutura adaptada para dentro das brechas da
economia da natureza, ou melhor, formando brechas ao expulsar os mais fracos.
Mas, nos dias e nas semanas que se seguem, os apontamentos de Darwin não sugerem um
espírito que transpôs um divisor de águas intelectual. Como Gruber observa, já no dia seguinte
Darwin escreve um longo verbete sobre a curiosidade sexual dos primatas que parece nada ter
a ver com sua nova descoberta. Mais de um mês se passa antes que ele tente registrar as regras
que governam a seleção natural.
Tudo isso indica que não podemos afirmar de maneira taxativa que Darwin encontrou a
ideia para sua teoria da seleção natural no dia 28 de setembro de 1838. O máximo que
podemos dizer é que ele não a possuía quando iniciou sua investigação no verão de 1837, e
que já a tinha de uma forma consolidada em novembro de 1838. Não se trata de uma questão
de lacunas no registro histórico. É difícil apontar o momento exato em que Darwin teve a ideia
simplesmente porque ela não lhe ocorreu num lampejo; penetrou em sua consciência pouco a
pouco, em ondas. Nos meses anteriores à leitura de Malthus, talvez se possa dizer que Darwin
tinha a ideia da seleção natural na mente, mas ao mesmo tempo era incapaz de pensá-la por
completo. É assim que muitas vezes intuições lentas amadurecem: de maneira sub-reptícia, em
pequenos passos. Assomam paulatinamente.
Esse padrão se repete em outra história iconográfica da jornada intelectual de Darwin: os
meses formativos que passou observando a estranha diversidade das ilhas Galápagos durante
a viagem do Beagle. Com certeza a exploração inicial dos princípios da seleção natural por
Darwin baseou-se fortemente nos impressionantes desvios que ele vira entre espécies
próximas no arquipélago de Galápagos. Não é à toa que os tentilhões de Darwin são famosos.
Mas nos cadernos preenchidos durante a exploração das ilhas em outubro de 1835 não há
quase nenhum sinal da teoria transformadora do mundo que eles iriam finalmente inspirar. Na
verdade, a maioria esmagadora das anotações de Darwin durante sua estada nas ilhas
Galápagos é de natureza geológica, muito mais preocupada com a teoria uniformitarianista de
Lyell do que com as aves e os répteis do arquipélago. (Um inventário dos cadernos encontrou
1.383 páginas de anotações geológicas contra 368 páginas sobre zoologia.) Ele fazia extensos
apontamentos à sua maneira “naturalista”, mas toda a energia especulativa dos diários do
Beagle é gerada pela geologia. Para o Darwin biólogo, os dias em Galápagos eram uma
missão de descoberta de fatos; o Darwin geólogo, porém, estava processando e interpretando
conscientemente os fatos à medida que os colhia.
Segundo seu próprio relato, Darwin só fixou de fato a atenção no intrigante enigma dos
tentilhões e seus vizinhos exóticos na primavera seguinte, no momento exato em que o Beagle
encontrava um porto seguro nas ilhas Cocos. Seu diário de 1837 inclui a frase: “Em julho abri
primeiro caderno sobre ‘Transmutação de Espécies’ – Havia ficado muito impressionado
desde o mês de março anterior com o caráter dos fósseis sul-americanos – e espécies no
arquipélago de Galápagos. Esses fatos originam (especialmente mais tarde) todas as minhas
ideias.” Ele testemunhara em primeira mão a maravilhosa diversidade de espécies em
Galápagos, documentara-a com uma precisão que nenhum ser humano ousara tentar antes. Mas
levou cinco meses para perceber por que isso era importante.
MANTER VIVA UMA INTUIÇÃO LENTA envolve desafios em múltiplas escalas. Em primeiro lugar,
temos de preservar a intuição em nossa memória, na rede densa de nossos neurônios. A maior
parte das intuições lentas nunca dura o bastante para se transformar em algo útil, porque entra
e sai de nossa memória depressa demais, justamente por apresentar certa obscuridade. Temos
a impressão de que há uma possibilidade interessante a explorar, um problema que poderia
nos levar um dia a uma solução, mas depois nos distraímos com assuntos mais prementes e a
intuição desaparece. Por isso, parte do segredo de cultivar intuições é simples: anote tudo.
Podemos rastrear a evolução das ideias de Darwin com tamanha precisão porque ele se
dedicava a uma prática rigorosa de manter cadernos em que citava outras fontes, improvisava
novas ideias, questionava e rejeitava pistas falsas, desenhava diagramas e, de maneira geral,
deixava sua mente divagar na página. Podemos acompanhar a evolução das ideias de Darwin
porque num nível básico a plataforma do caderno cria um espaço de cultivo para suas
intuições. Não que o caderno fosse uma mera transcrição das ideias que aconteciam em algum
lugar nos bastidores de sua mente. Ele estava sempre relendo suas anotações, descobrindo
novas implicações. Suas ideias se formam como uma espécie de dueto entre o cérebro
pensante do presente e todas aquelas observações passadas registradas no papel. Em algum
lugar no meio do oceano Índico, uma cadeia de associações o compele a reexaminar o que
anotara sobre a fauna do arquipélago de Galápagos cinco meses antes. E, quando ele lê suas
observações, começa a ganhar forma em sua mente um novo pensamento que provoca toda uma
nova série de anotações que só farão pleno sentido dois anos depois, a partir do episódio de
Malthus.
Os cadernos de Darwin situam-se na extremidade de uma longa e frutífera tradição que
chegou ao auge na Europa na era do Iluminismo, em particular na Inglaterra: o costume de
manter um livro de “citações”. Eruditos, cientistas amadores, aspirantes a homens de letras –
praticamente todas as pessoas com ambição intelectual nos séculos XVII e XVIII tinham um
livro de citações. As grandes cabeças do período – Milton, Bacon, Locke – eram entusiastas
dos poderes desses livros para avivar a memória. Em sua forma mais comum, a prática
envolvia a transcrição de passagens interessantes ou inspiradoras das obras lidas, reunindo
uma enciclopédia personalizada de citações. Há um nítido caráter de autoajuda nas primeiras
descrições das virtudes desses livros: mantê-los permitia à pessoa “armazenar um fundo de
conhecimento, a partir do qual poderá selecionar a qualquer momento o que for útil nas várias
atividades da vida”.
John Locke começou a usar um livro de citações em 1652, o primeiro ano que passou em
Oxford. Ao longo da década seguinte, ele desenvolveu e aprimorou um sistema elaborado para
indexar o conteúdo do livro. Locke julgou seu método importante o suficiente para inseri-lo
como apêndice a uma impressão de sua obra canônica, Ensaio sobre o entendimento humano.
A abordagem que propõe é de uma complicação quase cômica, mas era uma resposta a um
conjunto específico de requisitos: criar um índice funcional em apenas duas páginas, que
pudesse ser expandido à medida que o livro acumulasse mais citações e comentários.
Quando encontro algo que me parece apropriado pôr em meu livro de citações, penso primeiro num tópico adequado.
Suponhamos, por exemplo, que o tópico seja EPÍSTOLA. Procuro no índice pela primeira letra e pela vogal seguinte, que
nesse caso são E.i.; se no espaço marcado E.i. houver algum número que me dirija para a página destinada a palavras que
comecem com E e cuja primeira vogal após a letra inicial seja I, devo então escrever nessa página, sob a palavra Epístola, o
que tenho a comentar.
O método de Locke tornou-se tão popular que um século mais tarde John Bell, um editor
arrojado, publicou um caderno intitulado Bell’s Common-Place Book, Formed Generally
upon the Principles Recommended and Practised by Mr Locke. O livro incluía oito páginas
de instruções sobre o método de indexação de Locke, um sistema que não só tornava mais
fácil encontrar passagens, como também servia ao propósito mais elevado de “facilitar o
pensamento reflexivo”. O volume de Bell seria a base para um dos livros de citações mais
famosos do final do século XVIII, mantido de 1776 a 1787 por Erasmus Darwin, avô de
Darwin. Bem no fim de sua vida, quando trabalhava numa biografia do avô, Charles obteve do
primo Reginald o que chamava de “o grande livro”. Na biografia, o Darwin mais jovem capta
a maravilhosa diversidade do livro: “Há projetos e esboços para uma lâmpada aperfeiçoada,
como as ‘lâmpadas moderadoras’a atuais; castiçais com suportes de telescópio para serem
erguidos à vontade até qualquer altura desejada; uma espécie de papel-carbono; um tear para
tricotar meias; uma balança; uma máquina topográfica; uma ave voadora, com um engenhoso
escapamento para o movimento das asas; e ele sugere o uso de pólvora ou ar comprimido
como força motora.”
A tradição do livro de citações encerra uma tensão central entre ordem e caos, entre o
desejo de arranjo metódico e o de surpreender novos elos de associação. Para alguns
defensores do Iluminismo, a indexação sistemática do livro de citações tornou-se uma
metáfora do que as pessoas aspiravam para a própria vida mental. O pregador dissidente John
Mason escreveu em 1745:
Não considere suficiente abastecer esse Depósito da Mente com bons Pensamentos, mas armazene-os ali em Ordem,
sumariados ou organizados sob Assuntos ou Classes adequados. Que qualquer Assunto sobre o qual você tenha Ocasião de
pensar ou falar possa se valer imediatamente de um bom Pensamento, que você armazenou ali sob aquele Assunto. De
modo que a mera Menção dele possa pôr o Pensamento ao alcance; assim você carregará um Livro de Citações completo
na Memória.
Outros, entre os quais Priestley e ambos os Darwin, usavam seus livros de citações para
registrar uma vasta miscelânea de intuições. O historiador Robert Darnton descreve essa
confusa mistura de escrita e leitura:
Diferentemente dos leitores modernos, que seguem o fluxo de uma narrativa do começo ao fim, os ingleses do início da
Idade Moderna liam aos trancos e barrancos e pulavam de um livro para outro. Eles quebravam textos em fragmentos e os
reuniam em novas configurações, transcrevendo-os em diferentes seções de seus livros de citações. Depois reliam as cópias
e rearranjavam as configurações, acrescentando mais trechos. Ler e escrever eram, portanto, atividades inseparáveis. Elas
pertenciam a um esforço contínuo para interpretar as coisas, pois o mundo estava cheio de sinais: era possível orientar-se
nele pela leitura; e, ao manter um registro de suas leituras, as pessoas podiam fazer seu próprio livro, estampado com sua
personalidade.
Cada releitura do livro de citações torna-se um novo tipo de revelação. Vemos os caminhos
evolutivos de todas as nossas intuições passadas: as que se revelaram pistas falsas; as que se
revelaram óbvias demais para ser escritas; até aquelas que se transformaram em livros
inteiros. Mas cada encontro encerra a promessa de que alguma intuição há muito esquecida se
conectará de uma nova maneira com alguma obsessão emergente. A beleza do arranjo de
Locke estava em proporcionar a ordem suficiente para podermos encontrar fragmentos quando
os procuramos, mas ao mesmo tempo permitia ao corpo principal do livro de citações ter seus
próprios meandros indisciplinados, não planejados. Impor ordem demais é correr o risco de
deixar uma intuição promissora órfã num projeto mais amplo que morreu, e torna difícil para
essas ideias misturarem-se e procriarem quando as revisitamos. Precisamos de um sistema
para capturar intuições, mas não necessariamente categorizá-las, porque categorias podem
erigir barreiras entre ideias díspares, restringi-las às suas próprias ilhas conceituais. Esta é
uma das maneiras pelas quais a história humana da inovação desvia-se da história natural.
Novas ideias não florescem em arquipélagos.
NA HISTÓRIA BIBLIOGRÁFICA da miscelânea épica, outro título inglês merece menção, ao lado
do livro de citações de Erasmus Darwin: um guia vitoriano de conselhos práticos bastante
popular com o título memorável Enquire Within upon Everything [algo como “Informe-se
aqui sobre tudo”]. O texto que se lia na folha de rosto do livro, publicado pela primeira vez
em 1865, insinua o imenso acúmulo de recursos domésticos que continha:
Quer você deseje modelar uma flor em cera; estudar as regras da etiqueta; servir um aperitivo para o desjejum ou a ceia;
preparar uma deliciosa entrée para a mesa de jantar; planejar um jantar para um grupo grande ou pequeno; curar uma dor
de cabeça; fazer um testamento; casar-se; sepultar um parente; ficarei feliz em ajudá-lo em qualquer coisa que você queira
fazer, promover ou desfrutar, contanto que seu desejo tenha relação com as necessidades da vida doméstica; por isso espero
que não deixe de se informar aqui. – O editor.
Foram publicadas mais de cem edições desse guia, que permaneceu um item muito comum
nos lares britânicos até boa parte do século XX. Um exemplar mofado da obra subsistiu até os
anos 1960 na casa de um casal de matemáticos que morava num subúrbio de Londres. Eles
tinham um filho que se sentiu atraído pela “sugestão de magia” presente no título do livro e
passava horas explorando esse “portal para o mundo da informação”. O título ficou gravado
no fundo da sua mente, junto com a maravilhosa sensação de explorar um imenso tesouro de
dados. Mais de uma década depois, quando trabalhava como consultor de software num
laboratório de pesquisa suíço, ele se viu esmagado pelo fluxo de informação e pela
rotatividade do pessoal na organização. Como projeto paralelo, começou a brincar com a
montagem de um aplicativo que lhe permitiria acompanhar todos esses dados. Na hora de dar
nome ao programa, sua mente recuou até a curiosa enciclopédia doméstica vitoriana da sua
infância. Batizou seu aplicativo de Enquire.
O programa permitia ao usuário armazenar pequenos blocos de informação sobre pessoas
ou projetos como nós numa rede conectada. Era fácil fixar ponteiros bidirecionais entre os
nós, de modo que se o usuário clicasse no nome de uma pessoa, poderia ver num instante
todos os projetos em que ela estava trabalhando. O aplicativo provou-se verdadeiramente
informativo, mas o programador logo mudou de função e abandonou o código. Passados alguns
anos, ele deu início a uma nova versão, que chamou de Tangle, mas ela nunca decolou. Um
belo dia, porém, quase dez anos depois de ter programado o Enquire, ele começou a esboçar
um aplicativo mais ambicioso, capaz de estabelecer conexões entre documentos armazenados
em diferentes computadores, usando links de hipertexto. Durante algum tempo, andou à cata do
nome certo para essa plataforma nascente, chamando-a de “mina” ou “malha” de informações.
Finalmente descobriu uma metáfora diferente para a rede densa da plataforma. Batizou-a de
World Wide Web.
Em seu próprio relato das origens da web, Tim Berners-Lee não tenta condensar a
evolução de sua maravilhosa ideia numa única epifania. A web nasceu como uma intuição
lenta arquetípica: da exploração de uma enciclopédia centenária por uma criança, passando
pelo projeto paralelo de um freelance ocioso para ajudá-lo a acompanhar as atividades dos
colegas, até a tentativa deliberada de montar uma nova plataforma de informação que pudesse
conectar computadores ao redor de todo o planeta. Como a grande compreensão de Darwin da
rede emaranhada da vida, a ideia de Berners-Lee precisou de tempo – pelo menos uma década
para amadurecer:
Os jornalistas sempre me perguntam qual foi a ideia decisiva, ou o evento singular, que permitiu à web nascer um belo dia.
Ficam frustrados quando lhes digo que não houve nenhum momento “Eureca!” ... A invenção da World Wide Web envolveu
minha crescente compreensão de que havia um grande poder em se organizar ideias de maneira livre, como uma teia. E
essa percepção me chegou aos poucos, precisamente através desse tipo de processo. A web surgiu como resposta a um
desafio em aberto, por meio da mistura de influências, ideias e descobertas vindas de muitos lados, até que, graças aos
extraordinários ofícios da mente humana, um novo conceito ganhou forma. Foi um processo de acréscimo, não a solução
linear de um problema após outro.
O desenvolvimento lento, por acréscimo, da web de Berners-Lee nos leva à escala de
inovação seguinte. O cultivo de intuições estende-se para além do domínio privado da
memória e do livro de citações. Muitas pessoas não podem se dar ao mesmo luxo que Darwin
e dedicar uma vida inteira a seus devaneios intelectuais. Para a maioria, ideias surgem dentro
de seus ambientes de trabalho e em torno deles, com todas as pressões, distrações e
responsabilidades cotidianas, além da constante supervisão que a vida profissional tantas
vezes envolve. Nesse aspecto, Berners-Lee teve enorme sorte no tocante ao ambiente de
trabalho em que tinha se estabelecido, o laboratório franco-suíço de física das partículas
Cern. Foram-lhe necessários dez anos para cultivar sua intuição lenta relacionada a uma
plataforma de informação em hipertexto. Ele passou a maior parte desses anos trabalhando no
Cern, mas só em 1990 – uma década depois de começar a trabalhar no Enquire – o laboratório
o autorizou oficialmente a desenvolver o projeto de hipertexto. Durante o dia, ele trabalhava
em “aquisição e controle de dados”; construir uma plataforma global de comunicação era seu
hobby. Como as duas atividades tinham alguns atributos em comum, os superiores de Berners-
Lee permitiram que tocasse o projeto paralelo ao longo dos anos. Graças a alguns grupos de
discussão na internet, ele pôde conversar com outros inovadores pioneiros do hipertexto e
assim suplementar e aprimorar suas ideias. Essa combinação de flexibilidade e conexão lhe
deu apoio crítico para sua ideia. Ele precisava de um ambiente de trabalho que lhe
proporcionasse um espaço para intuições lentas, à margem de todas as exigências imediatas
dos compromissos diários. E precisava de redes de informação que permitissem a essas
intuições propagar-se a outras mentes, nas quais poderiam ser ampliadas e aperfeiçoadas.
Se há uma antimatéria para a matéria fomentadora de intuições do Cern, poderia sem
dúvida ser o FBI no verão de 2001. Duas redes fundamentais deixaram de fazer as conexões
apropriadas nos meses que antecederam o 11 de Setembro: a rede de informações do sistema
Automated Case Support e as redes neurais nos cérebros dos principais participantes. Mesmo
em 2001, recuperar documentos com uma combinação improvável de termos – digamos, por
exemplo, “escolas de pilotagem” e “fundamentalistas islâmicos radicais” – era uma questão
rotineira; milhões de usuários do Google, criado três anos antes, faziam buscas semelhantes
pela web inteira, com resultados quase instantâneos. Se a rede de informações tivesse
sugerido de maneira automática aos funcionários da Radical Fundamentalist Unit a leitura do
memorando Phoenix depois que o escritório de Minnesota começou sua investigação sobre
Moussaoui, as últimas semanas do verão poderiam ter transcorrido de maneira muito
diferente. Mas, por mais inteligente que a própria rede fosse, ainda teria sido necessário que
uma conexão comparável se estabelecesse nas mentes dos participantes. Se David Frasca
tivesse lido o memorando que Ken Williams lhe remetera, provavelmente teria sido capaz de
conectar os dois palpites, usando a avançada tecnologia de reconhecimento de padrões que o
cérebro humano possui.
O fracasso dessas duas redes em conectar as intuições de Phoenix e de Minnesota pode ser
atribuído em parte à tecnologia de informação quase medieval empregada pelo FBI. Mesmo
que a agência tivesse milagrosamente atualizado sua rede no verão de 2001, é provável que as
duas intuições permanecessem separadas, porque a falta de conexões no sistema Automated
Case Support era um princípio do projeto, não mero resultado de tecnologia obsoleta. No
linguajar da ciência da computação, era uma característica, não um bug. A rede de
informações do FBI era uma clássica rede fechada: além de impedir que intrusos acessassem
informações nela contidas, o sistema fora projetado de modo a proteger com cuidado os
documentos de outros membros do órgão, o legado de uma instituição baseada em segredos e
na extrema restrição do acesso aos dados. O relatório final da investigação do Comitê
Judiciário sobre as falhas do serviço secreto nos meses anteriores ao 11 de Setembro citou
explicitamente esse princípio do projeto da rede de informação do FBI como um dos
principais culpados, chamando-o de “‘mentalidade de silo’, que leva ao engavetamento de
informações vitais numa unidade, impedindo que seja compartilhada com outras”.
Num sentido real, durante os meses que conduziram ao 11 de Setembro, o FBI foi um
sistema aniquilador de intuições, o que é bastante irônico, dado o papel importante que elas
desempenham na maioria das descrições – reais ou ficcionais – do trabalho de grandes
investigadores. Na cultura do FBI, o fato de um analista rotular um relatório de “especulativo”
foi suficiente para impedir que ele avançasse pela cadeia de comando, ao mesmo tempo que a
antiquada arquitetura de silo impediu que a intuição de Williams circulasse entre outros
agentes de campo que trabalhavam com base em suas próprias intuições. A visão monumental
que Berners-Lee teve no Cern foi uma rede emaranhada de dados, uma “mistura de influências,
ideias e descobertas vindas de muitos lados”. O sistema Automated Case Support não foi
apenas incompetente em promover um emaranhado criativo; havia sido explicitamente
projetado para eliminá-lo.
EM 1980, ALUDIR A Enquire Within upon Everything no nome de um pacote de software era uma
audácia e tanto; Berners-Lee só estava tentando se manter a par do que faziam seus colegas no
Cern, não pretendia organizar toda a informação do mundo. Mas “informe-se aqui...” bem
poderia ser o slogan do Google, razão pela qual é bastante apropriado que essa empresa, em
seu ambiente corporativo, tenha feito o máximo para adotar e expandir o tipo de inovação por
intuição lenta que, afinal de contas, criou a web. No início de sua história, o Google instituiu o
famoso programa “20-percent time” para todos os seus engenheiros: para cada quatro horas
que passam trabalhando em projetos oficiais da companhia, eles são obrigados a dedicar uma
hora a projetos pessoais, guiados apenas pelas próprias paixões e instintos. (Inspirado num
programa semelhante adotado em caráter pioneiro pela 3M, conhecido como “the 15-percent
rule”, o nome oficial do sistema do Google é “Innovation Time Off” [tempo livre para
inovação]). A única exigência é que forneçam informações mais ou menos regulares sobre
seus progressos aos superiores. Boa parte dos engenheiros acaba passando de uma ideia para
outra, e a vasta maioria dessas ideias nunca se transforma num produto oficial da empresa. De
vez em quando, porém, uma dessas intuições dá origem a algo significativo. O AdSense, a
plataforma que permite a blogueiros e editores da web exibir anúncios do Google em seus
sites, foi em parte gerado durante os 20% de tempo livre. Em 2009, o AdSense proporcionou
ao Google um lucro de mais de 5 bilhões de dólares, quase um terço do total da empresa no
ano. O Orkut, um dos maiores sites de rede social na Índia e no Brasil, originou-se no
Innovation Time Off de um engenheiro turco do Google chamado Orkut Büyükkökten. A
requisitada plataforma de e-mail do Google, o Gmail, também teve raízes num projeto
desenvolvido no tempo livre. Marissa Mayer, vice-presidente de Produtos de Busca e
Experiência de Usuário da empresa, afirma que mais de 50% dos novos produtos lançados
provêm de intuições desenvolvidas no Innovation Time Off.
O contraste mais significativo entre o Google e o FBI está na história de Krishna Bharat,
que hoje detém o título de “principal cientista” da empresa. Nas semanas que se seguiram ao
11 de Setembro, Bharat viu-se esmagado pela quantidade de novas informações disponíveis
sobre os ataques e a guerra iminente no Afeganistão. Ocorreu-lhe que seria útil criar um
software que pudesse organizar aquelas notícias em grupos de relevância, permitindo ver num
relance todas as últimas notícias oriundas da web sobre a procura de Bin Laden, ou sobre os
esforços para a limpeza do Ground Zero, ou sobre a defesa da retaliação militar pelo governo
Bush. Bharat decidiu usar seus 20% de tempo livre para construir um sistema chamado
StoryRank – modelado com base no algoritmo original PageRank em que o mecanismo de
busca do Google se baseia – para organizar e agrupar itens de notícia. O StoryRank floresceu,
por fim, no Google News, uma das mais populares (e controversas) fontes de notícias e
comentários na web.
Em certo sentido, a narrativa da evolução do StoryRank é a imagem especular exata da
história das vicissitudes do memorando Phoenix. Como Tim Berners-Lee, Bharat teve a sorte
de fazer parte de uma cultura organizacional que estimulava intuições e lhes dava o espaço e o
tempo de que precisavam para se desenvolver. E Bharat se apossou desse ambiente favorável
e o usou para construir uma ferramenta que pudesse reunir de maneira automática grupos de
relevância e associação entre documentos – certamente o tipo de sistema que teria ligado os
pontos entre o memorando Phoenix e a investigação de Moussaoui. Bharat intuiu que havia
uma maneira melhor de organizar a rede de notícias, e construiu o que veio a ser uma
ferramenta que poderia ser usada para ajudar intuições relacionadas a se completar umas às
outras.
O Google News foi lançado em setembro de 2002, o que significa que o StoryRank levou
um ano para passar de uma intuição na mente de Krishna Bharat a produto acabado. Nove anos
depois do 11 de Setembro, o FBI ainda estava usando o sistema Automated Case Support.
a “Moderator lamps”, tipo de lâmpada a óleo vegetal inventado por M. Franchot por volta de 1836. (N.T.)

4. Serendipidade
COMO QUALQUER OUTRO PENSAMENTO, uma intuição nada mais é que uma rede de células
acendendo-se dentro de nosso cérebro num padrão organizado. Para algo mais substancial
florescer, porém, essa rede tem de se conectar com outras ideias. Precisa de um ambiente em
que conexões surpreendentemente novas possam ser forjadas: os neurônios e sinapses do
próprio cérebro e o ambiente cultural mais amplo que o cérebro ocupa.
Durante muitos anos grassou um debate sobre a natureza dessas conexões neurais. Seriam
elas de natureza química ou elétrica? Haveria sopas químicas no cérebro, ou faíscas? A
resposta, por fim, foi: ambas as coisas. Os neurônios enviam sinais elétricos pelos longos
cabos de seus axônios, que se conectam com outros neurônios por meio de pequenas lacunas
sinápticas. Ao chegar à sinapse, a carga elétrica libera um mensageiro químico – um
neurotransmissor, como a dopamina ou a serotonina – que flutua até o neurônio receptor e
desencadeia finalmente outra carga elétrica, que viaja até outro neurônio no cérebro.
A natureza híbrida, eletroquímica, da comunicação nervosa foi estabelecida pela primeira
vez em outra das mais célebres experiências do século XX. No início dos anos 1920, o
cientista alemão Otto Loewi isolou dois corações de rã, ainda pulsando, em recipientes
separados que continham uma solução salina. Em um coração, prendeu um eletrodo no nervo
vago, que num corpo intacto começa no tronco cerebral e se estende por todo o organismo.
Como o nervo vago ajuda a regular o sistema parassimpático, sua estimulação com uma carga
elétrica diminuiu a velocidade dos batimentos cardíacos. Em seguida, Loewi retirou parte da
solução que envolvia o coração e derramou-a sobre o segundo coração. No mesmo instante
este passou a bater mais devagar também, embora seu nervo vago não tivesse sido
eletricamente estimulado. O engenhoso experimento de Loewi demonstrou que a instrução
para a desaceleração dos batimentos cardíacos havia passado através da sopa química da
solução salina. Ao estimular uma parte diferente do nervo vago da rã, ele conseguiu também
acelerar os batimentos de ambos os corações da mesma maneira. Sabemos hoje que a
estimulação elétrica estava liberando duas moléculas diferentes na sopa: a acetilcolina (que
desacelerava o coração) e a adrenalina (que o acelerava).
Por mais influente que tenha sido, o experimento de Loewi é lembrado hoje igualmente pela
maneira curiosa como ele o concebeu. A ideia lhe veio num sonho – em dois sonhos, para ser
exato:
Na noite anterior ao domingo da Páscoa daquele ano, acordei, acendi a luz e fiz algumas anotações numa tirinha de papel
fino. Depois voltei a dormir. Às seis horas da manhã, eu me lembrei de que escrevera algo de extrema importância, mas não
consegui decifrar meus rabiscos. Na noite seguinte, às três horas, a ideia voltou. Era o projeto de um experimento para
determinar se a hipótese da transmissão química que eu formulara dezessete anos antes estava correta. Levantei-me no
mesmo instante, fui para o laboratório e realizei um experimento simples com um coração de rã, de acordo com o projeto
noturno.
Costumamos associar a inspiração onírica às artes criativas, mas o cânone das grandes
descobertas científicas contém muitas ideias revolucionárias que se originaram em sonhos. O
cientista russo Dmitri Mendeleev criou a tabela periódica dos elementos depois que um sonho
lhe sugeriu que ela poderia ser ordenada por peso atômico. Foi num sonho, em 1947, que o
ganhador do prêmio Nobel John Carew Eccles concebeu sua teoria da ação inibitória
sináptica, que ajudou a explicar como neurônios conectados podem entrar em atividade sem
desencadear uma cascata interminável de trabalho cerebral. De maneira curiosa, a intuição
inicial de Eccles envolvia um sistema puramente elétrico, mas experimentos posteriores
provaram que a substância química GABA era central para a inibição sináptica, fazendo-o ir
ao encontro do experimento realizado décadas antes por Loewi.
Não há nada de místico no papel dos sonhos na descoberta científica. Embora a atividade
onírica continue sendo um terreno fértil para pesquisas, sabemos que, durante o sono REM,
células do tronco cerebral que liberam acetilcolina se excitam de forma indiscriminada,
enviando ondas crescentes de eletricidade através do cérebro. Lembranças e associações são
desencadeadas de maneira caótica, semialeatória, gerando a característica alucinatória dos
sonhos. A maior parte dessas conexões neuronais é desprovida de sentido, mas por vezes o
cérebro topa no sonho com um elo valioso que escapara à consciência em vigília. Nesse
sentido, Freud compreendeu a coisa ao contrário com sua noção de interpretação dos sonhos:
o sonho não está revelando de algum modo uma verdade reprimida. O que ele faz é explorar,
tentando encontrar novas verdades por meio da experimentação com novas combinações de
neurônios.
Um experimento recente conduzido pelo neurocientista alemão Ullrich Wagner demonstra o
potencial que os estados oníricos têm de desencadear novos insights conceituais. Sujeitos
experimentais receberam uma tarefa matemática entediante que envolvia a transformação
repetitiva de oito dígitos num número diferente. Com a prática, eles ficavam cada vez mais
eficientes no desempenho da tarefa. Mas havia um padrão oculto no enigma de Wagner, uma
regra que governava as transformações numéricas. Uma vez descoberto, esse padrão permitia
aos sujeitos completar a tarefa muito mais depressa, mais ou menos como nossa atividade
aumenta rapidamente quando estamos prestes a completar um quebra-cabeça, e todas as peças
se encaixam de repente. Wagner descobriu que, após uma exposição inicial ao teste numérico,
“consultar o travesseiro” numa noite de sono mais do dobrava a capacidade dos participantes
de descobrir a regra oculta. As recombinações mentais do sono ajudavam a explorar toda a
gama de soluções para o enigma, detectando padrões que haviam escapado à percepção no
período inicial de treino. O trabalho do sonho mostra-se uma maneira particularmente caótica,
mas produtiva, de explorar o possível adjacente.
Em certo sentido, os sonhos são a sopa primordial da mente: o meio que facilita as colisões
serendipitosas do insight criativo. E as intuições se assemelham àqueles primeiros átomos de
carbono, buscando novos tipos de conexões para ajudá-los a formar novas cadeias e anéis de
inovação. O sonho de Loewi, do experimento do coração de rã, é muitas vezes evocado como
um caso de súbita epifania – uma versão do século XX da maçã de Newton –, mas na verdade
ele vinha matutando havia dezessete anos sobre a possibilidade de haver uma comunicação
química entre os neurônios. Em parte, sua epifania foi possibilitada pelas conexões aleatórias
do sono REM, mas em parte ocorreu graças à intuição lenta que subsistira no fundo de sua
mente por quase duas décadas.
Esse padrão da consolidação de uma intuição lenta numa epifania inspirada por um sonho
se repete no que talvez seja o devaneio mais famoso da história da ciência. Em 1865,
sonhando acordado junto a um fogo crepitante, o químico alemão Friedrich August Kekulé von
Stradonitz teve uma visão do Uróboro, a serpente da mitologia grega que devora a própria
cauda. Kekulé havia passado os dez anos anteriores de sua vida explorando as ligações de
moléculas baseadas no carbono. A imagem da serpente no devaneio deu-lhe uma súbita
apreensão da estrutura molecular do hidrocarboneto benzeno. A molécula de benzeno, ele
percebeu, era um anel de carbono perfeito, com átomos de hidrogênio circundando suas
bordas externas. A intuição lenta de Kekulé havia armado o palco para o insight, mas para que
essa intuição se tornasse uma ideia transformadora do mundo, ele precisava da mais
improvável das conexões: uma imagem icônica da mitologia antiga. E a visão de Kekulé
provou-se de fato uma descoberta de proporções épicas: a estrutura de anel da molécula de
benzeno tornou-se a base para uma revolução na química orgânica, abrindo uma nova
perspectiva da fascinante série de anéis, treliças e cadeias formada pelo mais conectivo de
todos os elementos, o carbono. Foi necessária a serendipidade combinatória de um devaneio –
todos aqueles neurônios acendendo-se em novas e improváveis configurações – para nos
ajudar a entender o poder combinatório do carbono, o qual, por sua vez, foi crucial para a
compreensão das inovações originais da própria vida.
O CÉREBRO ACORDADO também tem apetite para o caos produtivo que reina no estado onírico.
Os neurônios compartilham informações transmitindo substâncias químicas através da lacuna
sináptica que os conecta, mas se comunicam também por meio de um canal mais indireto:
sincronizam os ritmos em que se excitam. Por razões ainda não inteiramente compreendidas,
grandes agrupamentos de neurônios passam a se excitar regularmente na mesma frequência
exata. (Imagine uma banda de jazz dissonante, cada membro seguindo uma indicação de
compasso e um tempo diferentes, que de súbito começa a tocar uma valsa a precisas 120
batidas por minuto.) É isso que os neurocientistas chamam de phase-locking, o qual é
caracterizado por uma espécie de bela sincronia – milhões de neurônios pulsando num ritmo
perfeito. Mas o cérebro também parece precisar do oposto: períodos regulares de caos
elétrico, nos quais os neurônios estão em total falta de sincronia entre si. Quando
acompanhamos as várias frequências da atividade elétrica cerebral por meio de um
eletroencefalograma, obtemos um efeito semelhante ao de girar o dial num rádio AM:
períodos de padrões estruturados, rítmicos, interrompidos por estática e ruído. Os sistemas do
cérebro são “sintonizados” para ruído, mas só em rajadas controladas.
Em 2007, Robert Thatcher, um neurocientista da University of South Florida, decidiu
estudar a variação entre sincronia de fase e ruído nos cérebros de dezenas de crianças.
Embora tenha constatado que os períodos de ruído duravam, em média, 55 milissegundos, ele
também detectou uma variação estatisticamente significativa entre as crianças. Alguns
cérebros tendiam a ficar mais tempo em sincronia de fase [phase-locking], outros tinham
intervalos de ruído que se aproximavam sempre de sessenta milissegundos. Ao comparar os
resultados referentes às ondas cerebrais com o QI das crianças, Thatcher encontrou uma
correlação direta entre os dois conjuntos de dados. Cada milissegundo extra passado no modo
caótico acrescentava nada menos que vinte pontos aos QIs dessas crianças. Intervalos mais
longos em sincronia de fase subtraíam pontos de QI, embora de maneira menos acentuada.
O estudo de Thatcher sugere uma noção contrária à do senso comum: quanto mais
desorganizado for o seu cérebro, mais inteligente você será. Isso contraria o senso comum em
parte porque tendemos a atribuir à crescente inteligência do mundo tecnológico uma
coreografia eletromecânica cada vez mais precisa. A Intel não anuncia seus últimos
microprocessadores com o slogan “A cada 55 milissegundos, nossos chips irrompem numa
torrente de ruído!”. No entanto, de alguma maneira os cérebros que buscam esse ruído
parecem prosperar, pelo menos pela medida do teste de QI.
A ciência ainda não tem uma explicação consistente para os estados de caos do cérebro,
mas Thatcher e outros pesquisadores acreditam que o ruído elétrico do modo de caos permite
ao cérebro fazer experiências com novas ligações entre neurônios que não se conectariam em
cenários mais ordenados. O modo de sincronia de fase (segundo a teoria) é aquele em que o
cérebro executa um plano ou hábito estabelecido, enquanto o modo de caos é aquele em que
ele assimila novas informações e explora estratégias para responder a situações alteradas.
Nesse sentido, o modo de caos é uma espécie de devaneio em segundo plano: uma camada de
ruído que torna novas conexões possíveis. Verificou-se que até nas horas de vigília nosso
cérebro gravita para o ruído e o caos do sonho, por 55 milissegundos de cada vez.
Escrevendo no final dos anos 1880, William James não tinha meios para medir a excitação
sincronizada de neurônios, mas sua descrição da “ordem mais elevada das mentes” capta algo
do modo de caos:
Em vez de pensamentos de coisas concretas seguindo-se pacientemente uns aos outros, temos os mais abruptos atalhos e
transições de uma ideia para outra, as mais refinadas abstrações e distinções, as mais inauditas combinações de elementos
... um caldeirão fervilhante de ideias, em que tudo está chiando e se agitando num estado de desnorteante atividade, em que
parcerias podem ser estabelecidas ou rompidas num instante, a rotina monótona é desconhecida e o inesperado parece ser a
única lei.
O ATO DE REPRODUÇÃO SEXUAL é ele próprio uma espécie de atestado do poder das conexões
aleatórias, até nas relações mais monogâmicas. A esmagadora maioria dos seres vivos não
microscópicos na Terra gera descendentes compartilhando genes com outro organismo. Mas a
evolução dessa estratégia reprodutiva permanece um tanto misteriosa. Teria sido muito mais
fácil para a vida evitar as complicadas trocas genéticas da meiose e da fertilização. (Pense no
elaborado sistema que as plantas floríferas tiveram de desenvolver, atraindo insetos para
assumir a tarefa de carregar pólen de uma flor para outra.) A reprodução sem sexo é uma
simples questão de clonagem: você toma suas próprias células, copia-as e passa isso para
seus descendentes. Não soa muito divertido aos nossos ouvidos mamíferos, mas essa
estratégia funcionou muito bem por bilhões de anos para as bactérias. A reprodução assexual é
mais rápida e demanda menos energia que a sexual: não é preciso se dar o trabalho de
encontrar um parceiro para criar a próxima geração.
Se a seleção natural recompensasse os organismos apenas pela pura capacidade
reprodutiva, a reprodução sexual talvez nunca tivesse se desenvolvido. Organismos
assexuados se reproduzem em média de maneira duas vezes mais rápida que os sexuados, em
parte porque, sem uma distinção macho/fêmea, todo organismo é capaz de gerar prole por si
só. Mas a evolução não é apenas um jogo de quantidade. A superpopulação, afinal, gera seus
problemas, e uma comunidade de organismos com DNA idêntico constitui um alvo perfeito
para parasitas e predadores. Por essas razões, a seleção natural também recompensa a
inovação, a tendência da vida de descobrir novos nichos ecológicos, novas fontes de energia.
Foi isso que Stuart Kauffman reconheceu quando formulou pela primeira vez a ideia do
possível adjacente: que a biosfera tem algo como uma tendência essencial a se diversificar em
novas maneiras de subsistir. Misturar dois conjuntos distintos de DNA a cada geração
resultava numa estratégia reprodutiva muito mais complexa, mas muito vantajosa quanto à taxa
de inovação. O que perdemos em velocidade e simplicidade ganhamos em criatividade.
A pulga-d’água, Daphnia, vive em muitas lagoas de água doce e pântanos. Seus
movimentos espasmódicos na água são responsáveis pelo nome “pulga”, mas na realidade
Daphnia é um pequenino crustáceo, com poucos milímetros de comprimento. Em condições
normais, a espécie se reproduz de maneira assexuada, com as fêmeas produzindo uma ninhada
de cópias idênticas de si mesmas numa minúscula bolsa. Nessa modalidade, a comunidade de
Daphnia compõe-se inteiramente de fêmeas. Tal estratégia reprodutiva alcança assombroso
sucesso: nos meses quentes de verão, Daphnia é muitas vezes um dos organismos mais
abundantes no ecossistema de uma lagoa. Mas quando as condições ficam severas, e secas ou
outros distúrbios ecológicos ocorrem, ou quando o inverno chega, as pulgas-d’água fazem uma
notável transformação: começam a produzir machos e passam a se reproduzir sexualmente.
Parte dessa mudança pode ser atribuída aos ovos mais robustos produzidos por reprodução
sexual, que têm mais chances de sobreviver aos longos meses de inverno. Os cientistas
acreditam, entretanto, que a súbita adoção do sexo é também uma espécie de estratégia de
inovação biológica: em tempos difíceis, um organismo precisa de novas ideias para fazer face
aos desafios. A reprodução assexual faz pleno sentido durante períodos prósperos: se a vida
está boa, continue fazendo a mesma coisa. Não interfira no sucesso introduzindo novas
combinações genéticas. Porém, quando o mundo se torna mais desafiador – com recursos
escassos, predadores, parasitas –, é preciso inovar. E o caminho mais curto para a inovação é
estabelecer novas conexões. Essa estratégia de alternar entre a reprodução sexual e a assexual
recebe o nome de “heterogenia”, e, embora não seja comum, muitos diferentes organismos a
adotaram. Fungos, algas e pulgões, todos desenvolveram estratégias reprodutivas
heterogênicas. Em cada organismo, o padrão de Daphnia se repete: as recombinações
genéticas do sexo emergem quando as condições ficam difíceis. Trocar genes com outro
organismo é mais difícil que a simples clonagem, mas as recompensas do sexo em termos de
inovação superam seus riscos. Quando a natureza se vê necessitada de novas ideias, ela se
esforça para conectar, não para proteger.
A LÍNGUA INGLESA é abençoada com uma palavra maravilhosa que exprime o poder da conexão
acidental: “serendipity”. Cunhada pelo romancista inglês Horace Walpole em uma carta
escrita em 1754, a palavra provém de um conto de fadas persa intitulado “Os três príncipes de
Serendip”, cujos protagonistas estavam “sempre a descobrir, por acidente e sagacidade,
coisas que não procuravam”. O romancista contemporâneo John Barth descreve isso em
termos náuticos: “Você não chega a Serendip traçando um caminho para lá. Tem de partir com
convicção para outro lugar e perder o rumo serendipitosamente.”
Mas a serendipidade não é apenas uma questão de abraçar encontros fortuitos por puro
deleite. Ela é feita de felizes coincidências, sem dúvida, porém o que as torna felizes é o fato
de a descoberta ser significativa para quem a fez. A serendipidade completa uma intuição ou
abre uma porta para o possível adjacente que não havíamos percebido. Se um geólogo está
explorando a web ao acaso, e a ilha de Serendip em particular com que depara é um ensaio
sobre a reforma do sistema de saúde, essa descoberta poderá lhe parecer interessante e
informativa, mas não será de fato serendipitosa, a menos que o ajude a encaixar uma peça num
enigma sobre o qual vinha se debruçando. Isso não significa que geólogos só possam fazer
descobertas serendipitosas em textos de geologia – na verdade, muito pelo contrário.
Descobertas serendipitosas muitas vezes envolvem trocas entre as disciplinas tradicionais.
Pense no modo como a serpente mítica de Kekulé levou a uma revolução na química orgânica.
Foi verdadeiramente serendipitoso que seu cérebro adormecido evocasse a imagem do
Uróboro naquele momento. Mas, se ele não tivesse passado anos se engalfinhando com a
estrutura da molécula de benzeno, a forma da serpente poderia não ter despertado nenhuma
associação útil em sua mente. (Por vezes, como diria Freud, uma serpente engolindo a própria
cauda é apenas uma serpente engolindo a própria cauda.) A serendipidade requer colisões e
descobertas improváveis, mas também algo em que ancorá-las. Caso contrário, nossas ideias
são como átomos de carbono a colidir a esmo uns com os outros na sopa primordial, sem
jamais formar os anéis e treliças da vida orgânica.
O desafio, claro, é saber como criar ambientes que fomentem conexões serendipitosas em
todas as escalas apropriadas: no espaço privado de nossa mente; no âmbito de instituições
mais amplas; e através das redes de informação da própria sociedade.
À primeira vista, a ideia de provocar descobertas serendipitosas em nossa própria mente
parece uma contradição em termos. Não seria algo como nos perdermos na nossa própria
garagem? Ainda assim, era exatamente isso que Kekulé fazia ao pé do fogo. Ele estava
conectando dois pensamentos distintos, cada um dos quais ocupava um escaninho em seus
bancos de memória: o enigma da estrutura molecular do benzeno e o Uróboro que devora a
própria cauda. A verdade é que nossa mente contém um número quase infinito de ideias e
memórias que a qualquer momento se esconde de nossa consciência. Uma pequenina fração
desses pensamentos é como a serpente de Kekulé: compõe-se de conexões surpreendentes que
poderiam nos ajudar a abrir uma porta no possível adjacente. Mas como levar esses
aglomerados particulares de neurônios a se acender no momento certo?
Uma maneira é sair para dar uma volta. A história da inovação está repleta de relatos sobre
boas ideias que ocorreram quando as pessoas estavam fazendo um passeio. (Um fenômeno
semelhante acontece quando passamos um longo tempo debaixo do chuveiro ou mergulhados
numa banheira; na verdade, o momento “eureca” original – quando Arquimedes atinou com
uma maneira de medir o volume de formas irregulares – ocorreu numa banheira.) O banho ou o
passeio nos tiram do foco centrado em tarefas da vida moderna – pagar contas, responder a e-
mails, ajudar as crianças com o dever de casa – e nos inserem num estado mais associativo.
Se nos for dado tempo suficiente, nossa mente irá deparar muitas vezes com alguma velha
conexão que não notávamos havia muito, proporcionando aquela deliciosa sensação de
serendipidade íntima: por que não pensei nisso antes?
Em Science and Method, o matemático e físico francês Henri Poincaré dedica um capítulo
autobiográfico à questão da criatividade matemática. O texto tem início com uma descrição
detalhada de como Poincaré descobriu a classe das funções de Fuchs, um dos primeiros
conceitos matemáticos influentes de sua carreira. Ele começou tentando provar que essas
funções não existiam; durante quinze dias lutou sem sucesso à sua escrivaninha. Depois, certa
noite, contrariando seus hábitos, tomou café preto. Incapaz de dormir, viu sua mente fervilhar
com intuições promissoras. “Ideias surgiram em abundância”, escreveu. “Senti que se
entrechocavam, até que pares se entrelaçaram, por assim dizer, formando uma combinação
estável. Na manhã seguinte, eu havia estabelecido a existência de uma classe de funções de
Fuchs, aquelas que derivam da série hipergeométrica.” Seu insight seguinte – uma conexão
entre essas funções e a geometria não euclidiana – ocorreu várias semanas depois, quando
viajava de ônibus em uma expedição geológica na Normandia. Ao voltar para casa, começou a
trabalhar numa questão aritmética não relacionada e se atrapalhou durante vários dias.
“Aborrecido com meu fracasso”, escreveu ele, “fui passar alguns dias à beira-mar e pensar
em outra coisa. Uma manhã, caminhando sobre um penhasco, ocorreu-me a ideia, com
exatamente as mesmas características de brevidade, instantaneidade e certeza imediata, de que
as transformações aritméticas de formas quadráticas ternárias indeterminadas eram idênticas
àquelas da geometria não euclidiana.” Mais uma vez, Poincaré voltou para casa e se dedicou
às implicações desse achado, mas deparou com um novo obstáculo. Por imposição do serviço
militar, teve de viajar para o Fort Mont-Valérien, nos subúrbios de Paris, onde quase não teve
tempo para dedicar alguma reflexão à matemática. Isso não o impediu, contudo, de encontrar a
última peça que faltava. “Um dia, andando pela rua, a solução para a dificuldade que havia me
detido apareceu de repente. Não tentei aprofundá-la de imediato, e só retomei a questão após
concluir meu serviço. Eu tinha todos os elementos e precisava apenas organizá-los e reuni-los.
Assim escrevi minha dissertação de um só golpe e sem dificuldade.”
Esse relato de Poincaré talvez seja a anedota mais “prosaica” sobre criatividade científica
de que se tem notícia. Sempre que ele se senta à sua mesa, as inovações parecem se estancar.
Quando se levanta, as ideias “surgem em abundância”. Para tentar explicar o fenômeno, ele
recorre a uma metáfora atômica, em que cada ideia parcial ou intuição é representada por um
átomo colado a uma parede. Em situações normais, os átomos permanecem no lugar, presos
numa configuração estável. Quando a mente divaga, porém (e, no caso de Poincaré, quando
seu corpo físico divaga), os átomos se desprendem. “Durante um período de aparente repouso
e trabalho inconsciente, alguns deles de desprendem da parede e se põem em movimento.
Movem-se como coriscos em todas as direções através do espaço ... no qual estão
encerrados, como o faria, por exemplo, uma nuvem de mosquitos ou, se preferirem uma
analogia mais culta, como o fariam as moléculas de gás na teoria cinética dos gases. Assim,
suas colisões mútuas podem produzir novas combinações.”
Embora o passeio criativo ajude a gerar novas combinações serendipitosas de ideias já
existentes em nossas mentes, podemos também cultivar a serendipidade no modo como
absorvemos ideias do mundo exterior. Os livros continuam sendo um veículo insuperável para
a transmissão de novas ideias e perspectivas interessantes. Mas aqueles que não são
acadêmicos ou não estão envolvidos no mercado editorial só conseguem encontrar tempo para
os livros fora do horário de trabalho: ouvindo um audiolivro no carro a caminho do escritório
ou devorando um capítulo depois que as crianças dormem. O problema com a assimilação de
novas ideias nas franjas da rotina diária é que as combinações potenciais são limitadas pelo
alcance de sua memória. Se você leva duas semanas para terminar um livro, quando chega ao
livro seguinte já esqueceu muito do que havia de tão interessante ou provocativo no primeiro.
Podemos mergulhar na perspectiva de um único autor, mas nesse caso é mais difícil criar
colisões serendipitosas entre as ideias de múltiplos autores. Uma maneira de contornar essa
limitação é estabelecer períodos especiais para a leitura de uma grande e variada série de
livros e ensaios num intervalo restrito de tempo. Bill Gates (e seu sucessor na Microsoft, Ray
Ozzie) são famosos por tirar férias anuais dedicadas à leitura. Durante o ano, acumulam
deliberadamente uma pilha de material de leitura – grande parte sem relação com seu foco
diário na Microsoft –; depois se afastam por uma ou duas semanas e mergulham a fundo nos
textos que acumularam. Ao concentrar sua absorção em poucos dias, dão a novas ideias
oportunidades adicionais de se conectar entre si, pela simples razão de que é mais fácil nos
lembrar de algo que lemos ontem que de algo que lemos seis meses atrás.
Na linguagem de Poincaré, o mergulho profundo, como a longa caminhada, desprende os
átomos das paredes e os põe em movimento. A maioria de nós não pode se dar ao luxo de tirar
férias sabáticas para mergulhar na leitura; e nem todo mundo acha que ler alguns milhares de
páginas corresponde à ideia de férias divertidas. Mas não há razão para que as organizações
não reconheçam o valor de períodos sabáticos destinados à leitura, assim como muitas
estimulam os empregados a se afastar do trabalho para aprender novas habilidades. Se o
Google dá a seus engenheiros um dia por semana para trabalhar no que bem entenderem, sem
dúvida outras organizações podem descobrir uma maneira de dar a seus empregados um tempo
exclusivo para mergulhar numa rede de novas ideias.
A SERENDIPIDADE PRIVADA pode ser cultivada também por meio da tecnologia. Há mais de uma
década, venho organizando um arquivo digital de citações que me pareceram intrigantes,
minha versão do século XXI do livro de citações. Algumas dessas passagens envolvem
pesquisa muito focada num projeto específico; outras são descobertas mais aleatórias,
intuições à espera de uma conexão. Algumas são passagens que transcrevi de livros ou artigos;
outras foram pinçadas diretamente de páginas da web. (Nos últimos anos, graças ao Google
Books e ao Kindle, copiar e armazenar citações interessantes de um livro tornou-se muito
mais simples.) Mantenho todas essas citações num banco de dados usando um programa
chamado DEVONthink, onde guardo também meus próprios escritos: capítulos, ensaios, posts
publicados em blogs, anotações. Pela combinação de minhas próprias palavras com passagens
de outras fontes, a coleção se torna algo mais que um mero sistema de armazenagem de
arquivos. Passa a ser uma extensão digital de minha memória imperfeita, um arquivo de todas
as minhas velhas ideias e das ideias que me influenciaram. Hoje há mais de 5 mil entradas
diferentes nesse banco de dados e mais de 3 milhões de palavras – o equivalente a sessenta
livros em citações, fragmentos e intuições, tudo recolhido individualmente por mim e
armazenado num único banco de dados.
Ter toda essa informação ao alcance das mãos não é apenas uma questão quantitativa de
localizar minhas anotações mais depressa. Sim, quando procuro um artigo que escrevi muitos
anos atrás, agora é muito mais fácil recuperá-lo. Mas a mudança qualitativa consiste em outro
aspecto: é possível encontrar documentos dos quais havia me esquecido por completo e alguns
que eu não sabia estar procurando. O que torna o sistema realmente poderoso é a maneira
como promove a serendipidade.
O DEVONthink contém um algoritmo que detecta conexões semânticas sutis entre
passagens de texto distintas. Essas ferramentas são inteligentes o bastante para evitar o defeito
dos mecanismos de busca clássicos, a excessiva especificidade: procurar “cachorro” e perder
todos os artigos que só mencionam a palavra “cão”. Softwares de indexação modernos como
DEVONthink aprendem associações entre palavras individuais acompanhando a frequência
com que elas aparecem perto umas das outras. Isso pode criar conexões quase líricas entre
ideias. Alguns anos atrás, eu estava trabalhando num livro sobre o cólera em Londres e
busquei no DEVONthink informação sobre sistemas de esgoto vitorianos. Como o software
havia detectado que a palavra “resíduos” é frequentemente usada ao lado de “esgoto”, ele me
remeteu para uma citação que explicava a maneira como os ossos se desenvolveram nos
organismos vertebrados: dando um novo uso para os resíduos de cálcio gerados pelo
metabolismo das células. À primeira vista, poderia parecer um resultado desviante, mas isso
me lançou numa longa e frutífera tangente sobre o modo como sistemas complexos – quer
sejam cidades ou corpos – encontram usos produtivos para o lixo que produzem. Essa ideia
tornou-se um tema organizador central para um dos capítulos do livro sobre o cólera. (Na
verdade, ela reaparecerá neste livro sob outro viés.)
Agora, a rigor, quem foi responsável por essa ideia inicial? Fui eu ou foi o software?
Parece uma pergunta jocosa, mas formulo-a a sério. É óbvio que o computador não estava
consciente da ideia que ganhava forma, e eu forneci a cola conceitual que ligou os esgotos de
Londres ao metabolismo das células. Mas não estou nem um pouco convicto de que teria feito
a conexão inicial sem a ajuda do software. A ideia foi uma verdadeira colaboração, dois tipos
diferentes de inteligência enfrentando-se, uma baseada em carbono, a outra em silício. Quando
selecionei pela primeira vez aquela citação sobre o cálcio e a estrutura óssea, não tinha ideia
de que ela acabaria se conectando à história do sistema de esgotos de Londres (ou a um livro
sobre inovação). Mas houve alguma coisa naquele conceito que me intrigara o suficiente para
que eu o armazenasse no banco de dados. Ele permaneceu ali durante anos, na sopa primordial
do software, uma intuição lenta à espera de sua conexão.
Uso o DEVONthink também como uma ferramenta de improvisação. Escrevo um parágrafo
sobre algum tema – digamos, a extraordinária facilidade do cérebro humano para interpretar
expressões faciais. Depois jogo esse parágrafo no software e peço ao DEVONthink que
encontre em meu arquivo outras passagens semelhantes. Num instante, uma lista de citações
aparece na minha tela: algumas investigando a arquitetura neural que deflagra expressões
faciais, outras explorando a história evolutiva do sorriso, ou tratando da expressividade de
nossos parentes próximos, os chimpanzés. Invariavelmente, uma ou duas delas desencadeiam
uma nova associação em minha cabeça – talvez eu tivesse me esquecido da relação com os
chimpanzés –, e assim seleciono essa citação e peço ao software para encontrar um novo
grupo de passagens similares a ela. Em pouco tempo, uma ideia mais ampla ganha forma em
minha mente, baseada na trilha de associações que a máquina traçou para mim.
Compare isso à maneira tradicional como exploramos nossos arquivos, em que o
computador é como um mordomo obediente, mas burro: “Encontre para mim aquele
documento sobre os chimpanzés!” Essa é a busca. A outra parece radicalmente diferente, tão
diferente que não temos um verbo adequado para exprimi-la: é investigar ou explorar. Há
inícios falsos e pistas enganosas, mas há um número igualmente grande de felizes
coincidências e descobertas inesperadas. Na verdade, a obscuridade dos resultados é parte do
que torna o software tão poderoso. A serendipidade do sistema é fruto de duas forças
distintas. Primeiro, há o poder conectivo do algoritmo semântico, que é inteligente, mas
também um pouco imprevisível, criando assim uma pequena quantidade de ruído randomizante
que torna os resultados mais surpreendentes. Mas essa força randomizante é mantida sob
controle pelo fato de eu mesmo ter selecionado essas passagens, o que torna muito mais
provável que cada conexão individual me seja útil de alguma maneira. Quando começo uma
nova busca no DEVONthink e vejo os resultados iniciais, à primeira vista eles podem parecer
confusos e desconectados, mas depois os examino melhor e inevitavelmente algo intrigante me
chama a atenção. “Confusas” e “desconectadas” são também, é claro, as palavras que usamos
para descrever as estranhas explorações de nossos sonhos; e a comparação é bastante
apropriada. O DEVONthink toma as combinações estranhas mas férteis do estado onírico e as
transforma em software.
QUANDO VOCÊ CONSULTA o verbete “serendipity” na Wikipédia em inglês, está a um clique de
distância de verbetes sobre LSD, Teflon, mal de Parkinson, Sri Lanka, Isaac Newton, Viagra e
cerca de duzentos outros tópicos de diversidade comparável. Esse ecletismo é mais acentuado
na Wikipédia que em qualquer outro lugar, é claro, mas resulta da natureza fundamentalmente
“emaranhada” da arquitetura de hipertexto original de Tim Berners-Lee. Nenhum meio na
história jamais ofereceu tantas trilhas improváveis de conexão e acaso de maneira tão intuitiva
e acessível. Nos últimos anos, porém, um memea difícil de entender apareceu com estranha
insistência nas páginas de opinião dos jornais: a ascensão da web, sustentam seus
proponentes, levou ao declínio da descoberta serendipitosa. Considere esta representativa
elegia à “alegria ameaçada da serendipidade”, de autoria de um professor de jornalismo
chamado William McKeen:
Pensemos na biblioteca. Alguém ainda folheia livros? Tornamo-nos pessoas muito diretas. Podemos mirar no que queremos,
graças à internet. Insira um par de palavras-chave num mecanismo de busca e encontrará – afora um achado casual
irritante aqui e ali – exatamente o que procura. É eficiente, mas tedioso. Perdemos o costume demorado, mas enriquecedor,
de inspecionar estantes, puxando um livro porque o título ou a encadernação nos interessa ... Procurar alguma coisa e ser
surpreendidos pelo que encontramos – mesmo que não seja aquilo que buscávamos – é um dos grandes prazeres da vida, e
até agora não existe nenhum software capaz de reproduzir essa experiência.
Num texto semelhante, Damon Darlin, editor de tecnologia do New York Times, queixou-se
de que a “era digital está acabando com a serendipidade”. Darlin reconheceu o vasto influxo
de sugestões de leitura que chegam hoje à nossa tela a cada manhã por meio de serviços de
rede social como o Twitter e o Facebook, mas, segundo ele, esses links não constituem
serendipidade: “[Eles são] na verdade pensamento de grupo”, afirmou Darlin. “Tudo que
precisamos saber nos chega filtrado e avaliado. Estamos descobrindo o que todos os outros
estão aprendendo, e em geral a partir de pessoas que selecionamos porque compartilham
nossos gostos.”
Quando se queixam do declínio da serendipidade, os críticos costumam apontar dois
mecanismos da “mídia antiga” que supostamente não têm nenhum equivalente direto na web.
McKeen menciona o primeiro: vasculhar as estantes de uma biblioteca (ou livraria), “puxando
um livro porque o título ou a encadernação nos interessa.” Folhear os livros à maneira antiga
de fato levava a descobertas não planejadas. Mas, graças à natureza conectiva do hipertexto e
à fome exploratória da blogosfera por coisas novas, é muito mais fácil nos sentarmos diante
de nosso navegador e topar com algo absolutamente brilhante e surpreendente do que
percorrer uma biblioteca examinando lombadas de livros. Será que todos usam a web dessa
maneira? É claro que não. Mas trata-se de uma atividade muito mais comum do que o hábito
de explorar as estantes de uma biblioteca ao acaso, puxando livros por gostar da lombada.
Esta é a ironia do debate sobre a serendipididade: chora-se a perda de algo que, na verdade,
se transformou de experiência marginal em prática corrente na cultura.
O segundo mecanismo da era analógica que estimula a serendipidade tem a ver com as
limitações físicas do jornal impresso, que nos forçam a passar por uma serie de notícias
engenhosamente selecionadas a respeito de uma variedade de assuntos, antes de abrirmos a
seção que corresponde às paixões e aos conhecimentos que já temos. O jurista Cass Sunstein
refere-se a isso como um exemplo da “arquitetura da serendipidade”. A caminho da seção de
esportes, dos quadrinhos ou da página de negócios, você esbarra numa notícia sobre maus-
tratos físicos nas minas de diamante na África e alguma coisa na manchete lhe chama a
atenção. Mil palavras depois, você aprendeu algo importante sobre pessoas que vivem do
outro lado do mundo, cuja existência jamais lhe ocupara os pensamentos. E talvez se produza
algum tipo de clique serendipitoso nessa colisão: você estava à procura de uma nova causa
filantrópica para apoiar ou pensando em comprar um anel de diamante para sua mulher. Então
essa matéria cai no seu colo e o ajuda a completar o pensamento. Você não estava à procura de
uma notícia sobre minas de diamantes, mas era exatamente disso que precisava.
Esse é um excelente exemplo de serendipidade, e não há dúvida de que, quando estavam no
auge, os jornais inúmeras vezes facilitaram descobertas acidentais semelhantes ao serem lidos
em incontáveis cafés da manhã. A questão é se a transição para a web torna esse tipo de
descoberta mais ou menos frequente. Se compararmos as primeiras páginas das versões
impressa e on-line de um jornal, a web parece na verdade levar a melhor. O estudioso da
internet Ethan Zuckerman comparou a capa do New York Times com a de seu primo na web e
descobriu que na versão impressa havia 23 referências a artigos contidos no jornal (seja na
forma de artigos principais ou de breves resumos para despertar a curiosidade do leitor
abaixo da dobra). A primeira página do NYTimes.com, no estudo de Zuckerman, continha 315
links para artigos e outras formas de conteúdo. Se a arquitetura da serendipidade reside em
tropeços com conexões surpreendentes ao examinar a primeira página, então a web é mais de
dez vezes mais serendipitosa que o jornal impresso clássico.
Sunstein sem dúvida retrucaria que muita gente ignora a primeira página de um jornal on-
line, indo diretamente para a página de esportes ou de negócios marcadas de antemão como
favoritas, ou para algum assunto filtrado segundo seus interesses preexistentes. Certamente
milhões de pessoas lançam mão de filtros parecidos toda manhã. É razoável questionar se
pessoas assim, que se dão o trabalho de evitar o “panorama geral” da primeira página do
jornal, teriam tido alguma probabilidade de deparar com a notícia sobre a mina de diamantes
à mesa do café da manhã em um jornal impresso ou de perambular em torno das estantes de
sua biblioteca local. Sunstein, Darlin e McKeen de fato têm razão ao afirmar que a internet nos
dá filtros tópicos impensáveis no tempo da mídia analógica. Mas esses filtros são apenas
parte da história. Eles reduzem a serendipidade (a menos que nosso interesse particular
consista em sermos surpreendidos, o que é parte do atrativo de blogs maravilhosamente
variados como Boing Boing). Com exceção dos favoritos, os filtros são uma adição de
segunda geração à arquitetura da web. Não são inerentes a ela. O que é inerente à arquitetura
da Web são duas características essenciais que têm sido grandes aliadas da serendipidade: um
meio global e distribuído, no qual todos podem ser editores; e uma estrutura de documentos de
hipertexto, em que é muito simples saltar de um artigo de jornal para um ensaio acadêmico ou
para um verbete de enciclopédia em questão de segundos. A diversidade da informação na
web assegura que haja uma oferta interminável de informações surpreendentes com que
podemos nos deparar, e os links de hipertexto asseguram que podemos obtê-las na velocidade
de um raio, ou seguir trilhas de associação improvisadas que teriam sido penosas de
acompanhar na era da mídia impressa. Ironicamente, o problema da web é que há ruído
demais, caos demais – foi por isso que os filtros foram inventados. Temos filtros porque a
rede propiciou diversidade e surpresa demais, não de menos.
Pessoalmente, acredito que a web como meio impulsionou a cultura na direção de mais
encontros serendipitosos. O simples fato de “navegar” e “surfar” em busca de informação
serem agora atividades comuns confirma que houve um aumento da serendipidade em relação
a culturas dominadas por livros ou pelos meios de comunicação de massa. Mas, quer se aceite
ou não a premissa de que, em geral, o consumidor comum de mídia experimenta mais
descobertas serendipitosas graças à web, é quase inquestionável que ela é um meio sem igual
para a serendipidade quando estamos buscando isso ativamente. Se você quiser montar uma
lista diária de leituras com perspectivas ecléticas e diversas, pode alinhavar uma em seu
leitor de RSS ou em sua barra de favoritos em questão de minutos, a custo zero, sentado no
sofá. Igualmente importante, você pode usar a web para completar o contexto quando depara
com algum novo assunto interessante. O grande oráculo da era digital, o Google, é muitas
vezes evocado como um destruidor da serendipidade porque as consultas funcionam como
uma espécie de filtro por solicitação, que elimina 99,999% das informações que não são
relevantes para o interesse atual do usuário. Mas, quando os críticos incluem o Google entre
os filtros, eles supõem que as consultas são em sua maioria variações em torno do tema:
“Estou apaixonadamente interessada por x e gostaria de saber mais a respeito disso.” Sem
dúvida um número inconcebivelmente grande de usuários do Google faz consultas que
assumem esse formato básico todos os dias. Mas há outro tipo de consulta igualmente valioso:
“Acabo de ouvir falar sobre x e não sei nada a respeito, mas parece interessante. Conte-me
mais.” É dessa maneira sutil que o Google reforça os aspectos serendipitosos da web. Sim, é
verdade que ao digitar algo na caixa de busca do Google você já está envolvido com o tema.
(É por isso que o pioneiro da web John Battelle o chama de o “banco de dados de intenções”.)
Porém, com frequência esse envolvimento está diretamente correlacionado com nossa
ignorância sobre o assunto em questão: alguém menciona por acaso a poesia de John Ashbery,
ou a série de televisão Arrested Development, ou o Uróboro que devora a própria cauda, e
você pensa: “Que história é essa? Parece interessante.” Imagine que estamos em 1980 e você
está à mesa do café da manhã, lendo o jornal matinal, e, a caminho da página de esportes,
encontra um artigo na primeira página sobre a intrigante ideia do aquecimento global, da qual
nunca ouvira falar. Você pode ler o artigo, é claro, mas o que vai fazer se este o deixar ansioso
por mais informação e contexto? Liga a televisão e torce para que uma das três redes de
televisão privadas ou a PBS esteja transmitindo uma notícia ou um documentário sobre o
assunto naquele exato segundo? Entra no carro e dirige durante quinze minutos até a biblioteca
pública para consultar um livro sobre o assunto? Examina todas as revistas que tem em casa,
percorrendo os sumários em busca de algum artigo relacionado à mudança do clima?
Suponhamos que você more numa casa particularmente rica em fontes de informação para
os padrões de 1980 e por acaso tenha um exemplar da Encyclopaedia Britannica. Mas a
edição que você comprou é na verdade de 1976, e o aquecimento global só entrou na
Britannica em 1994, embora a expressão fosse comum na linguagem corrente a partir da
década de 1990.
Hoje, é claro, você consultaria o Google ou a Wikipédia usando o termo de pesquisa
“aquecimento global”. E teria num segundo mais informação (e até mais perspectivas) ao
alcance da mão do que teria podido imaginar quando folheava a Britannica em 1980. Sim,
esses resultados estão relacionados ao seu interesse expresso por um assunto específico, mas
esse interesse é muitas vezes algo com que você acaba de topar, mais uma alusão que uma
paixão. E, como essas páginas são construídas com hyperlinks, apenas alguns cliques podem
transportá-lo para um campo de interesse inteiramente novo, que você jamais teria sonhado
visitar. O Google e a Wikipédia dão a essas alusões passageiras algo a que se prender, uma
espécie de âncora da informação que o permite se instalar em torno de um tema e explorar a
área circundante. Eles transformam alusões e coincidências em informação. Se a tradição do
livro de citações nos diz que a melhor maneira de cultivar intuições é registrar tudo, o
mecanismo de serendipidade da web sugere uma instrução paralela: consulte tudo.
A PREMISSA DE QUE A INOVAÇÃO PROSPERA quando ideias podem se conectar e se recombinar
serendipitosamente com outras, quando intuições podem topar com outras capazes de
preencher suas lacunas, talvez pareça uma obviedade, mas o fato estranho é que grande parte
da sabedoria jurídica e popular sobre inovação buscou justamente o oposto, construindo
muros entre as ideias, evitando que estabelecessem conexões de tipo aleatório, serendipitoso,
típicas dos sonhos e dos compostos orgânicos da vida. Ironicamente, esses muros foram
erguidos com a finalidade explícita de estimular a inovação. Eles têm muitos nomes: patentes,
gestão de direitos digitais, propriedade intelectual, segredos comerciais, tecnologia
proprietária. Mas compartilham um pressuposto básico: se impusermos restrições à
propagação de ideias novas, no final das contas a inovação aumentará, porque tais restrições
permitirão aos criadores obter grandes compensações financeiras com suas invenções, o que
estimulará outros inovadores a seguir o mesmo caminho.b
O problema desses ambientes fechados é que eles inibem a serendipidade e reduzem a
totalidade da rede de mentes que podem se envolver potencialmente com um problema. É por
isso que um número crescente de grandes organizações – empresas, entidades sem fins
lucrativos, escolas, órgãos governamentais – começaram a experimentar ambientes de trabalho
que estimulam a arquitetura da serendipidade. Tradicionalmente, organizações com forte
demanda de inovação criaram uma espécie de cercadinho fechado para as intuições: o
laboratório de pesquisa e desenvolvimento. Por ironia, os laboratórios de P&D funcionaram
historicamente como uma espécie de caixa-forte de ideias; as intuições que neles se
desenvolviam tendiam a ser os segredos mais bem-guardados de toda a organização. Se fosse
permitido que essas ideias iniciais para produtos circulassem de maneira mais ampla, firmas
concorrentes poderiam copiá-las e explorá-las. Algumas empresas – inclusive a Apple –
fizeram grandes esforços para manter os experimentos de P&D isolados de outros empregados
dentro da própria organização.
Mas esse sigilo, como vimos, tem um preço alto. Quando protegemos ideias contra
imitadores e concorrentes, elas ficam protegidas também de outras ideias que poderiam
aperfeiçoá-las e transformá-las de palpites e intuições em verdadeiras inovações. E de fato há
um movimento crescente em algumas companhias progressistas para virar seus laboratórios de
P&D pelo avesso e torná-los muito mais transparentes que o modelo tradicional. Na última
década, organizações como a IBM e a Procter & Gamble, que têm uma longa história de lucros
com inovações patenteadas, protegidas, abraçaram plataformas de inovação abertas,
compartilhando sua pesquisa de ponta com universidades, parceiros, fornecedores e clientes.
No início de 2010, a Nike anunciou um novo mercado baseado na web que chamou de
GreenXchange, no qual divulgou mais de quatrocentas de suas patentes que envolvem
tecnologias ou materiais ecológicos. O mercado é uma espécie de híbrido entre interesse
comercial e bem cívico. Tornando suas ideias públicas, a Nike permitiu a outras empresas
aperfeiçoar essas inovações, criando um novo valor que ela própria poderá por fim usar em
seus produtos. Em certo sentido, ela estava ampliando a rede de mentes ativamente
empenhadas em descobrir como tornar essas ideias mais úteis, sem precisar incluir mais
ninguém em sua folha de pagamento. Mas os valores organizacionais da Nike também incluem
um compromisso com a sustentabilidade ambiental, e a companhia reconheceu que muitas de
suas patentes ecológicas poderiam ser úteis em contextos diferentes. A Nike é uma grande
empresa, com muitos produtos em muitas categorias, mas seu alcance tem limites. Algumas de
suas inovações poderiam sem dúvida se mostrar vantajosas para indústrias ou mercados em
que ela não tem envolvimento competitivo algum. Ao manter suas ideias ecológicas sob um
véu de sigilo, ela ocultava – sem nenhuma justificativa comercial real – ideias que poderiam,
em outro contexto, contribuir para um futuro sustentável. Em parceria com a Creative
Commons, a Nike tornou suas patentes disponíveis sob uma licença modificada, permitindo
seu uso em ramos “não competitivos”. (Eles também criaram um contrato-padrão, pré-
negociado, para as patentes, reduzindo assim os custos da negociação individual de cada uma
delas.) O cenário evocado como exemplo por ocasião do lançamento do GreenXchange teria
empolgado Stephen Jay Gould: uma borracha ambientalmente saudável inventada para uso em
tênis de corrida que poderia ser adaptada por uma companhia de mountain bike para criar
pneus sustentáveis. Ao que parece, o princípio da transformação de pneus em sandálias, de
Gould, funciona nos dois sentidos. Por vezes fabricamos um calçado dando um novo uso a
pneus, outras vezes fabricamos pneus dando um novo uso a calçados. O GreenXchange está
tentando dar às multinacionais um pouco da mesma liberdade para reinventar e reciclar de que
gozam os fabricantes de sandálias de Gould, que vasculham os ferros-velhos de Nairóbi.
A outra técnica organizacional para facilitar conexões serendipitosas é a sessão de
“brainstorming”, abordagem proposta pela primeira vez pelo executivo publicitário Alex
Osborn nos anos 1930. A técnica abre o fluxo de ideias e intuições de maneira mais criativa
do que é habitual numa reunião de trabalho disciplinada. Vários estudos recentes, contudo,
sugeriram que o brainstorming é menos eficaz do que querem crer seus praticantes. Um de seus
senões é ser finito tanto no tempo quanto no espaço: um grupo se reúne por uma hora numa
sala ou durante um dia todo de retiro corporativo, todos os participantes jogam um bando de
ideias malucas na mesa e em seguida a reunião se dispersa. Às vezes uma conexão útil
emerge, mas com frequência as intuições pertinentes não estão em sincronia umas com as
outras. Um empregado tem uma intuição promissora numa sala e, dois meses depois, outro
descobre a peça que faltava para transformá-la num verdadeiro insight. O brainstorming
poderia reunir esses dois fragmentos, mas isso é muito pouco provável. Imagine uma situação
hipotética em que o FBI promove um retiro corporativo no final de agosto de 2001 e convida
os agentes de campo do Arizona e de Minnesota para se sentar juntos numa sala e fazer um
brainstorming sobre ameaças potenciais aos Estados Unidos. Na certa teria sido o primeiro
retiro corporativo de que se tem registro a realmente mudar o destino da história mundial.
Porém, com mais de 10 mil agentes de campo no país todo, as probabilidades de uma reunião
na hora certa das pessoas certas do Arizona e de Minnesota seriam mínimas. Mas imagine se o
FBI estivesse usando, em vez do arcaico sistema Automated Case Support, uma versão em
rede do DEVONthink. Isso não teria impedido que a alta cúpula da Radical Fundamentalist
Unit lesse a solicitação de um mandado de busca para o laptop de Moussaoui e pensasse:
“Isso parece um palpite muito duvidoso.” No entanto, uma rápida consulta ao DEVONthink os
teria encaminhado para o memorando Phoenix, ou para algum outro palpite sobre curso de
pilotagem e terrorismo. Essas duas ideias improváveis teriam colidido, sem que os agentes de
campo em Phoenix e Minnesota tivessem sequer conversado entre si, muito menos se sentado
juntos para uma sessão de brainstorming.
O segredo para a inspiração organizacional é construir redes de informação que permitam
às intuições persistir, dispersar-se e recombinar-se. Em vez de enclausurar suas intuições em
sessões de brainstorming ou laboratórios de P&D, crie um ambiente em que o braistorming é
algo sempre em curso em segundo plano, no âmbito de toda a organização, uma versão
coletiva do conceito de 20% do tempo, que se provou tão bem-sucedido para o Google e a
3M. Uma maneira de fazer isso é criar um banco de dados de intuições aberto, a versão web
2.0 da tradicional caixinha de sugestões. Um banco de dados público torna cada ideia
passageira visível para todas as outras pessoas na organização, não apenas a gerência. Outros
empregados podem comentá-las ou expandi-las, conectando-as com suas próprias intuições
sobre novos produtos, prioridades ou mudanças organizacionais internas. Alguns sistemas
permitem até aos empregados votar nas sugestões dos colegas, mais ou menos como as
classificações dos usuários que alimentam sites de notícias coletivos como Digg ou Reddit. O
Google tem uma lista de e-mail no âmbito da companhia em que os funcionários podem sugerir
novas características ou produtos; depois cada sugestão é classificada numa escala de o
(“Perigoso ou prejudicial”) a 5 (“Excelente ideia! Ponha-a em prática”). A Salesforce.com
mantém a popular Idea Exchange, um espaço no qual seus clientes podem sugerir novas
características para os produtos de software da companhia. A Idea Exchange não permite
apenas que intuições interessantes circulem e se conectem. Também acompanha a maturação
delas em códigos de envio: a porta da frente da Idea Exchange inclui links em destaque para
as ideias propostas que estão sendo consideradas no momento para inclusão em versões
futuras, bem como aquelas que já foram integradas com sucesso a lançamentos passados. Com
muita frequência, as caixas de sugestão do mundo real funcionam como um buraco negro: você
coloca a sua ideia na ranhura e nunca mais ouve falar nela. Num fórum público como Idea
Exchange, você não só consegue ver e aperfeiçoar as sugestões dos outros, como obtém
provas concretas de que as suas podem fazer diferença.
Esses tipos de redes de informação podem fazer um excelente trabalho ao tirar bom
proveito da inteligência tanto individual quanto coletiva: o empregado individual tem uma
intuição provocativa e útil, e o grupo ajuda-o a completá-la ao associá-la a outras ideias que
circularam através do sistema; assim separa-se essa intuição de milhares de outras menos
úteis, elegendo-a como uma das melhores. Ao divulgar as ideias e assegurar que permaneçam
armazenadas no banco de dados, esses sistemas criam uma arquitetura para a serendipidade
organizacional. Dão às boas ideias novas maneiras de se conectar.
a Termo utilizado por Richard Dawkins para designar a unidade mínima da memória, análogo ao que gene significa para a

genética. (N.T.)

b Na verdade, as patentes têm uma relação histórica complexa com a ideia de redes abertas de informação. Embora em geral

sejam de natureza exclusiva – proibindo os que não a possuem de usar um “método” patenteado sem permissão por um período
determinado de tempo –, as leis de patentes costumam envolver também um elemento de divulgação, obrigando o inventor a
revelar a natureza de sua criação em detalhes técnicos. Essa revelação é obviamente destinada a ajudar na imposição de
restrições em caso de violação da patente, mas pretende também estimular a disseminação mais livre de boas ideias, tornando-
as parte do registro público. Infelizmente, o atual surgimento dos grileiros e trolls de patentes, apoiados por advogados
especialistas em propriedade intelectual excessivamente zelosos, demonstra que o aspecto protetor da lei tem dominado o
aspecto conectivo.

5. Erro
NO VERÃO DE 1900, um aspirante a inventor de 27 anos chamado Lee de Forest mudou-se para
Chicago, alugou um apartamento conjugado no Washington Boulevard e arranjou um emprego
diurno como tradutor de artigos estrangeiros sobre telegrafia sem fio para a revista Western
Electrician. O trabalho de tradução era informativo: uma importante exposição de tecnologia
em telegrafia sem fio acabara de se realizar em Paris, garantindo um fluxo constante de novos
e interessantes artigos de pesquisa através do Atlântico. Mas a verdadeira paixão de De
Forest era o “gabinete de curiosidades” que ele havia formado no quarto do Washington
Boulevard: baterias, transmissores de centelha, eletrodos – todos os componentes essenciais
que seriam reunidos na década seguinte para a invenção da era eletrônica.
Para um jovem inovador no campo da telegrafia sem fio na virada do século XX, o
transmissor de centelha era a mais essencial das engenhocas. As explorações originais do
espectro eletromagnético por Hertz e Marconi haviam se baseado em transmissores de
centelha. O dispositivo empregava dois eletrodos separados por um pequeno espaço. Uma
bateria presa aos eletrodos fornecia um pulso de alta tensão, que fazia uma centelha saltar de
um eletrodo para outro, deflagrando um pulso de atividade eletromagnética que podia ser
detectado e amplificado por antenas situadas a quilômetros de distância. Geradores de
centelhas emitiam uma breve rajada de ruído monótono, perfeita para o envio de código
Morse.
Na noite de 10 de setembro de 1900, De Forest fazia experiências com seu gerador de
centelhas num canto de seu quarto no Washington Boulevard. Do outro lado do cômodo, a mais
de quatro metros de distância, a chama vermelha de um bico de Welsbach bruxuleava. De
Forest provocou um pulso de voltagem no centelhador e, quando a máquina estalou, pôde ver a
chama do bico mudar instantaneamente de cor, de vermelha para branca. Mais tarde, estimou
que a intensidade da chama ficara várias candelas maior. De alguma maneira, por razões que
ele não sabia explicar, o pulso eletromagnético do centelhador estava intensificando a energia
de uma chama a metros de distância. A observação de que a chama passara de vermelha a
branca plantou a semente de uma ideia na cabeça de De Forest: talvez fosse possível empregar
um gás como detector sem fio, um que pudesse ser mais sensível do que tudo que Marconi ou
Tesla tinham criado até então.
De Forest topara com uma intuição lenta clássica. Em sua autobiografia, ele descreveu o
detector de chama de gás como “um assunto que desde aquele momento ficara no fundo de
minha mente”. No final das contas, essa intuição iria amadurecer num invento que acabou por
transformar a paisagem do século XX, uma invenção que tornou possíveis o rádio, a televisão
e os primeiros computadores digitais. Em 1903, ele iniciou uma série de experimentos
malogrados com a introdução de dois eletrodos em bulbos de vidro cheios de gás. Continuou a
trabalhar com o modelo até que, vários anos depois, ocorreu-lhe a ideia de introduzir no bulbo
um terceiro eletrodo, preso a uma antena ou sintonizador externo. Após várias repetições, usou
como eletrodo do meio um pedaço de fio curvado para trás e para a frente, que chamou de
“grade”. Testes iniciais mostraram que o dispositivo, que De Forest batizou de “Audion”, era
muito superior a outras tecnologias na amplificação de sinais de áudio, sem reduzir a
capacidade do sintonizador de distinguir sinais em diferentes frequências.
A criação de De Forest seria finalmente chamada de tríodo. Sua arquitetura com três
eletrodos formaria a base dos tubos de vácuo, que começaram a ser produzidos em massa na
década seguinte. Receptores de rádio, mesas telefônicas, aparelhos de televisão – todas as
revoluções em comunicações da primeira metade do século XX basearam-se em alguma
variação do projeto de De Forest para intensificar seus sinais. Empregado de início para a
amplificação, o tubo de vácuo veio a ter um uso imprevisto como interruptor eletrônico,
permitindo os portões lógicos de alta velocidade dos primeiros computadores digitais nos
anos 1940. Quando De Forest torceu o fio na forma de uma grade e o inseriu entre aqueles
dois eletrodos, sem saber abriu o possível adjacente da máquina analítica que Charles
Babbage não conseguira produzir sessenta anos antes. O poder desse novo portal se revelou
de imediato: o primeiro computador construído com tubos de vácuo, o gigantesco ENIAC, fez
cálculos que ajudaram no desenvolvimento da bomba de hidrogênio.
A invenção do Audion parece uma história clássica de engenhosidade e persistência: um
inventor independente, isolado no laboratório que montara no próprio quarto, observa um
padrão impressionante e o explora durante anos como uma intuição lenta, até descobrir um
dispositivo que transforma o mundo. Ao contar a história dessa maneira, porém, deixamos
escapar um fato crucial: omitimos que, em quase cada passo do caminho, De Forest estava
redondamente enganado com relação ao que estava inventando. O Audion resultou menos de
uma invenção que de um acúmulo constante e persistente de erros. No fim das contas, a
estranha comunicação entre o transmissor de centelhas e a chama do bico de gás de Wersbach
revelou nada ter a ver com o espectro eletromagnético. (A chama estava reagindo a ondas de
som comuns emitidas pelo transmissor de centelhas.) Mas, como De Forest havia começado
com a noção equivocada de que a chama de gás estava detectando os sinais de rádio, em todos
os outros Audions que montou havia algum gás a baixa pressão dentro do dispositivo, o que
limitava bastante sua confiabilidade. Os pesquisadores da General Electric e de outras
empresas levaram uma década para perceber que o tríodo tinha um desempenho muito melhor
num vácuo verdadeiro (daí o termo “tubo de vácuo”). Até o próprio De Forest admitiu sem
hesitação que não compreendia o dispositivo que inventara: “Eu não sabia como aquilo
funcionava”, observou. “Simplesmente funcionava.”
Talvez De Forest tenha sido o mais errático dos grandes inventores do século XX, mas sua
trajetória está longe de ser uma anomalia. A história de um acerto espetacular oculta uma
história secreta atrás de si: aquela, muito mais longa, de erros espetaculares e reiterados. E
não apenas erro, mas confusão. Um número surpreendentemente grande de ideias
transformadoras nos anais da ciência pode ser atribuído a ambientes de laboratório
contaminados. Como se sabe, Alexander Fleming descobriu as virtudes médicas da penicilina
quando uma cultura de estafilococos que deixara junto de uma janela aberta do laboratório foi
infiltrada por mofo. Na década de 1830, Louis Daguerre passou anos tentando arrancar
imagens de placas de prata iodadas. Certa noite, após mais uma tentativa inútil, ele guardou as
placas num armário cheio de substâncias químicas; na manhã seguinte, para seu assombro, viu
que as emanações do mercúrio derramado de um frasco haviam produzido uma imagem
perfeita na placa – nascera o daguerreótipo, o precursor da fotografia moderna.
No verão de 1951, Wilson Greatbatch, um veterano da Segunda Guerra Mundial que
servira na Marinha, trabalhava numa fazenda de estudos do comportamento animal ligada ao
departamento de psicologia da Universidade Cornell, onde estudava sob os auspícios do G.I.
Bill of Rights.a Greatbatch era um radioamador entusiasta havia muito tempo; quando
adolescente, montara um rádio de ondas curtas com descendentes do Audion de De Forest. Seu
amor por engenhocas o levara àquela fazenda porque o departamento de psicologia precisava
de alguém para prender instrumentos aos animais, medindo suas ondas cerebrais, seus
batimentos cardíacos e sua pressão sanguínea. Um dia, Greatbatch sentou-se por acaso para
almoçar com dois cirurgiões visitantes e começou a conversar sobre os perigos das arritmias
cardíacas. Alguma coisa na descrição que os médicos fizeram da enfermidade fez eclodir uma
associação em sua mente. Ele imaginou o coração como um rádio que não era capaz de
transmitir ou receber um sinal à maneira apropriada. Sabia que toda a história da eletrônica
moderna se baseava na regulação dos sinais elétricos transmitidos de um dispositivo para
outro com precisão cada vez mais miraculosa. Seria possível pegar todo esse conhecimento e
aplicá-lo ao coração humano?
Durante os cinco anos seguintes, Greatbatch guardou essa ideia no fundo da mente, onde ela
perdurou como uma intuição lenta. Após se mudar para Buffalo, começou a lecionar
engenharia elétrica e arranjou um emprego noturno no Chronic Disease Institute. Um médico
da instituição o recrutou para ajudá-lo a projetar um oscilador que registraria batimentos
cardíacos usando os novos transistores de silício que ameaçavam substituir o tubo de vácuo.
Um dia, ao trabalhar com o aparelho, Greatbatch pegou por acaso o resistor errado. Quando o
ligou ao oscilador, este começou a pulsar num ritmo familiar. Graças ao erro de Greatbatch,
em vez de registrar os batimentos de um coração humano, o aparelho estava simulando-os.
Lembrou-se então da conversa na fazenda cinco anos antes. Ali estava o começo de um
dispositivo que poderia restaurar o sinal defeituoso de um coração irregular, enviando-lhe
pulsos elétricos que o forçariam a bater a intervalos precisos. Dois anos depois, Greatbatch e
William Chardack, um cirurgião de Buffalo, implantaram o primeiro marca-passo cardíaco no
coração de um cão. Em 1960, o marca-passo de Greatbatch-Chardack pulsava com
regularidade no peito de dez seres humanos. Até hoje, variações do projeto original de
Greatbatch salvam ou prolongam milhões de vidas no mundo todo.
O marca-passo de Greatbatch é um exemplo de uma grande ideia que resultou –
literalmente – de uma nova combinação de peças avulsas. Por vezes essas novas combinações
se formam devido às colisões aleatórias que se dão nas ruas de uma cidade ou num cérebro
adormecido. Mas às vezes nascem de simples erros. Você enfia a mão na gaveta de resistores,
puxa a peça errada e quatro anos depois está salvando a vida de uma pessoa. Mas, por si só, o
erro raras vezes é suficiente. Greatbatch teve sua epifania ao ouvir a pulsação constante de seu
oscilador porque estivera pensando havia cinco anos sobre os batimentos cardíacos
irregulares como um problema de transmissão de sinal. Esse é mais um padrão recorrente na
história dos equívocos. Invenções como a radiografia, a borracha vulcanizada e o plástico
dependeram todas de erros fecundos – e fecundos exatamente por se conectarem a intuições
lentas nas mentes de seus criadores.
O economista britânico William Stanley Jevons, que tinha ele próprio experiência direta
como inventor, descreveu a importância do erro na obra Principles of Science, publicada em
1874:
Seria um erro supor que o grande descobridor capta de imediato a verdade ou tem um método infalível para adivinhá-la.
Provavelmente, os erros da grande mente superam em número os da mente menos vigorosa. A fertilidade da imaginação e a
abundância de conjecturas da verdade estão entre os primeiros requisitos da descoberta; mas as conjecturas errôneas
devem ser muitas vezes mais numerosas que aquelas que se provam bem-fundadas. As analogias mais fracas, as noções
mais extravagantes, as teorias aparentemente mais absurdas podem passar pelo cérebro prolífico, mas não se registra mais
do que a centésima parte disso.
“Os erros da grande mente superam em número os da mente menos vigorosa.” Isso não é
apenas estatística. Não significa que os pensadores pioneiros sejam simplesmente mais
produtivos que os menos “vigorosos”, gerando mais ideias ao todo, sejam boas ou ruins.
Alguns estudos históricos de registros de patentes mostraram de fato que a produtividade total
está correlacionada às descobertas radicais em ciência e tecnologia, que a simples quantidade
conduz por fim à qualidade. Mas Jevons faz uma defesa mais sutil do papel do erro na
inovação, porque o erro não é apenas uma fase que é preciso suportar a caminho da
genialidade. O erro muitas vezes cria um caminho que nos desvia de nossas suposições
confortáveis. De Forest estava errado em relação à utilidade do gás como detector, mas
continuou investigando nas bordas desse erro até descobrir algo genuinamente útil. O acerto
nos mantém no mesmo lugar. O erro nos força a explorar.
Em A estrutura das revoluções científicas, Thomas Kuhn desenvolve uma argumentação
semelhante em favor do papel do erro. Segundo ele, as mudanças de paradigma começam com
anomalias nos dados, no momento em que os cientistas constatam que suas previsões
continuam se revelando erradas. Quando Joseph Priestley pôs uma hortelã pela primeira vez
sob uma redoma para privá-la de oxigênio, esperava que a planta morresse, como acontecia
com os camundongos ou as aranhas nas mesmas circunstâncias. Mas ele estava errado: a
planta se desenvolvia. Na verdade, a planta prosperava, mesmo quando se queimava todo o
oxigênio existente sob a redoma antes de introduzi-la ali. O erro de Priestley estimulou-o a
investigar esse estranho comportamento e acabou por levá-lo a uma das descobertas
fundamentais do que hoje chamamos de ciência dos ecossistemas: a compreensão de que as
plantas expelem oxigênio como parte da fotossíntese e de fato criaram grande parte da
atmosfera da Terra. Nas palavras de William James: “O erro é necessário para fazer surgir a
verdade, mais ou menos como é preciso um pano de fundo escuro para exibir a luminosidade
de uma pintura.” Quando estamos errados, temos de desafiar nossas suposições, adotar novas
estratégias. O erro por si só não abre novas portas para o possível adjacente, mas nos força a
procurá-las.
O problema do erro é que temos uma tendência natural a desprezá-lo. Quando Kevin
Dunbar analisou os dados de seus estudos in vivo em laboratórios de microbiologia, um de
seus achados mais notáveis foi a grande quantidade de experimentos que produziam resultados
realmente inesperados. Mais da metade dos dados coletados pelos pesquisadores desviava-se
de maneira significativa do que eles haviam previsto encontrar. Dunbar descobriu que os
cientistas tendiam a tratar esses resultados surpreendentes como consequência de falhas em
seu método experimental: talvez algum tipo de contaminação do tecido original, ou um mau
funcionamento mecânico, ou um erro na fase do processamento de dados. Viam nele um ruído,
não um sinal.
A transformação do erro em insight revelou-se uma das funções essenciais das reuniões de
laboratório. Na pesquisa de Dunbar, pessoas alheias ao experimento, que estavam trabalhando
com problemas diferentes, eram muito menos propensas a rejeitar o erro aparente como ruído
inútil. O fato de considerarem o problema a partir de uma perspectiva diferente, com poucas
ideias preconcebidas sobre qual deveria ser o resultado “correto”, permitia-lhes conceber
cenários em que o erro poderia ser realmente significativo. Como observou o jornalista
científico Jonah Lehrer, esse padrão aparece num dos grandes avanços científicos da física no
século XX: a descoberta da radiação cósmica de fundo, que por mais de um ano foi
confundida com estática sem sentido pelos astrônomos Arno Penzias e Robert Wilson, até que
uma conversa casual com um físico nuclear de Princeton semeou neles a ideia de que o ruído
talvez fosse não o resultado de equipamento defeituoso, mas a reverberação ainda persistente
do Big Bang. Dois brilhantes cientistas de grande perspicácia depararam com evidências da
origem do universo – evidências que acabariam lhes valendo um prêmio Nobel –, e a primeira
reação de ambos, no entanto, foi: “Nosso telescópio deve estar quebrado.”
CERCA DE TRINTA ANOS ATRÁS, uma professora de psicologia de Berkeley chamada Charlan
Nemeth começou a investigar a relação entre ruído, discordância e criatividade em ambientes
de grupo. Um dos primeiros experimentos de Nemeth reuniu pequenos grupos e lhes mostrou
uma série de slides, com cada um dominado por uma única cor. As pessoas eram solicitadas a
avaliar a cor e o brilho de cada slide. Depois que o haviam feito, Nemeth lhes pediu que
fizessem associações livres com a cor percebida.
Poucas ações são tão comumente relacionadas à criatividade quanto a associação livre.
Está tentando inventar um novo slogan para um detergente? Esforçando-se para adotar uma
nova perspectiva em relação às suas lembranças de traumas da infância? Reunindo ideias para
um soneto? A associação livre, dizem, ajuda a encontrar uma resposta.
Mas há muito corre entre os psicólogos a piada de que os seres humanos fazem associações
livres de maneiras absurdamente previsíveis. Aborde cem americanos na rua e peça-lhes para
fazer uma associação livre a partir da palavra “verde” e quarenta deles dirão “grama”. Outros
quarenta mencionarão outra cor – “vermelho”, “amarelo” ou “azul” – ou a própria palavra
“cor”. As associações mais criativas só aparecerão quando você chegar aos 20% finais das
respostas, a longa cauda de associações em que palavras como “Irlanda”, “dinheiro” ou
“folhas” são mencionadas. Peça-lhes para fazer associações livres com a palavra “azul” e
verá o mesmo padrão: 80% vão sugerir outra cor ou a palavra “céu”, e só os últimos 20% das
associações se distribuirão entre diversas respostas menos previsíveis, como “jeans” ou
“lago”.
Psicólogos montaram imensas tabelas de probabilidade que documentam os padrões de
associação livre para centenas de palavras. Essas normas de associação lhes dão um
parâmetro estável para medir pensamento criativo em diferentes ambientes. Algumas situações
levam as pessoas a se tornar ainda mais previsíveis em suas associações, respondendo
“grama” e “azul” como robôs obedientes. Outras, porém, podem empurrar suas associações
para a extremidade da distribuição, a zona mais eclética de “Irlanda” e “dinheiro”. Indivíduos
excepcionalmente criativos tendem a gerar associações mais originais quando testados.
O experimento de Charlan Nemeth foi uma perfeita representação dessa previsibilidade.
Slides azuis provocaram associações de palavras absolutamente convencionais: “céu”,
“verde” e “cor” dominaram, ao passo que as associações mais inovadoras se restringiram aos
20% finais.
Mas em seguida Nemeth conduziu uma outra versão do experimento, dessa vez com uma
alteração inesperada. Ela mostrou os mesmos slides a pequenos grupos de sujeitos – porém,
introduziu secretamente em cada grupo um punhado de atores instruídos a descrever cada slide
de maneira inexata, como se ele fosse de uma cor diferente. Os verdadeiros sujeitos
experimentais descreviam corretamente os slides azuis como azuis, e ficavam muito surpresos
ao ver que seus pares olhavam para a mesma cor mas a descreviam como verde.
Quando Nemeth tomou essa coorte (isto é, os sujeitos experimentais menos os atores) e
pediu aos indivíduos que fizessem associações livres com a cor que haviam mencionado, as
palavras que sugeriram foram bastante diferentes das do grupo anterior. Alguns disseram
obedientemente “céu”, como os sujeitos do primeiro grupo, mas associações como aquelas em
geral encontradas na cauda criativa da distribuição – como “ jeans” – foram muito mais
numerosas. Em outras palavras, quando expostos a descrições inexatas dos slides, os sujeitos
se tornaram maiscriativos. Associações em geral situadas nas franjas da tabela de
probabilidades tornaram-se usuais. Nemeth havia introduzido ruído de maneira deliberada no
processo de tomada de decisão, e o que encontrou contraria frontalmente nossos pressupostos
intuitivos sobre verdade e erro. Os grupos contaminados com informação errônea acabaram
fazendo conexões mais originais que aqueles que só haviam recebido informação correta. Os
atores “discordantes” estimularam os demais sujeitos a explorar novas salas no possível
adjacente, ainda que estivessem, tecnicamente falando, acrescentando dados incorretos ao
ambiente.
Nemeth continuou, documentando o mesmo fenômeno em ação em dezenas de ambientes
diferentes: júris falsos, reuniões de diretoria, seminários acadêmicos. Sua pesquisa sugere
uma verdade paradoxal sobre a inovação: boas ideias têm maior probabilidade de emergir em
ambientes que contêm certa quantidade de ruído e erro. Seria de imaginar que a inovação
estaria mais fortemente correlacionada com os valores de precisão, clareza e foco. Uma boa
ideia tem de ser correta em algum nível básico, e valorizamos as boas ideias porque tendem a
ter uma proporção sinal/ ruído elevada. Isso não significa, porém, que seja desejável cultivar
essas ideias em ambientes livres de ruído, porque esses espaços tendem a ter uma produção
demasiado estéril e previsível. Os melhores laboratórios de inovação são sempre um pouco
contaminados.
A PRÓXIMA VEZ que você visitar um jardim zoológico ou um museu de história natural e
observar a extraordinária diversidade dos organismos em nosso planeta, pare um segundo
para lembrar que toda essa variação – as presas do elefante, a cauda do pavão e o neocórtex
do ser humano – tornou-se possível, em parte, por erro. Sem ruído, a evolução estagnaria,
reduzida a uma série interminável de cópias perfeitas, incapazes de mudança. Mas, como o
DNA é suscetível ao erro – sejam mutações no próprio código, sejam erros de transcrição
durante a replicação –, a seleção natural tem uma fonte constante de novas possibilidades para
testar. O mais das vezes, esses erros levam a resultados desastrosos ou não têm absolutamente
nenhum efeito. De vez em quando, porém, uma mutação abre uma nova ala do possível
adjacente. De uma perspectiva evolucionária, não basta dizer que “errar é humano”. Em
primeiro lugar, foi o erro que tornou o ser humano possível.
A proeminência da mutação randômica em nossa história evolucionária foi há muito
associada à teoria original de Darwin, mas a verdade é que o próprio Darwin teve grande
dificuldade em aceitar a premissa de que a variação aleatória não dirigida poderia produzir as
maravilhosas inovações da vida. Quando ele esboçou pela primeira vez a teoria da seleção
natural como a “preservação de variações favoráveis e a rejeição de variações prejudiciais”
em A origem das espécies, faltava-lhe uma teoria convincente para explicar de onde vinham
todas essas variações. Na obra, ele escreve de maneira geral sobre elas como se fossem
randômicas, em parte porque está tentando explicitamente repelir a noção lamarckiana de
variação dirigida, segundo a qual as inovações – o pescoço comprido da girafa é o exemplo
canônico – são geradas por atividade durante a vida do organismo e, depois, transmitidas à
geração seguinte. Mas, ao longo da década que se seguiu, Darwin afastou-se do abismo da
variação randômica e desenvolveu uma teoria chamada pangênese, publicada pela primeira
vez em seu livro de 1868, The Variation of Animals and Plants under Domestication. A
pangênese renegava o ruído da teoria original de Darwin, introduzindo um complexo
mecanismo para a hereditariedade que criava um tipo de variação dirigida. Segundo essa
teoria, cada célula do corpo liberava partículas hereditárias, chamadas gêmulas, que se
acumulavam nas células germinativas do organismo. Um órgão ou membro particular que fosse
intensamente usado durante toda a vida do animal liberaria mais gêmulas, e assim moldaria a
fisiologia da geração seguinte. Embora a pangênese tenha sido bem-recebida na época em que
Darwin a propôs, a genética moderna acabou revelando-a completamente falsa, e esse se
provou o mais notório erro da carreira científica dele. Em certo sentido, o maior erro de
Darwin foi não compreender a força proteica do erro.
Erro em excesso é fatal, claro, por isso nossas células contêm mecanismos elaborados para
reparar DNA danificado e assegurar que o processo de transcodificação seja exato até o
último nucleotídio. Um organismo que misturasse constantemente o código genético
transmitido a seus descendentes teria crias mais inovadoras, mas só no sentido de que elas
encontrariam muitas novas maneiras de perecer antes ou pouco depois do nascimento. Os pais
não desejam mutações genéticas no filho. Como espécie, no entanto, dependemos de mutação.
É em razão dessa dependência da mutação que alguns cientistas afirmaram que a seleção
natural gravitou rumo a uma taxa de erro pequena, mas estável, na transcodificação do DNA;
isto é, em certo sentido a evolução “sintonizou” o erro com o equilíbrio ideal entre excessiva
mutação e demasiada estabilidade. Dada a grave ameaça associada a erros de
transcodificação, poderíamos pensar que haveria uma extraordinária pressão seletiva para
tornar o sistema de reparo do DNA à prova de erro. Pais que fizessem cópias perfeitas de suas
células germinativas teriam uma prole mais saudável, enquanto aqueles com reparo de DNA
defeituoso teriam menos crias sobreviventes, por suas taxas mais elevadas de mutação. Com o
tempo, os genes para o reparo de DNA à prova de erros se espalhariam por toda a sociedade.
A complexidade do sistema de reparo do DNA sugere que a evolução seguiu em grande
medida esse caminho, mas parou antes que a eliminação do erro se completasse. Nossas
células parecem projetadas para deixar a porta para a mutação levemente entreaberta, apenas
o suficiente para deixar entrar um pequeno fio de mudança e variação, sem efeitos
catastróficos para a população como um todo. Estudos recentes sugerem que a taxa de mutação
nas células germinativas humanas é de cerca de um em 30 milhões de pares de bases, o que
significa que cada vez que os pais transmitem seu DNA para um filho essa herança genética
vem com cerca de 150 mutações. Grande parte da maquinaria em nossas células é dedicada à
preservação e à reprodução do sinal do código genético. Mesmo assim, a evolução abriu
espaço para o ruído.
Seria essa taxa de erro o resultado de pressões seletivas, ou apenas um reflexo do fato de
que a evolução não é perfeita? Os seres humanos têm uma visão relativamente boa enquanto
mamíferos, mas não somos capazes de ler um texto de revista a 150 metros de distância. Isso
não é necessariamente um sinal de que há algo de adaptativo nessa limitação; é mais provável
que seja difícil construir um olho que possa enxergar tão bem. Por mais poderosa que seja, a
evolução não pode fazer tudo. Seríamos talvez mais “adaptados” evolutivamente se
conseguíssemos correr 150 quilômetros por hora, mas as restrições de nossa estrutura óssea e
muscular impediram que fôssemos capazes de correr mais que os guepardos. Por que o mesmo
não poderia ser verdadeiro em relação a nosso sistema imperfeito de reparo do DNA?
É possível que a replicação perfeita seja apenas um limite ideal do qual a seleção natural
só pode se aproximar de maneira assimptótica. Para nossos objetivos, de fato, não importa se
a seleção sintonizou nossos sistemas de reparo de DNA para certo nível de ruído ou se eles
apenas não alcançaram seu “objetivo” de reprodução perfeita. De uma maneira ou de outra, o
ruído teve de ser preservado, pois sem ele a evolução cessaria pouco a pouco. Mas a hipótese
da sintonização tem sido apoiada ultimamente por pesquisas intrigantes. As bactérias têm
taxas de mutação muito maiores que as formas de vida multicelulares, o que sugere que a
tolerância ao erro varia segundo as condições específicas dos diferentes organismos. Um
estudo realizado por Susan Rosenberg no Baylor College descobriu que as bactérias
aumentavam bastante suas taxas de mutação ao enfrentar o “estresse” de baixos suprimentos de
energia. Quando a vida está boa, sugere a pesquisa de Rosenberg, as bactérias têm menos
necessidade de altas taxas de mutação, porque suas estratégias atuais estão bem-adaptadas ao
ambiente. Mas, quando o cenário fica mais hostil, a pressão para inovar – para encontrar
alguma nova maneira de ganhar a vida num ambiente de recursos escassos – muda o equilíbrio
entre risco e recompensa da mutação. O risco de ter a própria prole morta por alguma mutação
fatal não parece tão ruim se ela estiver fadada a morrer de fome de qualquer maneira. E, se
uma dessas mutações ajudar as bactérias a usar os recursos energéticos limitados com mais
eficiência, o novo gene rapidamente se espalhará pela população, enquanto as bactérias não
mutantes morrem pouco a pouco.
Em certo sentido, as bactérias mutantes de Rosenberg seguem uma estratégia semelhante
àquela adotada pelas pulgas-d’água em sua oscilação entre reprodução sexual e assexual.
Quando a subsistência fica difícil, a vida tende a gravitar em direção a estratégias inovadoras
de reprodução, por vezes introduzindo mais ruído no sinal do código genético, por vezes
permitindo aos genes circular mais depressa através da população.
Verifica-se que sexo e erro têm uma longa história em comum, o que talvez não seja
novidade para os que se lembram da própria vida amorosa nos tempos de faculdade. Uma das
vantagens fundamentais da reprodução sexual é permitir que genes mutantes se desprendam
daqueles genes que aumentam as taxas de mutação. Imagine uma bactéria que possua um gene
que iniba de leve o reparo de seu DNA, aumentando sua taxa total de mutação. A maior parte
dessas mutações não terá consequências, ou será pura e simplesmente fatal. Mas imagine que
um dia a bactéria tire a sorte grande e tope com uma mutação que aumente sua adequação
reprodutiva – por exemplo, permitindo ao organismo detectar fontes de alimento de modo
mais eficiente. Nossa afortunada bactéria se divide em duas e passa seus genes à geração
seguinte. O problema é que essa nova geração recebe uma herança mista: recebe o novo gene,
mas herda também aquele que produz maiores taxas de mutação. Como as mutações negativas
são muito mais prováveis que as positivas, através das gerações, as vantagens do gene
eficiente na busca de alimento são esmagadas pelo ruído introduzido pelo gene que causa
taxas de mutação mais altas. Mas, se nossa bactéria de sorte passar de repente para o modo de
reprodução sexual, como a pulga-d’água, o resultado poderia ser bem diferente, porque na
reprodução sexual um organismo só transmite a metade dos seus genes para a prole. A geração
seguinte pode herdar o dom do pai para procurar comida e o talento da mãe para um esmerado
reparo do DNA.
Já exploramos algumas das razões por que a evolução gravitou rumo ao sistema muito mais
complexo da reprodução sexual: ele permite que inovações potencialmente úteis se espalhem
através da população e às vezes colidam e juntem forças com outras inovações. Porém,
quando pensamos sobre sexo no contexto desses genes da mutação e da busca de alimentos,
fica claro que também houve outro motivo para que grande parte da vida na Terra abraçasse
essa forma de reprodução: o sexo ajudava no aproveitamento da força produtiva do erro ao
mesmo tempo que mitigava os riscos. Ele mantém aberta apenas uma fresta da porta para o
possível adjacente, de modo que possamos nos adaptar às pressões ou oportunidades de nosso
ambiente. Ao manter a abertura tão estreita, também mantém as taxas de mutação sob controle,
e essa é uma razão fundamental para a bactéria assexual ter taxas de erro tão mais altas que a
vida multicelular. O sexo nos permite aprender com os erros de nossos genes.
É essa relação complicada entre precisão e erro, entre sinal e ruído, que explica a pesquisa
de Charlan Nemeth sobre associação livre e a deliberação de júris. Quando um dos pares diz
que a pintura azul é verde, ou se ergue em defesa de um suspeito claramente culpado,
tecnicamente falando, ele introduz informação mais inexata no ambiente. Mas esse ruído torna
os outros mais argutos, mais inovadores, certamente porque são forçados a repensar seus
preconceitos, a contemplar um modelo alternativo em que as pinturas azuis são, na verdade,
verdes. A correção é como os estados de sincronia de fase do cérebro humano, em que todos
os neurônios se excitam em perfeita harmonia. Precisamos desses estados pela mesma razão
por que precisamos da verdade: um mundo de erro e caos completos seria intratável, tanto no
nível social quanto no neuroquímico (para não mencionar o genético). Mas deixar algum
espaço para erros produtivos é importante também. Ambientes inovadores prosperam graças a
erros úteis e sofrem quando as demandas de controle de qualidade os esmagam. Grandes
organizações gostam de seguir regimes perfeccionistas, como Six Sigma e Gestão da
Qualidade Total (TQM, na sigla em inglês), sistemas inteiros dedicados à eliminação do erro,
desde a sala de reuniões até a linha de montagem. Mas não é por acaso que um dos mantras do
mundo das start-ups da web é “fracasse mais depressa” (“ fail faster”). Não quer dizer que
os erros sejam a meta – afinal, continuam sendo erros, e por isso se deve passar por eles
depressa. Mas são um passo inevitável no caminho da verdadeira inovação. Benjamin
Franklin, que por experiência própria sabia algumas coisas sobre inovação, expressou isso
muito bem: “Talvez a história dos erros da humanidade seja, afinal de contas, mais valiosa e
interessante que a de suas descobertas. A verdade é uniforme e estreita; existe de maneira
constante; e, para encontrá-la, parece ser necessário menos uma energia ativa que uma aptidão
passiva da mente. Os erros, porém, são infinitamente variados.”
a Projeto de lei destinado a fornecer melhores oportunidades aos veteranos da Segunda Guerra Mundial. Assinada pelo

presidente Roosevelt em junho de 1944, a lei proporcionou ajuda federal a ex-combatentes nas áreas da hospitalização, compra
de casas, negócios e em especial educação, estimulando veteranos a levar adiante seus estudos secundários ou universitários.
(N.T.)

6. Exaptação
DOIS ANOS ANTES DE MORRER em uma ousada tentativa de salvar amigos após a erupção do
Vesúvio, Plínio, o Velho, lendário historiador e erudito romano, completou sua
protoenciclopédia Naturalis Historiae. Nela, ele conta a história de um dispositivo que os
vinicultores tinham inventado havia pouco, um novo tipo de prensa que empregava um
parafuso para “concentrar a pressão sobre pranchas largas colocadas sobre as uvas, que são
cobertas também com grandes pesos por cima”. Há algum debate entre os estudiosos sobre a
possibilidade de que Plínio estivesse torcendo para o time de casa ao atribuir a invenção a
seus compatriotas, já que evidências do uso de prensas de parafuso na produção de vinhos e
azeites remontam aos gregos, vários séculos antes. Mas, seja qual for a data exata de sua
origem, a utilidade prática da prensa de parafuso assegurou que, diferentemente de tantas
excelentes ideias do período greco-romano, ela sobrevivesse intacta ao longo da Idade Média.
Quando o Renascimento por fim floresceu, mais de um milênio depois da morte de Plínio, a
Europa teve de redescobrir a astronomia ptolomaica e os segredos da construção de
aquedutos, mas não precisou reaprender como prensar uvas. Na verdade, a prensa de parafuso
havia recebido alterações durante todo o tempo, aperfeiçoando e otimizando seu modelo para
a produção de vinhos em massa. Em meados do século XV, a região alemã da Renânia, que
fora historicamente hostil à viticultura por razões climáticas, estava enfeitada de treliças de
parreiras. Estimulados pelo aumento da eficiência da prensa de parafuso, os vinhedos alemães
chegaram ao auge em 1500, cobrindo cerca de quatro vezes mais terra que hoje em dia. Era
um trabalho árduo produzir vinho bebível numa região tão setentrional, mas a eficiência
mecânica da prensa de parafuso o tornava financeiramente irresistível.
Em algum momento por volta de 1440, um jovem empresário renano começou a tentar
melhorar o projeto da prensa de vinho. Ele acabava de sair de um negócio desastroso, a
fabricação de espelhinhos supostamente dotados de poderes mágicos de cura, que pretendia
vender a peregrinos religiosos. (O plano foi por água abaixo, em parte por causa da peste
bubônica, que reduziu de maneira drástica o número de peregrinos.) Mas o fracasso do
negócio das bugigangas provou-se oportuno, já que levou o empresário a um caminho muito
mais ambicioso. Johannes Gutenberg mergulhou na tecnologia dos vinhateiros renanos, mas
não porque estivesse interessado em vinho. Eram as palavras que o interessavam.
Como muitos estudiosos notaram, a prensa de Gutenberg foi uma inovação combinatória
clássica, mais bricolagem que invenção. Todos os elementos essenciais que fizeram dela uma
máquina tão transformadora – o tipo móvel, a tinta, o papel e a própria prensa – haviam sido
desenvolvidos separadamente muito antes que Gutenberg imprimisse sua primeira Bíblia. O
tipo móvel, por exemplo, fora concebido de maneira independente por um ferreiro chinês
chamado Pi Sheng quatro séculos antes. Mas os chineses (e depois os coreanos) não
conseguiram adaptar essa tecnologia para a produção em massa de textos, em grande parte
porque fixavam os caracteres na página mediante a fricção das mãos, o que tornava o processo
pouco mais eficiente que o trabalho do escriba medieval mediano. Graças a sua experiência
como ourives, Gutenberg introduziu algumas modificações brilhantes na metalurgia subjacente
ao sistema do tipo móvel; sem a própria prensa, contudo, suas meticulosas fontes de chumbo
teriam sido inúteis para produzir Bíblias em massa.
Parte importante da genialidade de Gutenberg, portanto, não está em conceber uma
tecnologia inteiramente nova a partir do zero, mas em tomar emprestada uma tecnologia
madura de um campo inteiramente diferente e usá-la para resolver um problema de outra
natureza. Não sabemos ao certo que cadeia de eventos levou Gutenberg a fazer esse elo
associativo; restam poucos registros documentais de sua vida entre 1440 e 1448, período no
qual reuniu os principais componentes de sua invenção. Mas está claro que ele não tinha
nenhuma experiência anterior com a prensagem de uvas. A revolução radical que operou se
baseou antes na onipresença da prensa de parafuso na cultura de fabricação de vinho na
Renânia e em sua própria capacidade de ir além de seu campo específico de conhecimento e
inventar novos usos para uma tecnologia mais antiga. Gutenberg pegou uma máquina destinada
a embriagar pessoas e transformou-a numa máquina para a comunicação de massa.
OS BIÓLOGOS EVOLUCIONÁRIOS têm uma palavra para esse tipo de empréstimo, proposta pela
primeira vez por Stephen Jay Gould e Elisabeth Vrba num influente ensaio publicado em 1971:
exaptação. Um organismo desenvolve um traço otimizado para um uso específico, mas depois
ele é apropriado para uma função completamente diferente. O exemplo clássico, destacado no
ensaio de Gould e Vrba, são as penas das aves, que, segundo se acredita, foram desenvolvidas
de início para fins de regulação da temperatura, ajudando dinossauros não voadores do
período Cretáceo a se proteger do frio. Quando alguns de seus descendentes, entre os quais
uma criatura que hoje chamamos de Archaeopteryx, começaram a fazer experiências com o
voo, as penas se revelaram úteis para controlar o fluxo de ar sobre a superfície da asa,
permitindo a essas primeiras aves planar.
A transformação inicial é quase acidental: uma ferramenta esculpida por pressões
evolucionárias para uma finalidade passa a ter uma propriedade inesperada que ajuda o
organismo a sobreviver de uma nova maneira. Mas, uma vez que essa nova propriedade é
posta em uso, depois que o Archaeopteryx começa a usar suas penas para planar, o traço
evolui segundo outro conjunto de critérios. Todas as penas de voo, por exemplo, têm uma
acentuada assimetria: as barbas de um lado (ou lâmina) da haste central são maiores que as do
lado oposto. Isso lhes permite atuar como uma espécie de aerofólio, proporcionando
estabilidade durante o bater das asas. Aves que voam em velocidades muito elevadas, como
os falcões, têm assimetrias mais acentuadas que aves mais lentas. No entanto, as penas da
penugem, que só isolam o corpo, são perfeitamente simétricas. Quando as penas só servem
para manter o organismo aquecido, não há vantagem em construí-las ligeiramente enviesadas.
Mutações ou outros tipos de variabilidade geral no pool genético produzem inevitavelmente
penas um pouco menos simétricas que a média, mas esses traços não se intensificam e se
difundem através das gerações, pois não proporcionam nenhuma vantagem reprodutiva em
relação às penas normais. Mas, uma vez que a velocidade de voo se torna uma propriedade
com implicações importantes para a sobrevivência, essas barbas assimétricas revelam-se de
extrema utilidade. Ali onde anteriormente a assimetria entrava e saía do pool genético, a
seleção natural começa a esculpir essas penas de modo a torná-las mais aerodinâmicas. Uma
pena adaptada para o aquecimento é então exaptada para o voo.
O conceito de exaptação é decisivo na refutação do clássico argumento bíblico (hoje
muitas vezes chamado de “projeto inteligente”) contra o darwinismo, argumento que remonta
ao furor que envolveu a publicação do livro A origem das espécies: se exemplos
extraordinários de engenharia natural como olhos ou asas não são produto de um criador
inteligente, como puderam esses traços sobreviver ao longo do que deve ter sido um estado de
desenvolvimento de pronunciada não funcionalidade? Enquanto se desenvolve, a asa precisa
passar, por definição, por um longo período em que é completamente inútil para voar. (Como
diz um ditado: “De que valem 5% de uma asa?”) Como a seleção natural não “sabe” que está
tentando construir uma asa, não pode impulsionar essas asas primitivas rumo à meta final de
voar como um engenheiro mecânico pode fazer com um aeromodelo até que ele decole. Se
essa asa incipiente não ajuda uma ave a voar, permitindo-lhe assim levar a melhor sobre seus
predadores ou descobrir novas fontes de alimento, as novas mutações que tornaram esse
apêndice ligeiramente mais parecido com uma asa não terão uma probabilidade maior de se
espalhar pela população. A seleção natural não dá prêmios por esforço.
Mas, quando pensamos em inovações evolucionárias em termos de exaptação, a história se
torna muito menos misteriosa. Mais uma vez, acaso e felizes coincidências ganham um papel
central na narrativa: mutações aleatórias levam à evolução de penas selecionadas para fins de
aquecimento, e por acaso elas se revelam úteis para o voo, em particular depois de
modificadas para criar um aerofólio. Por vezes essas exaptações tornam-se possíveis porque
outras delas estão acontecendo no seio da espécie – pensa-se que a própria asa é uma
exaptação de um osso do pulso de um dinossauro, adaptado originalmente para fins de maior
flexibilidade. Ao propor a metáfora da transformação de pneus em sandálias, Gould falava,
em essência, sobre a maneira como a exaptação definiu os caminhos da inovação
evolucionária: novas habilidades e traços surgem não por haver na biosfera uma marcha
inexorável rumo à complexidade cada vez maior, mas porque a seleção natural tem o instinto
do sapateiro de Nairóbi de se apropriar de peças velhas e dar-lhes novos usos.
Com frequência esses novos usos tornam-se possíveis graças a mudanças externas no
ambiente de um organismo. Quando o peixe de nadadeiras lobadas Sarcopterygii começou a
explorar a vida na beira da água, 400 milhões de anos atrás, a criatura tinha um pequeno leque
na ponta da nadadeira, sustentado por estreitos ossículos. À medida que seus descendentes
começaram a passar mais tempo fora da água, explorando as abundantes fontes de energia das
plantas e dos artrópodes que já haviam conquistado a vida sobre a terra, a ponta da nadadeira
lobada revelou-se útil para uma atividade que a vida aquática havia tornado inconcebível:
andar. Em pouco tempo, a seleção natural remodelou o leque em autopódio, a arquitetura
básica dos tornozelos e dos pés de todos os mamíferos. Com o tempo, o próprio autopódio
seria exaptado de várias maneiras: criando as mãos e os dedos dos primatas, otimizados para
agarrar, ou aquelas asas do Archaeopteryx. Em alguns casos, o autopódio foi até exaptado de
volta para suas antigas origens, como nas nadadeiras das focas e dos leões-marinhos.
SE MUTAÇÃO, ERRO E SERENDIPIDADE abrem novas portas no possível adjacente da biosfera, a
exaptação nos ajuda a explorar as novas possibilidades que se escondem atrás delas. Um
fósforo que acendemos para iluminar uma sala escura vem a ter um uso completamente
diferente quando abrimos a porta e descobrimos uma sala com uma pilha de lenha e uma
lareira. Uma ferramenta que nos permite ver em um contexto acaba nos ajudando a nos aquecer
em outro. Essa é a essência da exaptação.
É tentador presumir que o mecanismo da inovação cultural está mais próximo daquele
engenheiro fazendo experiências com seu aeromodelo do que do afortunado Archaeopteryx
que salta do alto da árvore e descobre que suas penas não são apenas um agasalho. Ninguém
contesta o papel do projeto inteligente na história da cultura humana. Mas as exaptações
abundam na história da criatividade humana. No início do século XIX, Joseph-Marie
Jacquard, um tecelão francês, desenvolveu os primeiros cartões perfurados para tecer padrões
complexos de seda em teares mecânicos. Algumas décadas depois, Charles Babbage tomou
emprestada a invenção de Jacquard para programar a máquina analítica. Os cartões perfurados
continuariam fundamentais para computadores programáveis até a década de 1970. Lee de
Forest criou o Audion com um objetivo claro: detectar e amplificar sinais eletromagnéticos.
Nunca lhe ocorreu que a arquitetura do tríodo poderia ser aplicada com igual facilidade à
construção de uma bomba de hidrogênio. Em termos evolucionários, o tubo de vácuo foi
originalmente adaptado para tornar o volume dos sinais mais alto, mas acabou sendo exaptado
para transformar esses sinais em informação: zeros e uns que podiam ser manipulados de
maneiras impressionantes. Um amplificador de guitarra Fender dos anos 1950, que se baseava
num tubo de vácuo para aumentar o sinal dos primeiros guitarristas do rock’n’roll, era em
última análise uma variação do sistema original de amplificação de De Forest. Porém, aqueles
17 mil tubos de vácuo dentro do ENIAC, fazendo os cálculos da física de uma bomba de
hidrogênio, estavam servindo a uma função que jamais passou pela cabeça de De Forest, por
mais imaginativo que ele fosse. Hoje, mercados emergentes de patentes, como o
GreenXchange da Nike, permitem exaptações comerciais que seriam impensáveis no ambiente
encastelado dos laboratórios de P&D tradicionais.
A história da World Wide Web é, em certo sentido, uma história de contínua exaptação. Tim
Berners-Lee projetou os protocolos originais pensando num ambiente especificamente
acadêmico, criando uma plataforma para o compartilhamento de pesquisas num formato de
hipertexto. Mas, quando as primeiras páginas da web se espalharam para além dessa sopa
primordial acadêmica e começaram enfrentar consumidores comuns, a invenção de Berners-
Lee revelou possuir um número extraordinário de qualidades imprevistas. Exaptou-se uma
plataforma adaptada para o estudo acadêmico para permitir compras, compartilhamento de
fotos e observação de pornografia – junto com milhares de outros usos que teriam estarrecido
Berners-Lee quando ele criou os primeiros diretórios baseados em HTML no início dos anos
1990. Quando Sergey Brin e Larry Page tiveram a ideia de usar links entre páginas da web
como votos digitais que endossavam o conteúdo dessas páginas, estavam exaptando o projeto
original de Berners-Lee: tomaram uma característica adaptada para a navegação – o link de
hipertexto – e a usaram como um veículo de avaliação de qualidade. O resultado foi o
PageRank, o algoritmo original que transformou o Google no gigante que é hoje.
O historiador da literatura Franco Moretti documentou de maneira persuasiva o papel da
exaptação na evolução do romance. Um autor concebe um novo tipo de recurso narrativo para
atender a uma necessidade local, específica, numa obra que está escrevendo. Alguma coisa
nesse recurso atrai outros autores, e ele começa a circular através do pool genético literário.
Depois, à medida que o ambiente literário muda e novas possibilidades imaginativas se
tornam necessárias, o recurso passa a ter uma função diferente, muito distante de seu uso
original. O romancista francês Édouard Dujardin usou pela primeira vez a técnica do “fluxo de
consciência” no romance Les lauriers sont coupés, de 1888; nessa obra, a técnica fica restrita
a curtos períodos de introspecção entre os principais acontecimentos da história, breves
parênteses dentro da trama. Três décadas depois, porém, James Joyce pegaria a técnica e a
transformaria em um dos mais memoráveis e fascinantes modos perceptivos, usando o recurso
em seu romance Ulisses para capturar a agitação e a dispersão da vida mental numa cidade
alvoroçada. Quando Dickens inventou seu inspetor Bucket para reunir os múltiplos fios da
coincidência metropolitana em A casa abandonada, não tinha a menor ideia de que seu
artifício ajudaria a criar todo um novo gênero, a ficção policial, que se estenderia de A pedra
da lua de Wilkie Collins até Assassinato por escrito, passando por Sherlock Holmes. Novos
gêneros requerem velhos recursos.
Exaptações retóricas ou figurativas não são propriedade exclusiva das artes. A história da
inovação científica e tecnológica também está cheia delas. Em The Act of Creation, Arthur
Koestler afirmou que “todos os eventos decisivos na história do pensamento científico podem
ser descritos em termos de fecundação cruzada mental entre diferentes disciplinas”. Conceitos
migram de um campo para outro como uma espécie de metáfora estruturante, abrindo assim
uma porta secreta que por muito tempo não pudera ser vista. Em suas memórias, Francis Crick
conta que atinou pela primeira vez com a ideia do sistema de replicação complementar do
DNA – cada base A se conecta com uma T, e cada base C com uma G – ao pensar no modo
como podemos reproduzir uma escultura fazendo uma impressão em gesso e usando-a, depois
de seca, como molde para criar cópias. Johannes Kepler atribuiu suas leis do movimento
planetário a uma metáfora generativa importada da religião; imaginou o Sol, as estrelas e o
espaço escuro que as separa como os equivalentes celestes do Pai, do Filho e do Espírito
Santo. Quando pioneiros da ciência da computação como Doug Engelbart e Alan Kay
inventaram a interface gráfica, importaram uma metáfora do ambiente dos escritórios no
mundo real: em vez de organizar a informação na tela como uma série de entradas de linha de
comando, como um programador faria, tomaram emprestada a iconografia de uma escrivaninha
com pilhas de papéis em cima. Kekulé não pensou que a molécula de benzeno era literalmente
uma serpente da mitologia grega, mas seu conhecimento desse símbolo antigo o ajudou a
resolver um dos problemas essenciais da química orgânica.
NO INÍCIO DOS ANOS 1970, um sociólogo de Berkeley chamado Claude Fischer começou a
investigar os efeitos sociais da vida em centros urbanos densos. Esse assunto interessava
havia muito aos teóricos do urbanismo, entre os quais Louis Wirth, que num famoso ensaio de
1938, “Urbanism as a Way of Life”, afirmou que a vida metropolitana levava à desorganização
social e à alienação, com a dissolução dos laços sociais e do conforto das comunidades
menores no tumulto da cidade grande. Como a argumentação de Wirth não se confirmara com o
passar do tempo – bairros densamente povoados revelavam abrigar laços sociais muito
complexos e ricos, quando se procurava por eles –, Fischer dispôs-se a verificar quais
padrões sociais eram de fato induzidos pelo ambiente das grandes cidades. Sua pesquisa o
levou a uma conclusão impressionante, publicada num artigo seminal em 1975: cidades
grandes alimentam subculturas de maneira muito mais vigorosa que subúrbios ou cidades
pequenas.
Estilos de vida ou interesses que se desviam do padrão dominante precisam de massa
crítica para sobreviver; em comunidades menores eles se atrofiam, não por estas serem mais
repressivas, mas sim porque a probabilidade de encontrar pessoas com ideias semelhantes é
muito mais baixa quando o universo de indivíduos é menor. Se um décimo de 1% da
população for apaixonado por, digamos, colecionar besouros ou teatro improvisado, numa
cidade de tamanho médio isso não equivale a mais que uma dúzia de indivíduos. Numa grande
cidade, porém, significa milhares de pessoas. Como Fischer observou, esse acúmulo cria um
ciclo de realimentação positiva, pois os residentes mais inconvencionais dos subúrbios ou
áreas rurais migram para a cidade em busca de companheiros de viagem. “A teoria ... explica
ao mesmo tempo o que as cidades têm de ‘ruim’ e de ‘bom’”, escreveu Fischer. “A
inconvencionalidade criminosa e a inovadora (por exemplo, artística) são ambas alimentadas
por subculturas vibrantes.” Coletivos de poesia e gangues de rua podem parecer estar
separados por quilômetros de distância, mas ambos dependem da capacidade que a cidade
tem de alimentar subculturas.
O mesmo padrão se aplica a ofícios e negócios em cidades grandes. Como Jane Jacobs
observou em The Death and Life of Great American Cities: “Quanto maior é a cidade, maior
a variedade de sua indústria, e maior também o número e a proporção de seus pequenos
fabricantes.”
Cidades pequenas e subúrbios, por exemplo, são lares naturais para enormes supermercados e pouco mais em matéria de
comestíveis, para cinemas comuns ou drive-ins e outras poucas salas de espetáculo. Simplesmente não há gente suficiente
para sustentar maior variedade, embora possa haver pessoas (muito poucas) que fariam uso dela, caso existisse. As cidades
grandes, porém, são lares naturais de supermercados e cinemas comuns, além de delicatessens, confeitarias vienenses, lojas
de comestíveis estrangeiros, cinemas de arte e assim por diante, tudo isso coexistindo, o comum com o estranho, o grande
com o pequeno. Onde quer que encontremos trechos de cidades animados e apreciados, o pequeno é muito mais numeroso
que o grande.
Tanto Fischer e quanto Jacobs enfatizam as férteis interações que ocorrem entre subculturas
num centro urbano denso, o inevitável excesso que se produz sempre que seres humanos se
aglomeram em grandes grupos. Subculturas e negócios ecléticos geram ideias, interesses e
habilidades que se difundem inevitavelmente através da sociedade, influenciando outros
grupos. Nas palavras de Fischer: “Quanto maior é a cidade, mais provável é que contenha, em
número e unidade significativos, viciados em drogas, radicais, intelectuais, adeptos da troca
de casais, entusiastas da alimentação natural ou qualquer outra coisa; e mais provável é que
eles influenciem (bem como ofendam) o centro convencional da sociedade.”
As cidades são, portanto, ambientes oportunos para a exaptação, porque cultivam
habilidades e interesses especializados e criam uma rede líquida em que a informação pode
vazar dessas subculturas e influenciar seus vizinhos de maneiras surpreendentes. Essa é uma
explicação para o escalamento superlinear na criatividade urbana. A diversidade cultural
gerada por essas subculturas não é valiosa apenas por tornar a vida urbana menos monótona.
O valor reside também nas migrações improváveis que ocorrem entre os diferentes grupos.
Um mundo em que uma grande diversidade de profissões e paixões se superpõe é um mundo
em que exaptações prosperam.
Muitas vezes esses ambientes compartilhados tomam a forma de um espaço público do
mundo real, o que o sociólogo Ray Oldenburg chamou, numa expressão famosa, de o “terceiro
lugar”, um ambiente conectivo distinto do mundo mais insular da casa ou do trabalho. Na era
do Iluminismo, o café inglês do século XVIII fertilizou incontáveis inovações; as coisas mais
diversas, desde a ciência da eletricidade até a própria democracia, passando pela indústria
dos seguros. Freud mantinha um célebre salão nas noites de quarta-feira em sua casa na
Berggasse, número 19, em Viena, onde médicos, filósofos e cientistas se reuniam para ajudar a
moldar o recém-criado campo da psicanálise. Vale lembrar, também, os cafés de Paris, nos
quais muito do modernismo nasceu; ou o lendário Homebrew Computer Club, nos anos 1970,
onde um conjunto excêntrico de aficionados, adolescentes, empresários digitais e cientistas
acadêmicos conseguiu deflagrar a revolução do computador. De certa forma, os participantes
afluem a esses espaços pela camaradagem de outros que compartilham suas paixões, e sem
dúvida essa rede de apoio aumenta o empenho e a produtividade do grupo. Mas estímulo não
conduz necessariamente à criatividade. Colisões, sim – as colisões que ocorrem quando
diferentes campos de conhecimento convergem num espaço físico ou intelectual
compartilhado. É aí que verdadeiras centelhas voam. O modernismo dos anos 1920 exibiu
tanta inovação cultural num período tão curto porque escritores, poetas, artistas e arquitetos
estavam todos se acotovelando nos mesmos cafés. Não estavam afastados em ilhas separadas,
conduzindo seminários de escrita criativa ou fazendo críticas de design. Essa proximidade
física tornou o espaço rico em exaptação: o fluxo de consciência da literatura influenciando as
novas e estonteantes perspectivas do cubismo; o abraço futurista da velocidade tecnológica na
poesia moldando novos padrões de planejamento urbano.
A EXAPTAÇÃO TAMBÉM PROSPERA EM OUTRA ESCALA: o ambiente de mídia compartilhado de
uma comunidade física. No final dos anos 1970, o músico e artista britânico Brian Eno
mudou-se para a cidade de Nova York pela primeira vez. Ocupou um apartamento numa casa
geminada convertida, no coração de Village. A cidade estava no zênite – ou mais
provavelmente no nadir – de sua loucura, enfrentando motins, aterrorizada com o Filho de
Sam,a flertando com a falência. Mas Eno, que tinha vivido na Londres e na Berlim dos anos
1970, estava bem-aclimatado à anarquia urbana. Na verdade, o contraste mais perturbador
com seu passado europeu era a turbulenta mistura de vozes que ouvia no rádio. Após anos
ouvindo as vozes graves e profissionais da BBC, os bizarros discursos do rádio americano lhe
pareciam um novo universo de insanidade.
E assim ele começou a gravá-los. Como muitos músicos experimentais naquela época, Eno
andara explorando as possibilidades de usar tape loops como instrumento musical. (“O
gravador sempre foi o instrumento com o qual eu me sentia mais à vontade”, disse ele uma vez
numa entrevista. “Depois vinham os teclados, com o baixo em um terceiro lugar bem
distante.”) Os Beatles haviam reservado a faixa mais longa do Álbum Branco para uma
colagem de tape loop de Lennon, “Revolution #9”, e o protossintetizador Mellotron,
desenvolvido em meados dos anos 1960, tinha diferentes tape loops montados para serem
acionados por teclas individuais no teclado. Nenhum desses experimentos, porém, havia
realmente empregado a voz falada como elemento harmônico ou percussivo. Afinal, os
zumbidos e murmúrios de “Revolution #9” mal podiam ser considerados musicais por padrões
tradicionais. Mas as horas que Eno passou com os evangelizadores, os anarquistas e os recém-
surgidos shock jocksb haviam enfiado aquelas vozes na sua cabeça, e, quando começou a
trabalhar em colaboração com David Byrne, pôs-se a brincar com a ideia de explorar as
possibilidades musicais delas. O resultado foi My Life in the Bush of Ghosts, uma mescla
absolutamente original de seções de ritmo africano e instrumentos acústicos excêntricos, mas
evitando de maneira notável as tensas estilizações vocais new wave de Byrne – que haviam
tido um papel muito destacado nos álbuns do Talking Heads em que os dois haviam
colaborado anteriormente. Em vez de canto tradicional, Byrne e Eno construíram as canções a
partir de conjuntos superpostos, em loop, extraídos por Eno das ondas do rádio. Foi um estudo
de caso da exaptação criativa: palavras destinadas a difundir a palavra de Jesus em um meio,
ou a bradar contra o complexo militar-industrial, migraram para um novo ambiente e se
tornaram música, contra todas as expectativas.
My Life in the Bush of Ghosts marcou o nascimento de certo tipo historicamente decisivo
de empréstimo musical: não era apenas uma nova música, mas toda uma nova maneira de
pensar sobre com que era possível fazer música. (Algo não muito diferente do modo como,
cinquenta anos antes, Marcel Duchamp e seus companheiros surrealistas haviam mudado
nosso entendimento das coisas com que se podia fazer arte.) Alguns anos depois, quando se
sentou para gravar o álbum It Takes a Nation of Millions to Hold Us Back, Hank Shocklee, o
produtor do Public Enemy, imitou as amostras vocais superpostas e percussivas da produção
de Eno e Byrne. It Takes a Nation veio a ser um dos discos mais influentes da década,
reverberando através da cultura mais ampla – em todo tipo de coisa, de toques de telefone
celular aos primeiros lugares nas listas da Billboard, passando pela experimentação de
vanguarda –, tal como Highway 61 Revisited e Pet Sounds haviam feito uma geração antes. A
inovação de Eno foi brilhante, sem dúvida, e, à distância, quase parecia um momento eureca
clássico do “gênio solitário”: o inovador trancado em seu laboratório que descobre uma ideia
que transformaria a cultura popular. Porém, um elemento fundamental na história é que Eno
não estava, tecnicamente falando, sozinho com seu gravador, mas inserido em uma rede das
mais diferentes vozes, todas discursando em diferentes frequências. Eno não precisou de um
café. Ele tinha um aparelho de rádio AM.
NO FINAL DOS ANOS 1990, Martin Ruef, professor da Stanford Business School, decidiu
investigar a relação entre inovação nos negócios e diversidade. Ruef estava interessado no
modelo de diversidade dos cafés, não no tipo “melting pot” político: a diversidade de
profissões e disciplinas, não de raça ou orientação sexual. Ele entrevistou 766 pessoas
formadas na Stanford Business School que haviam ingressado em carreiras empresariais.
Criou um sistema complexo para classificar inovações com base numa combinação de fatores:
a introdução de novos produtos, digamos, ou o registro de marcas e patentes. Depois
acompanhou a rede social de cada sujeito – não só o número, mas o tipo de conhecidos.
Alguns tinham grandes redes sociais agrupadas dentro de suas organizações; outros tinham
pequenos grupos insulares dominados por amigos e parentes. Alguns tinham vastas conexões,
com pessoas de fora do círculo íntimo de amigos e colegas.
O que Ruef descobriu foi uma ressonante confirmação do modelo de relacionamento social
dos cafés: em seu levantamento os indivíduos mais criativos possuíam invariavelmente redes
sociais amplas que se estendiam além de sua empresa e envolviam pessoas especializadas em
diversas áreas. Redes sociais diversificadas e horizontais, na análise de Ruef, eram três vezes
mais inovadoras que redes uniformes e verticais. Em grupos unidos por valores
compartilhados e intimidade duradoura, a concordância e a convenção tendiam a suprimir
quaisquer potenciais centelhas criativas. O alcance limitado da rede significava que conceitos
interessantes do exterior raramente penetravam na consciência do empresário. Mas aqueles
que construíam pontes para fora de suas “ilhas”, como Ruef as chamou, eram capazes de tomar
emprestadas ou cooptar novas ideias desses ambientes externos e aplicá-las a um novo
contexto. Um estudo semelhante conduzido por Ronald Burt, professor da escola de negócios
da Universidade de Chicago, examinou a origem de boas ideias dentro da rede organizacional
da Raytheon Corporation. Burt descobriu que o pensamento inovador tinha muito mais
probabilidade de emergir de indivíduos que transpunham “lacunas estruturais” entre grupos
muito coesos. Se comparados a outros que mantinham vínculos ativos com um grupo mais
diversificado, empregados que partilhavam informação essencialmente com pessoas de sua
própria divisão tinham mais dificuldade em propor sugestões úteis para os negócios da
Raytheon.
Em certa medida, as pesquisas de Ruef e de Burt são uma validação do célebre argumento
da “força dos laços fracos”, proposto pela primeira vez por Mark Granovetter e popularizado
por Malcolm Gladwell em The Tipping Point. Mas observar os laços fracos de uma rede
social extensa através das lentes da exaptação muda o quadro de uma maneira importante: os
laços fracos não permitem apenas à informação viajar através da rede de maneira mais
eficiente – isto é, sem ficar presa na ilha distante de um grupo muito coeso. Da perspectiva da
inovação, é até mais importante que a informação que chega de um desses laços fracos venha
de um contexto diferente, o que o estudioso da inovação Richard Ogle chama de um “espaço
de ideias”: um complexo de ferramentas, crenças, metáforas e objetos de estudo. Uma nova
tecnologia desenvolvida em um espaço de ideias pode migrar para outro espaço de ideias
através dessas conexões de longa distância; nesse novo ambiente, a tecnologia pode revelar
propriedades inesperadas ou provocar uma conexão que conduza a uma nova descoberta. O
valor do laço fraco não se deve apenas à velocidade com que transmite informação através de
uma rede; ele também promove a exaptação dessas ideias. Embora formado como
metalúrgico, Gutenberg tinha laços fracos com os vinhateiros da Renânia alemã. Sem esse
vínculo, teria sido apenas um tipógrafo pioneiro, fazendo pequenos aperfeiçoamentos no tipo
móvel de Pi Sheng. Ao não se dedicar com exclusividade à ilha da metalurgia, tornou-se algo
muito mais importante: o pai da impressão.
O modelo da exaptação baseada no laço fraco também nos ajuda a compreender uma
clássica história de epifania científica do século XX: a descoberta da estrutura em hélice
dupla do DNA por Watson e Crick. Como Ogle e outros observaram, na pequena comunidade
científica que trabalhava com o problema do DNA no início dos anos 1950, a pessoa que tinha
a visão mais clara e direta da própria molécula não era nem James Watson nem Francis Crick.
Era Rosalind Franklin, uma biofísica da Universidade de Londres, que estava usando uma
tecnologia de ponta, a cristalografia de raios X, para estudar os misteriosos fios do DNA. Mas
a visão de Franklin era limitada por dois fatores. Em primeiro lugar, a tecnologia dos raios X
era ainda imperfeita, dando-lhe apenas indícios sobre a estrutura em hélice e a simetria dos
pares de bases. Franklin estava também limitada pela ilha conceitual em que baseava seu
trabalho. Sua abordagem era puramente indutiva: dominar a tecnologia dos raios X e depois
usar a informação obtida para construir um modelo do DNA. (“Vamos deixar que os dados nos
revelem a estrutura”, disse ela a Crick numa frase famosa.) No entanto, para “ver” a hélice
dupla no início dos anos 1950 não bastava analisar o DNA numa máquina de raios X. Para
solucionar o mistério, Watson e Crick tiveram de juntar as peças com ferramentas tomadas de
múltiplas disciplinas: bioquímica, genética, teoria da informação e matemática, para não falar
nas imagens de raios X de Franklin. Até a metáfora escultural de Crick provou-se decisiva
para decifrar o código. Perto de Franklin, Watson e Crick pareciam quase diletantes e
amadores: Crick trocara a física pela biologia durante a pós-graduação; nenhum dos dois tinha
uma compreensão abrangente de bioquímica. Mas o DNA não era um problema passível de ser
resolvido no âmbito de uma única disciplina. Watson e Crick tiveram de fazer empréstimos em
outras áreas para compreender a molécula. Como Ogle o expressou, “depois que ideias
fundamentais, tomadas de espaços de ideias que normalmente tinham pouco contato uns com
os outros, foram conectadas, elas começaram, de maneira quase autônoma, a fazer um novo
sentido em relação umas com as outras, levando ao surgimento de um todo que era mais que a
soma de suas partes”. A título de nota de rodapé, vale acrescentar que Watson e Crick eram
conhecidos por fazer longas pausas para o cafezinho, nas quais jogavam conversa fora num
ambiente mais descontraído, fora do laboratório – um costume em geral desdenhado pelos
colegas mais exigentes. Com suas conexões de laço fraco com campos díspares e sua
inteligência exaptativa, Watson e Crick abriram caminho para um prêmio Nobel na mesa de
seu café particular.
A APLICAÇÃO DO MODELO DO CAFÉ À CRIATIVIDADE ajuda a explicar um daqueles estranhos
paradoxos da inovação nos negócios no século XXI. Mesmo depois que grande parte da
cultura high-tech abraçou as redes líquidas e descentralizadas em sua abordagem à inovação, a
companhia sempre classificada como a mais inovadora do mundo – a Apple – permanece
desafiadoramente no caminho inverso, cercando o desenvolvimento de novos produtos de um
sigilo quase cômico. Você não verá Steve Jobs ou Jonathan Ive recorrendo ao crowdsourcing
para desenvolver a próxima geração do iPhone. Se redes abertas e densas levam a mais
inovação, como explicar o caso da Apple, que está muito mais perto da fábrica de chocolate
de Willy Wonka do que da Wikipédia no que se refere à abertura? A resposta mais fácil seria
que Jobs e Ive simplesmente possuem um gênio colaborativo que permitiu à companhia
produzir um fluxo constante de produtos revolucionários. Não há dúvida de que os dois sejam
imensamente talentosos no que fazem, mas nenhum deles poderia projetar, fabricar, programar
e vender sozinho um produto tão complexo como o iPhone, da maneira como Jobs e Steve
Wozniak construíram o primeiro computador Apple em sua hoje lendária garagem. É evidente
que a Apple tem uma liderança sem paralelo, mas deve haver também algo no ambiente da
empresa que permita que ideias tão revolucionárias cheguem ao mercado.
De fato, embora a Apple tenha adotado em grande medida uma mentalidade de fortaleza em
relação ao mundo exterior, seu processo de desenvolvimento interno é estruturado de maneira
explícita para facilitar choques e conexões entre diferentes perspectivas. O próprio Jobs gosta
de usar a alegoria do protótipo de carro para descrever seu método. Você vai a uma
exposição, vê um protótipo de carro fascinante, extremamente inovador, e pensa: “Eu
compraria isto sem pestanejar.” Cinco anos depois, o carro chega enfim ao mercado e foi
reduzido de uma Ferrari a um Corcel – todas as características verdadeiramente
revolucionárias foram abrandadas ou eliminadas por completo, e o que sobrou mais parece o
modelo do ano passado. O iPod poderia ter tido o mesmo triste destino: Ive e Jobs poderiam
ter esboçado um tocador de música brilhante, revolucionário e, dois anos depois, lançado uma
bobagem. O que manteve a chama acesa?
A questão é que o ciclo de desenvolvimento da Apple é mais parecido com um café do que
com uma linha de montagem. A maneira tradicional de construir um produto como o iPod se
resume a seguir uma cadeia linear de conhecimento especializado. Os projetistas propõem um
aspecto básico e um conjunto de características, depois passam o projeto para os engenheiros,
que descobrem como fazê-lo realmente funcionar. Em seguida isso é passado para a turma da
fabricação, que estuda como produzi-lo em grandes números. Por fim, é enviado para o
pessoal de marketing e vendas, que encontra maneiras de convencer as pessoas a comprar o
produto. Esse modelo é bastante disseminado porque funciona bem em situações em que a
eficiência é fundamental, mas tende a ter efeitos desastrosos sobre a criatividade, pois a ideia
original é podada a cada etapa da cadeia. A equipe de engenheiros dá uma olhada no projeto
original e diz: “Bem, não podemos fazer isso... mas podemos fazer 80% do que vocês
querem.” E depois a equipe de produção diz: “Claro, podemos fazer uma parte disso.” No
final, o projeto original foi tão adulterado que está irreconhecível.
A abordagem da Apple, em contraposição, é mais desorganizada e caótica a princípio, mas
evita esse problema crônico do esvaziamento das boas ideias à medida que elas avançam pela
cadeia de desenvolvimento. A empresa a chama de produção paralela ou concorrente. Todos
os grupos – projeto, fabricação, engenharia, vendas – se encontram continuamente durante o
ciclo de desenvolvimento do produto, fazendo brainstormings, trocando ideias e soluções,
criando estratégias para a abordagem dos problemas mais prementes e em geral mantendo a
conversa aberta para um leque diversificado de perspectivas. O processo é ruidoso e envolve
muito mais reuniões abertas e encontros conflituosos que os ciclos de produção tradicionais –
e muito mais diálogo entre pessoas versadas em diferentes disciplinas, com todas as
dificuldades de tradução que isso gera. Mas os resultados falam por si.
MUITOS DOS GRANDES INOVADORES DA HISTÓRIA conseguiram construir um ambiente de café
interdisciplinar dentro de suas próprias rotinas de trabalho. Conta-se muitas vezes a história
de que Darwin adiou a publicação de sua teoria da evolução por temer a controvérsia que ela
provocaria, em particular depois que a morte de uma filha querida, Annie, traumatizou sua
religiosa mulher, Emma. Mas Darwin também tinha um imenso número de interesses paralelos
para distraí-lo de sua obra: estudava recifes de coral, criava pombos, desenvolvia elaborados
estudos taxonômicos de besouros e cracas, escreveu artigos importantes sobre a geologia da
América do Sul, passou anos pesquisando o impacto das minhocas sobre o solo. Nenhuma
dessas paixões era central para a argumentação que seria por fim publicada em A origem das
espécies, mas todas forneceram úteis elos de associação e conhecimento à questão da
evolução. O mesmo padrão eclético aparece em inúmeras outras biografias. Joseph Priestley
saltava entre a química, a física, a teologia e a teoria política. Antes mesmo de se tornar um
estadista, Benjamin Franklin realizou experimentos em eletricidade, teorizou sobre a
existência da Corrente do Golfo, projetou fogões e, é claro, ganhou uma pequena fortuna como
impressor. Enquanto solucionava o mistério do cólera nas ruas de Londres nos anos 1850,
John Snow também inventava uma tecnologia de ponta para a administração do éter,
publicando pesquisas sobre o envenenamento por chumbo e a ressuscitação de crianças
recém-nascidas, sem deixar, durante todo esse tempo, de atender seus pacientes como clínico
geral. Inovadores lendários como Franklin, Snow e Darwin possuem algumas qualidades
intelectuais em comum – certa rapidez de raciocínio, curiosidade insaciável –, mas também
com partilham outro atributo determinante. Todos têm muitos hobbies.
O historiador Howard Gruber gosta de chamar esses projetos concorrentes de “redes de
empreendimentos”, mas prefiro descrevê-los usando um termo contemporâneo que tem sido
muito malvisto nos últimos tempos: multitarefa. Não se trata, é claro, do multitarefa da tela do
computador moderno: passar do e-mail para a planilha e dela para o Twitter em questão de
segundos. O que descrevo é muito mais vagaroso que esse modo frenético da era digital; as
próprias tarefas individuais podem se prolongar por dias ou semanas antes de dar lugar ao
projeto seguinte. Mas há, ainda assim, uma constante variação, não apenas no assunto, mas no
tipo de trabalho realizado em cada uma das tarefas. Havia modos fundamentalmente diferentes
de atividade intelectual envolvidos nos diversos projetos de John Snow. A construção de
engenhocas mecânicas para controlar a temperatura do clorofórmio exigiu habilidades e uma
atitude mental diferentes daquelas exigidas para atender os pacientes ou escrever artigos para
The Lancet. É tentador chamar esse modo de trabalho de “tarefas em série”, no sentido de que
os projetos se sucedem uns aos outros, mas a ênfase na natureza seriada do trabalho obscurece
um aspecto fundamental desse ambiente mental: num modo multitarefa lento, um projeto ocupa
o papel central por uma série de horas ou dias, mas os demais projetos persistem o tempo todo
nas margens da consciência. É essa superposição cognitiva que torna esse modo tão inovador.
O projeto em curso pode exaptar ideias daqueles que estão nas margens, fazer novas
conexões. Não é tanto uma questão de procurar ser original, mas de permitir à mente mover-se
entre múltiplas esferas. O movimento de um campo para outro nos força a abordar barreiras
intelectuais a partir de novos ângulos, ou a tomar ferramentas emprestadas de uma disciplina
para resolver problemas em outra.
A história corrente sobre Snow conta que ele solucionou o problema da transmissão do
cólera pela água contaminada fazendo o trabalho epidemiológico convencional durante o surto
de 1854 no Soho, mas a verdade é que ele desenvolvera uma versão da teoria da transmissão
pela água muito antes daquele ano. Uma razão para não se deixar enganar pela influência da
teoria do “miasma” dominante na época – segundo a qual o cólera era causado pela inalação
de vapores insalubres – foi que seu trabalho com anestesia lhe dera um conhecimento prático
do modo como os gases se difundiam através da atmosfera. Snow raciocinou que a
distribuição geográfica da mortalidade de uma doença transmitida por gás venenoso
obedeceria a um padrão diferente: grande número de mortes nas proximidades imediatas dos
maus odores, declinando muito rapidamente à medida que a distância da fonte original
aumentasse. De maneira semelhante, a formação médica de Snow também o ajudou a descartar
a visão limitada do miasma: ao tratar pacientes acometidos pelo cólera, ele observou que os
efeitos da doença sobre o corpo humano indicavam que o agente fora ingerido, não inalado,
uma vez que produzia quase todo o seu dano direto no sistema digestivo e quase não afetava
os pulmões. Num sentido verdadeiro, para dar seu grande salto na compreensão do cólera,
Snow teve de pensar como químico molecular e como médico. Graças à sua habitual
alternância lenta entre tarefas, ele teve esses sistemas interpretativos prontamente disponíveis
quando se voltou para o mistério do cólera. Como vimos no caso das penas do Archaeopteryx,
Snow não poderia ter previsto que seus experimentos mecânicos com inaladores de
clorofórmio se provariam úteis para livrar o mundo moderno de uma bactéria letal, mas esse é
o poder imprevisível das exaptações. O acaso favorece a mente conectada.
a Assim era conhecido o famoso assassino em série David Richard Berkovitz, que matou pelo menos seis pessoas em Nova
York de julho de 1976 a agosto de 1977, quando foi preso. (N.T.)

b Shock jock é uma gíria pejorativa aplicada a locutores de rádio cujos maneirismos, declarações e ações são ofensivos para
muitos ouvintes. (N.T.)

7. Plataformas
EM 12 DE ABRIL DE 1836, o HMS Beagle zarpou das ilhas Cocos depois de um idílio de duas
semanas que dera a Darwin as provas decisivas de que precisava para sustentar a primeira
grande ideia de sua jovem carreira. Quando o navio deixava as plácidas águas verdes da
laguna, rumando de volta para a Inglaterra passando pelas ilhas Maurício, o capitão FitzRoy
tentou medir a profundidade na periferia do atol com uma linha de mais de 2 mil metros de
comprimento. Não encontrou o fundo. As mensurações de FitzRoy confirmaram, nas palavras
de Darwin, que a “ilha forma uma montanha submarina muito elevada, com lados mais
escarpados até que os do mais abrupto cone vulcânico”. O dado lhe foi fundamental, porque
estava construindo em sua mente uma teoria sobre “montanhas submarinas muito elevadas” e
seu legado geológico.
A teoria havia nascido anos antes como uma intuição: ocorreu-lhe que a teoria da formação
dos atóis de seu mentor Charles Lyell tinha um defeito crítico que girava em torno da
probabilidade estatística de que uma montanha só pudesse se elevar poucos metros acima do
nível do mar. A variação da altura entre as ilhas vulcânicas era imensa: algumas terminavam
em ponta uns três metros acima do nível do mar; outras, como Mauna Kea, se alçavam cerca
de 3 mil metros rumo ao céu. A maioria dos picos vulcânicos situava-se centenas de metros
abaixo da superfície. No entanto, Darwin, como a maioria dos geólogos de sua época, sabia
que os oceanos eram povoados por um imenso número de atóis tropicais que haviam todos, de
algum modo, parado de se elevar cerca de um metro acima do nível do mar. Era como
espalhar cem bolas de futebol num campo e ver vinte delas se agruparem exatamente sobre a
linha do meio de campo. Darwin não dispunha da teoria das placas tectônicas, mas sabia que
massas de terra subiam e desciam por todo o mundo. Não fazia sentido, porém, que essas
forças épicas fossem detidas de algum modo, num número significativo de casos, pela linha
divisória do nível do mar. Um vulcão empurrado para cima por imensas correias
transportadoras deveria, evidentemente, irromper rapidamente através da superfície do oceano
e continuar subindo, como Mauna Kea e inúmeras outras ilhas vulcânicas. Pela mesma lógica,
uma montanha que descesse mar adentro deveria continuar descendo. Por que tantas delas
ficavam emperradas?
Não sabemos ao certo quando a resposta ocorreu a Darwin. É possível que isso tenha
acontecido quando ele se encontrava nas areias brancas de uma praia das ilhas Cocos.
Conhecendo Darwin, é mais provável que ela tenha se aproximado devagar, centímetro por
centímetro, e que algum pedacinho dela lhe tenha chegado quando estava parado naquelas
águas verdes. Embora a ideia fosse simples, era extremamente difícil visualizá-la. Começava
com um princípio definidor: o solo sob os pés de Darwin não era produto de forças
geológicas. Havia sido construído por um organismo.
Esse organismo era da ordem Scleractinia, composta pelos chamados escleractíneos ou
corais-pétreos. Vivo, um escleractíneo individual é um pólipo mole com poucos milímetros de
comprimento. Esses corais crescem em vastas colônias, com novos pólipos aparecendo como
brotos ao lado dos “pais”. Numa das estranhas ironias da biologia marinha, a contribuição
essencial do coral para o ecossistema submarino se dá depois de sua morte. Durante a vida, o
pólipo constrói um exosqueleto à base de cálcio, produzindo um mineral chamado aragonita,
vigoroso o suficiente para permanecer intacto séculos depois da morte de seu hospedeiro
original. Um recife de coral, portanto, é uma espécie de vasto mausoléu submerso: milhões de
esqueletos unidos para formar a dispersão alveolada, labiríntica de um recife.
Durante a quinzena passada nas ilhas Cocos, Darwin havia observado que o solo das ilhas
era inteiramente desprovido de rochas tradicionais. Como escreveu em seu diário: “Em todo o
grupo de ilhas, cada átomo, desde a partícula mais diminuta até grandes fragmentos de rocha,
carrega a marca de um dia ter sido sujeito ao poder do arranjo orgânico.” Em sua vasta
maioria, essas partículas e rochas eram esqueletos de aragonita, os restos mortais de pólipos
de coral que morreram décadas ou séculos antes. Isso por si só provava que a teoria de Lyell
era errônea: se Darwin estivesse parado no topo de um vulcão submarino adormecido, as
rochas a seus pés deviam ser basalto, obsidiana ou púmice, rochas criadas a partir do
esfriamento de lava derretida. Elas teriam sido forjadas num abrasador núcleo de magma, não
excretadas por minúsculos pólipos.
O fato de o solo de um atol do oceano Índico ser de natureza orgânica, construído por
corais, e não o produto de atividade vulcânica, não oferecia uma resposta satisfatória para o
mistério da existência dos atóis. Por que uma colônia de corais formaria um objeto oval tão
perfeito no meio de um imenso oceano, a centenas de quilômetros de outra massa de terra?
Para solucionar o mistério, Darwin lançou mão da teoria original de Lyell, mas acrescentou-
lhe uma alteração essencial. Transformou uma moldura imóvel num quadro em movimento.
Para compreender a formação dos atóis, Darwin percebeu, era preciso imaginar uma ilha
vulcânica afundando pouco a pouco no mar. À medida que desapareciam sob as ondas do
oceano, as encostas do vulcão tornavam-se um terreno extremamente propício à formação de
colônias de coral, que prosperam em águas rasas a profundidades de até cerca de 45 metros.
(A dieta delas baseia-se sobretudo em algas fotossintéticas, que não podem sobreviver muito
longe da superfície da água iluminada pelo sol.) Por fim o topo da montanha afunda no mar,
deixando um círculo de água rasa definido pela periferia da cratera vulcânica. Dada a lentidão
com que afunda, os corais são capazes de construir seus recifes mais rapidamente que o fim
desse processo. Como empreiteiros superzelosos, as colônias de coral continuam adicionando
novos pavimentos à estrutura que erigiram no topo do vulcão, limitadas apenas pela superfície
da água. À medida que o pico original mergulha cada vez mais no mar, os recifes mais velhos
morrem, mas continuam dando suporte estrutural aos novos e florescentes recifes acima deles.
Darwin não tinha meios para medir isso com precisão, mas previu que corais fósseis
deveriam se estender por até cerca de 1.500 metros abaixo do nível do mar antes de atingir
uma fundação vulcânica, número que foi confirmado mais de um século depois com a moderna
tecnologia de perfuração.
Enquanto o Beagle partia, Darwin registrou a natureza milagrosa dessa explicação em seu
diário: “Devemos ver um atol como um monumento erigido por miríades de minúsculos
arquitetos para marcar o ponto onde uma antiga terra jaz enterrada nas profundezas do
oceano.”
Publicada anos mais tarde na forma de monografia, a teoria da formação do atol de Darwin
marcou sua primeira contribuição significativa para a ciência, em grande parte resistindo à
prova do tempo. A própria ideia surgiu de uma espécie de bate-papo de diferentes disciplinas:
para solucionar o mistério, ele teve de pensar ao mesmo tempo como naturalista, biólogo
marinho e geólogo. Precisou compreender o ciclo de vida das colônias de coral e observar as
minúsculas evidências de escultura orgânica nas rochas das ilhas Cocos. Teve de pensar nas
imensas escalas de tempo da elevação das montanhas vulcânicas e de seu afundamento no mar.
E, é claro, contou com a competência técnica de FitzRoy com a sonda. A compreensão da
ideia em toda a sua complexidade requereu uma espécie de inteligência investigativa,
propensa a pensar nos termos dessas diferentes disciplinas e escalas. Darwin fez a melhor
descrição disso no capítulo sobre suas investigações nas ilhas Cocos em A viagem do Beagle:
“Ficamos surpresos quando viajantes nos falam das vastas dimensões das Pirâmides e de
outras grandes ruínas, mas quão absolutamente insignificantes são as maiores delas quando
comparadas a essas montanhas de pedra acumuladas pela atividade de vários animais
minúsculos e tenros. Esse é um prodígio que a princípio não nos enche os olhos do corpo, e
sim, após reflexão, os olhos da razão.”
Da perspectiva de Darwin, esses “animais minúsculos e tenros” haviam construído uma
plataforma, no sentido mais prosaico do termo. Darwin caminhava naquele topo em forma de
pires, sem se esforçar para se manter à tona na água no meio do oceano Índico, porque aqueles
animais haviam construído uma plataforma em que se podia ficar estável. Mas um recife de
coral é uma plataforma num sentido muito mais profundo: os montes, placas e fendas do recife
criam um hábitat para milhões de outras espécies, uma metrópole submarina de imensa
diversidade. Até hoje, as tentativas de medir com precisão a plena diversidade dos
ecossistemas de recifes foram frustradas pela complexidade desses hábitats; os cientistas
acreditam atualmente que algo entre 1 milhão e 10 milhões de espécies diferentes vivem em
recifes de coral no mundo todo, embora estes só ocupem um décimo de 1% da superfície do
planeta. Este é o paradoxo de Darwin: que águas tão pobres em nutrientes tenham podido
gerar tanta vida maravilhosa, improvável, heterogênea.
Durante quarenta anos, os ecologistas usaram a expressão “espécie-chave” para designar
um organismo que tem um impacto desproporcional sobre seu ecossistema – um carnívoro, por
exemplo, que é o único predador de uma outra espécie que, na ausência dele, esmagaria o
hábitat com um crescimento populacional desenfreado. Se o predador-chave for removido, o
hábitat se desintegra. Cerca de vinte anos atrás, porém, Clive Jones, um cientista que
trabalhava no Cary Institute of Ecosystem Studies, decidiu que a ecologia precisava de outra
expressão para descrever um tipo muito específico de espécie-chave, aquele que na realidade
cria o próprio hábitat. Jones chamou esses organismos de “construtores de ecossistemas”. Os
castores são o exemplo clássico de construtores de ecossistemas. Derrubando choupos e
salgueiros para construir represas, eles transformam, sozinhos, florestas temperadas em
brejos, que depois atraem e sustentam um número extraordinário de vizinhos: os pica-paus-de-
penacho furando cavidades para servir de ninho em árvores mortas; patos-carolinos e gansos-
do-canadá instalando-se em tocas de castor abandonadas; garças, martins-pescadores e
andorinhas desfrutando os benefícios da lagoa “artificial”, ao lado de rãs, lagartos e outras
espécies de águas lentas como libélulas, mexilhões e besouros aquáticos. Tal como aquelas
colônias de coral submersas, o castor cria uma plataforma que sustenta um conjunto
extraordinariamente diversificado de vida.
A construção de plataformas é, por definição, uma espécie de exercício de comportamento
emergente. Embora o minúsculo pólipo escleractíneo não esteja ativamente empenhado em
criar uma Las Vegas submersa, sua incessante labuta – assimilando algas e erigindo aqueles
esqueletos de aragonita – gera um sistema de nível mais elevado. O que havia sido um trecho
muito desolado de água do mar pobre em nutrientes é transformado num resplandecente foco
de atividade. O castor constrói uma represa para melhor se proteger de seus predadores, mas
essa engenharia tem o efeito emergente de criar um espaço em que martins-pescadores,
libélulas e besouros podem obter seu sustento. Os construtores de plataformas e de
ecossistemas não apenas abrem uma porta para o possível adjacente. Eles constroem um novo
pavimento inteiro.
A CAFETERIA DO LABORATÓRIO DE FÍSICA APLICADA (LFA) da Universidade Johns Hopkins em
Laurel, Maryland, tinha sido por muito tempo o local de produtivas conversas profissionais
entre físicos, técnicos, matemáticos e proto-hackers que ali trabalhavam. Mas a conversa no
almoço da segunda-feira, dia 7 de outubro de 1957, foi excepcionalmente animada, graças às
manchetes publicadas no fim de semana anunciando o lançamento pelos soviéticos do Sputnik
1 , o primeiro satélite artificial a orbitar em volta da Terra. Dois jovens físicos, William Guier
e George Weiffenbach, viram-se mergulhados numa acalorada discussão sobre os sinais de
micro-ondas que provavelmente estariam emanando do Sputnik. Após indagar de alguns
colegas, apuraram que ninguém se dera o trabalho de ir ao laboratório durante o fim de
semana para ver se era possível captar sinais do satélite no equipamento do LFA. Por acaso,
Weiffenbach se encontrava no meio de uma tese de doutorado sobre espectroscopia de micro-
ondas e tinha um receptor de 20MHz instalado em sua sala.
Guier e Weiffenbach passaram a tarde debruçados sobre o receptor, tentando ouvir a
impressão digital sonora do Sputnik. Para combater os incrédulos, que na certa levantariam a
hipótese de o lançamento ser uma elaborada mistificação, mero produto da propaganda
comunista, os soviéticos haviam construído o satélite de tal maneira que ele transmitisse um
sinal excepcionalmente acessível: um tom ininterrupto transmitido numa margem de 1kHz
perto de 20MHz. No fim da tarde, Weiffenbach e Guier tinham um firme controle do sinal. O
próprio som era um pulso breve de bipes eletrônicos, mas o contexto o transformava na
música mais maravilhosa que os dois homens já tinham ouvido. Parecia inacreditável:
estavam sentados numa sala na suburbana Maryland, ouvindo sinais produzidos pelo homem
que vinham do espaço. A notícia de que dois jovens físicos haviam captado o sinal do Sputnik
começou a correr pelo LFA, e um fluxo constante de visitantes apareceu à porta de
Weiffenbach para dar uma escutadinha no gorjeio do satélite.
Ao perceber que estavam ouvindo a história, Guier e Weiffenbach ligaram o receptor a um
amplificador de áudio e começaram a gravar o sinal em fita de áudio. Incluíram etiquetas com
o tempo em cada gravação. Enquanto ouviam e gravavam, os dois homens se deram conta de
que poderiam usar o efeito Doppler para calcular a velocidade com que o satélite estava se
movendo pelo espaço. Observado pela primeira vez mais de um século antes pelo físico
austríaco Christian Doppler, o efeito Doppler descreve a maneira previsível como a
frequência de uma forma de onda muda quando a fonte ou o receptor estão em movimento.
Imagine um alto-falante tocando uma única nota, digamos o lá acima do dó central, que emite
ondas de som com uma frequência de 440Hz. Se o alto-falante for fixado no capô de um carro
e ele estiver se movendo em direção a você, as ondas vão se sobrepor, o que torna o intervalo
entre uma e outra mais curto. Quando essas ondas comprimidas chegam ao seu tímpano, a
frequência percebida é de mais de 440Hz. Quando o carro se afasta, o efeito Doppler se
inverte, e a nota percebida cai abaixo do lá. Podemos ouvir o efeito Doppler cada vez que
uma ambulância passa por nós com a sirene ligada; à medida que ela se afasta, o som da
sirene parece ficar mais grave.
O efeito Doppler provou-se um conceito de extraordinária versatilidade: foi usado para
detectar a expansão do universo, seguir a pista de tempestades elétricas e realizar ultrassons.
Como o Sputnik emitia um sinal numa frequência constante e o receptor de micro-ondas era
estacionário, Guier e Weiffenbach perceberam que poderiam calcular o movimento do satélite
com base nas mudanças pequenas, mas constantes, na forma de onda que estavam captando.
Tarde da noite, lembraram-se de mais um truque matemático: pela análise da inclinação da
mudança do Doppler, poderiam determinar qual era o ponto da órbita do Sputnik mais
próximo do LFA. Quase por acaso, descobriram uma técnica não só para calcular a
velocidade do satélite, mas para mapear de fato a trajetória de sua órbita. Em poucas horas, os
jovens cientistas haviam passado da capacidade de ouvir à de medir e rastrear o satélite
russo.
Nas semanas que se seguiram, formou-se uma rede frouxa de cientistas do LFA em torno da
intuição de Guier e Weiffenbach, acrescentando detalhes, pesquisando a literatura teórica
sobre corpos orbitantes e propondo aperfeiçoamentos da tecnologia. Por fim, o diretor do
laboratório aprovou fundos para o processamento dos números no novo computador UNIVAC.
Poucos meses depois, eles tinham uma descrição completa da órbita do Sputnik, inteiramente
inferida a partir daquele simples sinal de 20MHz. Guier e Weiffenbach haviam iniciado uma
busca que iria definir suas carreiras profissionais, a “aventura de suas vidas”, como mais
tarde a chamaram. Na primavera de 1958, Frank T. McClure, o lendário diretor interino do
Laboratório de Física Aplicada, chamou Guier e Weiffenbach à sua sala. McClure tinha uma
pergunta confidencial a lhes fazer: se vocês puderam usar a localização conhecida de um
receptor no solo para calcular a posição de um satélite, seriam capazes de fazer o contrário?
Poderiam calcular a localização de um receptor no solo se conhecessem a órbita exata do
satélite? Após raciocinar por alguns minutos, Guier e Weiffenbach responderam que sim. Na
verdade, deduzir a localização a partir de uma órbita conhecida – em vez de fazê-lo a partir
de uma posição estacionária no solo – tornaria os resultados significativamente mais precisos.
Sem explicar seu interesse final na questão, McClure disse aos dois para fazer uma rápida
análise de viabilidade. Após passar alguns dias processando freneticamente os números, eles
comunicaram: o “problema inverso”, como o chamaram, era eminentemente solucionável.
Logo Guier e Weiffenbach entenderiam por que o problema inverso era tão importante para
McClure: as Forças Armadas estavam desenvolvendo os mísseis nucleares Polaris, destinados
a ser lançados de submarinos. O cálculo de trajetórias precisas para um ataque com mísseis
exigia o conhecimento da localização exata do lançamento. Era bastante fácil determinar isso
em terra – digamos, para um silo de mísseis no Alasca –, mas terrivelmente difícil no caso de
um submarino imerso em algum ponto do oceano Pacífico. A ideia de McClure era pegar a
engenhosa solução para o caso do Sputnik e virá-la de cabeça para baixo. Os militares
estabeleceriam a localização desconhecida de seus submarinos acompanhando a posição
conhecida dos satélites que orbitavam acima da Terra. Assim como, durante milhares de anos,
os marinheiros haviam usado as estrelas para navegar, eles guiariam seus navios usando as
estrelas artificiais da tecnologia dos satélites.
O projeto foi apelidado de sistema Transit. Exatos três anos após o lançamento do Sputnik,
havia cinco satélites dos Estados Unidos em órbita fornecendo dados de navegação às Forças
Armadas. Em 1983, quando o voo 007 da Korean Air Lines foi derrubado a tiros após
penetrar no espaço aéreo soviético por conta de defeitos em faróis de navegação baseados no
solo, Ronald Reagan declarou que a navegação por satélite deveria ser um “bem comum”,
aberto para uso civil. Por volta dessa época, o sistema ganhou seu nome atual, Global
Positioning System, ou GPS. Meio século mais tarde, cerca de trinta satélites GPS cobrem a
Terra com sinais de navegação, fornecendo orientação para os mais diversos usos, de
telefones celulares a Airbus A380, passando por câmeras digitais.
Para ver em primeira mão o imprevisível poder de uma plataforma emergente, basta olhar
para o que aconteceu com o GPS nos últimos cinco anos. Os engenheiros que construíram o
sistema – a começar por Guier e Weiffenbach – criaram todo um ecossistema de inesperada
utilidade. Frank McClure identificou que era possível utilizar a intuição original de Guier e
Weiffenbach para rastrear submarinos nucleares, mas não fazia a menor ideia de que cinquenta
anos depois o mesmo sistema ajudaria adolescentes a se divertir com jogos complexos em
centros urbanos, ou alpinistas a explorar cadeias de montanhas traiçoeiras, ou fotógrafos a
transferir suas fotos para mapas no Flickr. Como a própria internet, o GPS revelou ter imenso
valor comercial, e muitas empresas com fins lucrativos estiveram envolvidas na construção da
infraestrutura que fez dele uma realidade. Mas as ideias fundamentais para a tecnologia – a
própria noção de satélite, os relógios atômicos em que os satélites se baseiam para informar a
hora exata e, é claro, a intuição original de Guier e Weiffenbach com o Sputnik – vieram todas
do setor público. A natureza generativa da plataforma do GPS reflete muito bem o ambiente
que lhe deu origem. Quando solicitados a explicar como tiveram a revelação do Sputnik,
Guier e Weiffenbach a atribuíam mais ao hábitat intelectual do Laboratório de Física Aplicada
que a seus talentos pessoais:
O LFA era um ambiente magnífico para garotos curiosos, em especial o Centro de Pesquisas. Estimulava as pessoas a
pensar de maneira ampla e geral sobre problemas de trabalho, e no qual jovens de espírito indagador sentiam-se livres para
tentar satisfazer sua curiosidade. De maneira igualmente importante, era um ambiente onde garotos em início de carreira
podiam recorrer a colegas versados nos mais diversos campos relevantes, e, graças ao gênio da diretoria do laboratório, a
colegas que eram também instruídos em matéria de hardware, armas e necessidades de armamentos.
À sua maneira modesta, o LFA era uma plataforma que estimulava e amplificava intuições,
que permitia que elas se conectassem com outras mentes que tinham conhecimento
especializado pertinente. Nessa rede densa, instalou-se uma das plataformas tecnológicas mais
produtivas do século XXI. O LFA não era uma plataforma puramente aberta, é claro. Afinal de
contas, havia segredos militares em jogo; e, mesmo que Guier e Weiffenbach tivessem
desejado compartilhar sua descoberta sobre o Sputnik com o mundo, era muito mais difícil
difundir uma descoberta desse tipo numa época em que o computador mais avançado – o
UNIVAC – ocupava uma sala inteira. Atrás daquelas portas fechadas, porém, William Guier e
George Weiffenbach foram os beneficiários de um ambiente que estimulava as colisões
casuais entre diferentes campos, um ambiente que deixava dois “garotos” topar com uma ideia
na cafeteria e construir toda uma carreira em torno disso.
Espaços físicos semelhantes estão associados à maioria dos viveiros de inovação: o
Homebrew Computer Club no Vale do Silício; as reuniões de quarta-feira de Freud na
Berggasse, número 19; os cafés do século XVIII. Todos esses espaços foram, na escala menor
que lhes era característica, plataformas emergentes. Os donos de café, como Edward Lloyd ou
William Unwin, não estavam tentando inventar a indústria editorial moderna, nem a atividade
seguradora; não estavam em absoluto interessados em promover o avanço científico ou a
agitação política. Eram apenas homens de negócios, empenhados em faturar o suficiente para
alimentar suas famílias, exatamente como aqueles castores construíam tocas para manter sua
prole protegida. Mas os espaços criados por Lloyd e Unwin revelaram ter esta propriedade
incomum: faziam as pessoas pensar de maneira diferente, porque geravam um ambiente em que
diversos tipos de pensamento podiam colidir e se recombinar de maneira produtiva.
AS PLATAFORMAS MAIS GENERATIVAS surgem em pilhas, de maneira notória no caso da
plataforma em camadas da web. (A expressão “pilha de plataformas” é ela mesma parte da
linguagem comum da programação moderna.) A web pode ser imaginada como uma espécie de
sítio arqueológico, com camadas sobre camadas de plataformas enterradas sob cada página.
Tim Berners-Lee conseguiu projetar sozinho um novo meio porque pôde construir livremente
sobre os protocolos abertos da internet. Não teve de construir um sistema inteiro para que a
comunicação entre computadores se espalhasse por todo o planeta; esse problema já havia
sido resolvido décadas antes. Bastou-lhe construir uma estrutura padrão para descrever
páginas de hipertexto (HTML) e compartilhá-las através de canais existentes da internet
(HTTP). Até o HTML baseou-se em outra plataforma já em uso, a SGML, desenvolvida na
IBM nos anos 1960. Passados catorze anos, quando Hurley, Chen e Karim se reuniram para
criar o YouTube, construíram o serviço costurando elementos de três plataformas diferentes: a
própria web, é claro, mas também a plataforma Flash da Adobe, que lidava com a gravação e
a reprodução de vídeos, e a linguagem de programação Javascript, que permitia a usuários
finais incorporar videoclipes em seus próprios sites. A habilidade de construir sobre essas
plataformas preexistentes explica por que três sujeitos foram capazes de criar o YouTube em
seis meses, ao passo que um exército de comitês de especialistas e companhias eletrônicas
levaram vinte anos para transformar a HDTV em realidade.
A cultura também se baseia em plataformas empilhadas. Os paradigmas da pesquisa de
Kuhn são os equivalentes da plataforma de software no mundo científico: um conjunto de
regras e convenções que governam a definição de termos, a coleta de dados e os limites da
investigação para determinado campo. A argumentação de Kuhn foi muitas vezes confundida
com a defesa de uma visão puramente relativista da ciência, na qual a “verdade” empírica está
sempre entre aspas porque os paradigmas se substituem uns aos outros com o tempo. (Nessa
concepção, a aparente solidez da verdade científica não passa de uma espécie de holograma
produzido pelo aparato do paradigma.) Mas raras vezes se derrubam os paradigmas
científicos modernos; o que se faz é construir sobre os mesmos. Eles criam uma plataforma
que sustenta novos paradigmas sobre si. A teoria da seleção natural de Darwin era uma ideia
“perigosa” – como disse Daniel Dennett – porque contestava explicações bíblicas e
antropocêntricas da história da vida, mas a verdadeira medida de seu poder científico está no
número de novos campos que se empilharam sobre ela ao longo do século XX: a genética
mendeliana e populacional que emergiu da “síntese moderna” nos anos 1940; a revolução da
genética molecular desencadeada pela descoberta do DNA por Watson e Crick; campos mais
recentes como a psicologia evolucionária e o “desenvolvimento evolucionário”. Com
frequência, novos campos científicos se formam apoiando-se sobre múltiplas plataformas. O
campo que explicou finalmente o paradoxo de Darwin – a ecologia dos ecossistemas – se
ergue sobre, entre outros, os ombros da genética populacional, da teoria dos sistemas e da
bioquímica.
Até as artes criativas se desenvolvem por meio de plataformas empilhadas. Isso pode
parecer surpreendente, dada nossa tendência a evocar a imagem do gênio artístico individual,
isolado em seu ateliê, criando todo um mundo novo em sua cabeça a partir do zero. Por razões
compreensíveis, gostamos de falar sobre inovações artísticas em termos do modo como elas
rompem as regras, abrem novas portas no possível adjacente que mentes inferiores nem sequer
chegam a ver. Mas gênios precisam de gêneros. Flaubert e Joyce precisaram do gênero
romance de formação (bildungsroman) para contorcê-lo e solapá-lo em A educação
sentimental e Retrato do artista quando jovem. Dylan precisou das convenções da música
folk acústica para eletrizar o mundo com Highway 61 Revisited. Os gêneros fornecem um
conjunto de regras implícitas que têm coerência suficiente para que tradicionalistas possam
brincar em segurança dentro delas e artistas mais ousados possam contrariar nossas
expectativas brincando com elas. Os gêneros são plataformas e paradigmas do mundo criativo.
Eles quase nunca são gerados por uma única obra pioneira. Em geral, aparecem aos poucos,
mediante um conjunto complexo de sinais compartilhados transmitidos entre artistas, cada um
adicionando um elemento diferente à mistura. O romance policial tem sido um gênero
consistente há cem anos, mas quando de fato tentamos traçar seu pedigree é difícil apontar um
único doador: é um pouco de Poe, um pouco de Dickens, um pouco de Wilkie Collins, para
não mencionar as dezenas de contemporâneos que, embora não tenham criado o cânone,
desempenharam um papel no equilíbrio das convenções do gênero. O mesmo pode ser dito do
cubismo, do sitcom, da poesia romântica, do jazz, do realismo mágico, do cinema-verdade,
dos romances de aventura, dos reality shows e de praticamente qualquer gênero ou modo
artístico que tenha tido alguma importância.
A pilha criativa, no entanto, é mais profunda que os gêneros, eles próprios construídos
sobre convenções e tecnologias mais estáveis. Mesmo quando Miles Davis anunciou seu
rompimento com as convenções de acorde e improvisação do bebop em “So What?” – a faixa
de abertura de Kind of Blue –, estava trabalhando dentro das convenções da escala dórica de
ré que a canção utiliza, um modo que, como seu nome sugere, remonta aos gregos dóricos. E, é
claro, Davis construiu seu novo som a partir das plataformas mais antigas e estáveis dos
próprios instrumentos, a começar pelo trompete de pistons que tocava. Os trompetes
“naturais”– sem as válvulas complexas que permitem ao trompetista mudar de tom sem se
deter – são quase tão antigos quanto o modo dórico; o moderno trompete de pistons que Davis
tocava surgiu como um padrão no século XIX, depois que fabricantes de instrumentos em toda
a Europa passaram décadas tentando aperfeiçoá-lo. Se Davis teve condições de explorar o
possível adjacente do jazz, de ajudar a inventar todo um novo gênero que outros
desenvolveriam, foi em parte por não ter precisado inventar a escala dórica de ré ou o
trompete de pistons.
No mundo on-line, o estudo de caso recente mais celebrado sobre o poder inovador de
plataformas empilhadas foi a rápida evolução do Twitter. Da mesma maneira que os
fundadores do YouTube, os criadores desse serviço de rede social, Jack Dorsey, Evan
Williams e Biz Stone, beneficiaram-se de plataformas existentes: o famoso limite de 140
caracteres é baseado nas limitações da plataforma de comunicações móveis SMS, que eles
utilizam para conectar mensagens da web a telefones celulares. Mas o que o Twitter tem de
mais fascinante é o quanto se construiu sobre sua plataforma em apenas três anos. Assim que
surgiu, ele foi alvo de zombaria, considerado uma distração frívola cuja principal utilidade
era contar aos amigos o que tínhamos comido no café da manhã. Agora é usado para organizar
e compartilhar notícias sobre os protestos políticos no Irã, driblar a censura governamental,
fornecer suporte técnico a clientes de grandes empresas, divulgar notícias interessantes e
milhares de outras aplicações que não tinham passado pela cabeça dos fundadores quando
eles inventaram o serviço em 2006. Esse não é apenas um exemplo de exaptação cultural –
pessoas encontrando um novo uso para uma ferramenta projetada para fazer outra coisa. No
caso do Twitter, os usuários vêm reprojetando a própria ferramenta. A convenção de
responder aos outros com o símbolo @ foi inventada espontaneamente por sua base de
usuários. Os primeiros usuários do serviço trouxeram uma convenção da plataforma de envio
de mensagens IRC e começaram a agrupar tópicos ou eventos com hashtags, como em
“#30Rock” ou “#inauguração”. A capacidade de rastrear um live stream de tweets – que
provavelmente se mostrará decisiva para o modelo comercial do serviço, devido a seu
potencial publicitário – foi desenvolvida por uma nova empresa completamente distinta.
Graças a essas inovações, seguir um live feed de tweets sobre um evento – debates políticos
ou episódios da série Lost – tornou-se parte fundamental da experiência do Twitter. Durante o
primeiro ano de existência do serviço, porém, esse modo de interação não teria sido
tecnicamente possível. É como inventar um forno tostador e, um ano depois, olhar em volta e
descobrir que todos os seus clientes, por si sós, descobriram uma maneira de transformá-lo
num micro-ondas.
Um dos fatos mais expressivos com relação à plataforma do Twitter é que a vasta maioria
de seus usuários interage com o serviço por meio de softwares criados por terceiros. Centenas
de aplicativos de iPhone e BlackBerry lhes permitem manejar seus feeds do Twitter, todos
criados por programadores amadores e pequenas start-ups. Há serviços que ajudam os
usuários a fazer upload de fotos e inserir links para elas em seus tweets; programas que
mapeiam outras pessoas que estão tuitando nas proximidades geográficas deles. Ironicamente,
as ferramentas que nos são oferecidas quando visitamos o site Twitter.com mudaram muito
pouco nos dois últimos anos. Mas há um Wal-Mart inteiro de ferramentas para o Twitter
disponível por toda parte.
A diversidade da plataforma do Twitter não é casual. Ela resulta de uma estratégia
deliberada que Dorsey, Williams e Stone abraçaram desde o início: primeiro eles construíram
uma plataforma, depois fundaram o Twitter. com. Uma plataforma aberta em software é muitas
vezes chamada de API, que significa application programming interface. Uma API é uma
espécie de língua franca que aplicativos de software podem usar de maneira confiável para se
comunicar uns com os outros, um conjunto de regras e definições padronizadas que permite
aos programadores criar novas ferramentas com base em outra plataforma, ou combinar
informações provenientes de múltiplas plataformas. Quando usuários da web fazem mashupsa
usando o Google Maps, eles escrevem programas que se comunicam com os dados
geográficos do Google usando seu API de mapeamento.
Algumas APIs revelam apenas um pequeno subconjunto do código subjacente de uma
plataforma, em parte por razões de simplicidade, mas também por questões proprietárias.
Convencionalmente, um programador cria um software e, depois de concluí-lo, expõe uma
pequena parte de sua funcionalidade para programadores de fora por meio da API. A equipe
do Twitter adotou a abordagem exatamente contrária. Primeiro eles criaram a API e
expuseram todos os dados essenciais para o serviço, depois criaram o Twitter.com em cima
da API. Em geral, pressupõe-se que os usuários de API são cidadãos de segunda classe, aos
quais não se deve dar pleno acesso ao pulo do gato do software, sob pena de perder vantagem
competitiva. Os criadores do Twitter reconheceram que a abertura completa proporcionava
outro tipo de vantagem competitiva: aquela que decorre de se ter o maior e mais diversificado
ecossistema de aplicativos de software sendo construído sobre sua plataforma. Podemos
chamá-la de vantagem cooperativa. A própria companhia deixa de arcar sozinha com a
responsabilidade de descobrir boas ideias para o produto. Numa plataforma aberta, boas
ideias vêm de toda parte.
Observar o modo como companhias com fins lucrativos como o Twitter e o Google usaram
APIs para estimular inovação foi fascinante. Mas é no setor público que encontramos os
desenvolvimentos mais intrigantes. No outono de 2008, Vivek Kundra, diretor de tecnologia
no Distrito de Colúmbia, anunciou um programa chamado Apps for Democracy (no lugar do
título provisório um pouco mais escandaloso, Hack the District). Desenvolvedores de
software foram convidados para criar aplicativos que fizessem uso dos dados abertos que o
governo municipal punha a seu dispor. Esses aplicativos poderiam assumir praticamente
qualquer forma imaginável – websites, aplicativos do Facebook, do iPhone –, contanto que
tentassem tornar alguma parte do acervo de dados do governo útil para moradores, visitantes,
empresas ou agências governamentais. Os vencedores receberiam um prêmio de 10 mil
dólares.
A cidade concedeu aos programadores apenas trinta dias para a criação de seus
aplicativos, mas mesmo com esse prazo curto, 47 diferentes programas foram apresentados.
Um dos dois vencedores exibia guias para caminhadas pelos sítios históricos por toda a área
de Washington, D.C., e o outro fornecia ampla informação demográfica para residentes que
estivessem pensando em se mudar para um bairro diferente. Candidatos apresentaram
ferramentas para rastrear os gastos do governo em projetos específicos, guias para ciclistas e
informação em tempo real sobre vagas em estacionamento com dados recebidos diretamente
de parquímetros instalados nas ruas. Um aplicativo engenhoso e engraçado, chamado
StumbleSafely, ajudava usuários embriagados a encontrar o melhor trajeto para voltar a pé
para casa a partir de qualquer bar da cidade.
O experimento do Distrito de Colúmbia fez tanto sucesso que versões dele vêm
proliferando em dezenas de grandes cidades no mundo todo. Na primavera de 2009, quando o
D.C. repetiu o concurso, Kundra não estava por lá para entregar os prêmios, mas por um bom
motivo: havia sido nomeado diretor-geral de informação do país pelo presidente Obama,
ajudando a criar o ambicioso programa Data.gov, junto com o concurso Apps for America,
conduzido pela Sunlight Foundation. O que essas iniciativas têm em comum é uma disposição
para aprender com as plataformas de inovação do Twitter, do Google e do Facebook. Quando
Al Gore se dispôs a “reinventar o governo” durante a administração Clinton, uma das metas
ambiciosas desse projeto era tornar a burocracia mais inovadora. Mas as soluções de Gore
eram, quase sem exceção, voltadas para dentro: criação de novas estruturas organizacionais
dentro do governo; redução da burocracia; estímulo à colaboração entre departamentos. O que
o Apps for Democracy sugere é uma concepção mais aberta: é provável que algumas das
melhores ideias para o governo venham de fora dele. Se a comunidade de programadores
externos pôde construir algo tão essencial quanto uma interface de busca para o negócio do
Twitter, por que os cidadãos não podem fornecer inovações comparáveis para seu governo?
Com certeza deve haver alguém por aí capaz de descobrir uma experiência de usuário melhor
para o preenchimento de declarações de imposto de renda.
As burocracias governamentais têm uma longa e muito merecida reputação de liquidar
inovações, mas possuem quatro elementos essenciais que podem lhes permitir beneficiar-se da
máquina de inovações de uma plataforma emergente. Primeiro, são repositórios de uma vasta
quantidade de informações e serviços que poderiam ter valor para pessoas comuns, contanto
que pudessem ser mais bem-organizados. Segundo, as pessoas têm um interesse apaixonado
pelo tipo de informação com que os governos lidam, sejam dados sobre zoneamento industrial,
serviços de saúde ou taxas de criminalidade. Terceiro, existe uma longa tradição de cidadãos
que dedicam tempo e energia intelectual ao enfrentamento de problemas quando algum bem
cívico está em jogo. Por fim, pelo fato de não estarem no setor privado, os governos não
sentem nenhuma pressão competitiva para resguardar a propriedade dos dados.
Desde a supernova que foi a campanha de Howard Dean em 2004, ficou claro que a
tecnologia de rede pode ser usada para ajudar nossos líderes a disputar cargos. Ainda não
vimos, porém, nenhuma prova real de que essas extraordinárias tecnologias permitem a esses
líderes governar de maneira mais eficiente depois de eleitos. Mas pensar no governo como
uma plataforma – para tomar emprestada uma expressão do visionário da web Tim O’Reilly –
poderia ser uma maneira de cumprir a promessa da governança da era digital. A liderança
política envolve alguns elementos que não convém transferir para uma rede líquida: a tomada
de decisões e a oratória. Mas um bom governo é, pelo menos em parte, aquele que encontra
soluções inovadoras para os problemas de seus cidadãos ou para os problemas da própria
burocracia. É aí que o modelo da plataforma pode operar sua mágica.
Parte dessa mágica é econômica: plataformas emergentes podem reduzir enormemente os
custos de criação. Aqueles 47 aplicativos gerados em um mês pelo primeiro concurso Apps
for Democracy representaram um custo total de 50 mil dólares para o governo do Distrito de
Colúmbia. Kundra estimou que, se a cidade tivesse contratado o desenvolvimento desses
aplicativos usando os métodos tradicionais, o custo teria sido de mais de 2 milhões de
dólares. (Além disso, o processo demoraria mais de um ano.) A mesma matemática se aplica
às inovações na web no setor privado. Se Hurley, Chen e Karim tivessem sido obrigados a
inventar um padrão de vídeo on-line a partir do zero, teriam levado anos e gastado dezenas de
milhões de dólares apenas para chegar a uma versão beta capaz de funcionar. Até hoje, o
Twitter não gastou um centavo para desenvolver um aplicativo de mapeamento para rastrear a
localização de tweets, porque existem inúmeros serviços, criados e promovidos por terceiros,
que fazem exatamente isso a custo zero para o próprio serviço.
Embora não sejam medidas em unidades monetárias, plataformas naturais exibem padrões
semelhantes de eficiência econômica. Pica-paus-de-penacho constroem suas casas fazendo
grandes buracos em árvores mortas. Não tendo recursos para matar árvores, contudo, eles
dependem extremamente de descobrir árvores que tenham morrido por causas naturais. Mas,
ao criar seus pântanos florestais, os castores derrubam árvores constantemente, então os pica-
paus florescem no ecossistema assim construído. Eles se beneficiam da madeira mais mole e
maleável de uma árvore em putrefação, sem o custo de ter de derrubá-la. Curiosamente, esses
pica-paus costumam abandonar as casas que entalharam na árvore após um ano, tornando-as
os espaços ideais para ninhos de aves canoras. Estas se beneficiam das cavidades criadas
pelos pica-paus sem o ônus de ter de furar toda aquela madeira. O brejo criado pelo castor, tal
como a florescente plataforma criada pelos fundadores do Twitter, convida à variação por ser
uma plataforma aberta, em que os recursos são compartilhados na mesma medida em que são
protegidos.
SE VOCÊ NAVEGAR RUMO AO LESTE por cerca de trinta quilômetros a partir do estreito do rio
Indian em Delaware e mergulhar 24 metros nas águas abertas do oceano Atlântico, descobrirá
uma cidade submersa florescendo no fundo do mar: grandes cardumes de linguados, robalos e
bodiões-de-ostra arremessando-se em meio a gramas marinhas suavemente ondulantes.
Encontrará também cerca de setecentos vagões de metrô, depositados ali pelo Departamento
de Recursos Naturais e Controle Ambiental de Delaware ao longo da década passada. Os
trens foram afundados ao largo da costa de Delaware para criar um recife artificial,
fornecendo um abrigo duradouro para mexilhões e esponjas que, de outro modo, seriam
desafiados pelos fundos arenosos do litoral nordeste. Os recifes artificiais criam importantes
locais de procriação para um grupo diversificado de peixes; a biomassa nos recifes de
Delaware teve um aumento de 400% desde que os primeiros vagões foram afundados. (Os
recifes artificiais também têm o efeito secundário de evitar a erosão da praia.) Não mais
necessários para o transporte de massa, os vagões de metrô abandonados assumiram uma nova
ocupação em seus anos de aposentadoria. Agora são construtores de ecossistema.
As plataformas têm um apetite natural por lixo, resíduos e bens abandonados. Os robalos e
mexilhões que se instalam num trem retirado de circulação, assim como as aves canoras que
se aninham nas casas abandonadas dos pica-paus, refletem um padrão que Jane Jacobs
detectou anos atrás no desenvolvimento urbano: a inovação floresce em espaços postos fora
de uso. As plataformas emergentes extraem grande parte de sua criatividade da reutilização
inventiva e econômica de recursos existentes, e, como qualquer citadino sabe, o recurso mais
caro numa cidade grande são os bens imobiliários. “Se você olhar à sua volta, verá que
apenas empresas bem-estabelecidas, que movimentam grande volume de dinheiro,
padronizadas ou fortemente subsidiadas podem se permitir, em geral, arcar com os custos de
uma nova construção”, escreveu Jacobs. “Cadeias de lojas, cadeias de restaurantes e bancos
se instalam em construções novas. Mas bares das redondezas, restaurantes estrangeiros e
casas de penhores ocupam prédios antigos. Supermercados e lojas de sapatos, o mais das
vezes, se instalam em prédios novos; boas livrarias e antiquários raramente o fazem.” Uma
implicação disso é que negócios mais arriscados ou de menor escala tendem a ter dificuldade
em progredir em ambientes planejados, que não passaram pelo desgaste econômico do tecido
urbano tradicional, em que prédios, quarteirões e bairros inteiros perdem seus habitantes e
suas indústrias originais, por vezes com efeitos catastróficos. (No subúrbio, o que mais se
aproxima disso é o espaço marginal da garagem, onde a Hewlett-Packard, a Apple e o Google
tiveram suas raízes.) O shopping center tem apenas cinquenta anos de idade, sendo portanto
relativamente jovem pela escala milenar de algumas cidades, mas até agora mesmo o shopping
mais malsucedido conservou sua função original: é um lugar onde consumidores se reúnem
para comprar coisas para uso pessoal. Eles ainda não foram aproveitados por trupes de
artistas performáticos, start-ups de internet ou pela indústria pesada. Há ruas em West
Village, Manhattan, onde Jacobs morou por tantos anos, que hoje parecem shopping centers.
Mas ao longo dos dois últimos séculos aqueles velhos prédios se prestaram a uma longa série
de diferentes usos: serviram como o eixo de um porto industrial; como o principal ponto de
fornecimento de carne para uma cidade de 8 milhões de habitantes; como refúgio para beatniks
e rebeldes; como o epicentro do movimento pelos direitos dos gays. O argumento de Jacobs
era que a energia frenética de uma grande cidade, a versão urbana da destruição criativa, cria
um estoque natural de ambientes mais velhos, menos desejáveis, que pode ser reocupado de
maneira imaginativa pelo pequeno ou pelo excêntrico, as subculturas que Fischer considerava
tão essenciais à vida urbana. Artistas, poetas e empreendedores são os peixes vibrantes que
nadam em meio aos corais das ilhas Cocos: parece-lhes mais fácil viver num exosqueleto há
muito abandonado por seu hospedeiro original. Como Jacobs observou:
Quanto a ideias realmente novas de qualquer tipo – não importa quão lucrativas ou bem-sucedidas sob outros aspectos
algumas delas possam final mente provar ser –, não há nenhuma margem para essas tentativas, erros e experimentações
casuais na economia de altas despesas operacionais da nova construção. Velhas ideias podem por vezes usar prédios novos.
Ideias novas têm de usar prédios velhos.
As plataformas reciclam muito mais do que a mera arquitetura. Os ecologistas marinhos
que estudaram o fluxo de energia através dos ecossistemas dos recifes de coral descobriram
que eles fazem um trabalho de reciclagem de nutrientes estarrecedor. Há muito os cientistas
reconheceram a importância da relação simbiótica entre o coral e uma alga microscópica
chamada zooxantela. De fato, os dois organismos dependem dos resíduos um do outro: a alga
capta energia do sol e produz, como resíduo, oxigênio e açúcares, os quais os pólipos de coral
usam para prover de energia seu próprio crescimento. Ao mesmo tempo, os corais expelem
como resíduo dióxido de carbono, nitratos e fosfatos, que alimentam o crescimento das
zooxantelas. À medida que a população de zooxantelas se expande, mais energia solar é
captada, tornando-se portanto disponível para ser compartilhada com o ecossistema mais
amplo do recife. A zooxantela e o coral são como dois vizinhos que, milagrosamente, têm uma
necessidade premente do lixo um do outro e se encontram toda noite para trocar suas lixeiras.
A reciclagem de nutrientes de um recife de coral, entretanto, vai muito além da colaboração
entre o coral e a zooxantela. Em 2001, uma equipe de ecologistas alemães liderada por
Claudio Richter usou endoscópios para examinar as minúsculas cavidades internas de recifes
de coral no mar Vermelho. Escondida nessas diminutas grutas havia uma vasta população de
esponjas que se adaptou ao interior escuro dos recifes de coral. Nessa espécie de santuário, as
esponjas estão a salvo de seus predadores naturais, os ouriços-do-mar e peixes-papagaios. Ao
flutuar pelas cavernas de aragonita do recife, elas consomem um outro organismo
fotossintético essencial, o fitoplâncton. Como as zooxantelas, as esponjas expelem resíduos
que o coral usa como nutrientes. Essas esponjas por muito tempo escondidas incorporam dois
princípios da reciclagem da plataforma: ao ocupar o espaço abandonado do esqueleto de
coral, elas reduzem os custos de sua própria fortificação contra predadores. Em troca,
expelem nutrientes que permitem a seu hospedeiro excretar ainda mais aragonita, criando
novos hábitats para mais esponjas.
Todo o ecossistema do recife de coral se caracteriza por redes de alimentação igualmente
intrincadas e interdependentes, cuja complexidade só agora os cientistas começam a mapear
em sua plenitude. Quando compreendemos de que modo as plataformas biológicas usam os
resíduos gerados dentro do sistema como base, o paradoxo de Darwin se dissolve por
completo. A relação simbiótica entre o coral e a zooxantela aumenta a energia total captada do
sol, e os estreitos ciclos de nutrientes criados pela reutilização produtiva de fontes de energia
por tantas espécies densamente interconectadas significam que o hábitat pode fazer muito mais
com menos. Encontramos uma metrópole aquática, com assombrosa diversidade, num
ambiente que por todas as razões deveria ser tão desolado quanto o arenoso atol acima do
nível do mar. O que impulsiona o processo não é a competição, mas antes as colaborações
inventivas da densidade. A plataforma de coral não possui a luxuriante provisão de nutrientes
que encontramos nos estuários, abastecidos diariamente pelos rios de água doce, que entalham
a camada superficial do solo das margens rio acima. Apesar disso, a plataforma de coral
floresce, graças ao trabalho de construção do ecossistema realizado pelo coral e à
maravilhosa reciclagem, tanto do abrigo quanto dos resíduos biológicos, que torna a
plataforma tão vital.b Acima da linha do mar, sobre aqueles atóis desabitados, encontramos
uma paisagem acentuadamente diferente, muito mais próxima dos ecossistemas destrutivos dos
desertos. A maior parte da energia solar que satura os ambientes desérticos se perde,
assimilada apenas pelas poucas plantas suculentas que conseguem sobreviver num clima tão
hostil. Essas plantas transmitem energia suficiente para sustentar um número limitado de
insetos, que, por sua vez, fornecem alimento aos répteis e às aves ocasionais, os quais acabam
por alimentar as bactérias. A maior parte da energia, porém, nunca chega a ser posta em uso
por vida orgânica.
SE BRENT CONSTANTZ ESTIVER CERTO, a genialidade do recife de coral para reciclar e construir
plataformas acabará transformando as plataformas físicas dos povoamentos humanos. No fim
dos anos 1970, quando se empenhava em obter uma dupla especialização em biologia e
geologia na Universidade da Califórnia, em Santa Barbara, Constantz ficou fascinado pelos
extraordinários poderes de biomineralização do pólipo de coral, sua capacidade de construir
uma imensa estrutura de carbonato de cálcio, resistente o bastante para durar milhões de anos.
O ser humano pode ter justificável orgulho de façanhas veneráveis de engenharia como as
Pirâmides ou a Grande Muralha da China, mas esses monumentos empalidecem se
comparados à Grande Barreira de Coral, a maior estrutura biológica do planeta. Quando
cursava a graduação, Constantz sonhava em aproveitar as habilidades construtivas do coral
para criar edifícios inteiros a partir de moldes pré-fabricados. Em vez de derramar concreto
ou prender vigas de aço, bastaria arriar os moldes na água do mar, e o processo de construção
de recife, em um passe de mágica, faria surgir um edifício nesse lugar. Naqueles anos isso era
uma fantasia, mas Constantz guardou essa estranha visão no fundo de sua mente por décadas.
Em 1985, ele estava prestes a concluir seu ph.D. na Universidade da Califórnia, em Santa
Cruz, e havia se especializado em técnicas de biomineralização. A caminho de uma expedição
de pesquisa financiada por uma bolsa da National Science Foundation, parou para fazer uma
visita de alguns dias aos pais, que residiam perto de Palo Alto. Ao assistir a um jogo de
futebol com o pai, um médico, Constantz pegou uma revista médica e, por acaso, leu um artigo
sobre as enormes despesas de saúde associadas à osteoporose, doença que reduz a densidade
mineral óssea, causando fraturas dolorosas e debilitantes. Algumas semanas mais tarde,
quando se encontrava no atol Rangiroa, no meio do oceano Pacífico, medindo a velocidade
com que os corais constroem seus esqueletos, se lembrou do artigo sobre osteoporose. “Se
pudéssemos, de alguma maneira, nos apropriar desses processos de desenvolvimento de
esqueleto”, pensou, “na certa poderíamos ajudar todas aquelas velhinhas com fratura no
quadril.” Dois anos depois, ele fundou sua primeira empresa, que imitava o mecanismo de
desenvolvimento do coral para criar um cimento ósseo destinado a reparar fraturas. Hoje, os
cimentos criados por Constantz são usados na maioria das salas de cirurgia ortopédica nos
Estados Unidos e na Europa.
Constantz fundou mais duas outras empresas biomédicas de sucesso, mas aquela intuição
original sobre a construção de infraestrutura física a partir de esqueletos de coral persistia no
fundo de seus pensamentos. Em meados da década de 2000, quando lecionava em Stanford,
ele ingressou no corpo docente transdisciplinar do Woods Institute for the Environment, onde
pela primeira vez se inteirou do gigantesco impacto ambiental da fabricação de cimento
Portland, a terceira maior fonte de emissões de dióxido de carbono produzida pelo homem no
planeta. Em sua mente, uma nova rede de ideias começou a ganhar corpo, reacendendo o velho
sonho que acalentara na graduação de desenvolver cidades aquáticas. Os recifes de coral
criavam estruturas semelhantes ao cimento sem poluir o ambiente, e Constantz tinha três
empresas de sucesso para mostrar que a imitação da mecânica do desenvolvimento do coral
podia criar novos materiais úteis. E se usássemos essa mecânica não para reparar fraturas de
quadril, mas para construir viadutos rodoviários?
A intuição lenta que Constantz estivera cultivando por 25 anos havia por fim encontrado a
conexão certa. Ele levou sua ideia de um cimento “verde” para Vinod Khosla, um dos
lendários investidores de risco do Vale do Silício, que concordou em financiar a companhia
(que Constantz chamou de Calera) sem chegar a ver sequer um plano de negócios ou uma
apresentação de PowerPoint. Constantz construiu um laboratório em Los Gatos, onde se
começou a “cultivar” cimento de carbonato em carrocerias cheias de água do mar. Logo ele
descobriu que o sistema gerava oito vezes mais cimento se bombeasse a água cheia de dióxido
de carbono, como uma enorme água tônica salgada. Um dia, quando Khosla foi inspecionar o
laboratório, Constantz virou-se para seu investidor e perguntou: “Onde podemos conseguir
grandes quantidades de dióxido de carbono?” Khosla fitou-o, incrédulo. Sendo um dos mais
destacados investidores em tecnologia não poluente do mundo, ele tinha plena ciência de que
o planeta estava repleto de fábricas que procuravam desesperadamente um lugar onde
descarregar seu dióxido de carbono. Mercados inteiros estavam surgindo em torno de
tecnologias de sequestro de carbono, que permitiam aprisionar CO 2 injetando-o em reservas
de óleo e gás ou enterrando-o nas profundezas do oceano. Mas Constantz havia tropeçado
numa ideia muito mais poderosa. Não era preciso sepultar todo aquele CO 2. Era possível usá-
lo na construção de matéria.
A história da Calera ainda está longe de terminar. Ainda não se sabe se as cidades do
futuro serão construídas debaixo d’água por recifes de coral artificiais submetidos a uma dieta
de resíduos gasosos de fábricas. Descrito assim, parece fantasioso, é claro, mas não mais do
que a ideia da Grande Barreira de Coral 1 bilhão de anos atrás. Há muito a natureza constrói
suas plataformas reciclando os recursos disponíveis, inclusive os resíduos gerados por outros
organismos. Se temos duas coisas em abundância no planeta neste momento são poluição e
água do mar. Por que não tentar construir uma cidade com elas?
A PLATAFORMA EM PILHAS DA WEB também depende da reciclagem. A palavra “ecossistema”
tornou-se um termo da moda para descrever a diversificada coleção de sites e serviços
associados à web 2.0. Como quase todo jargão, a metáfora aponta para uma verdade
importante, se pensarmos nos fluxos de informação que atravessam a web como análogos aos
fluxos de energia que correm através de um ecossistema natural. Mas, também como quase
todo jargão, a metáfora generaliza demais, e seu vasto alcance torna, na verdade, mais difícil
perceber o que ocorreu de mais importante na evolução da web nos últimos quinze anos. Ela
não é simplesmente um ecossistema; é um tipo específico de ecossistema. Começou como um
deserto e foi se transformando de maneira incessante num recife de coral.
Parte da beleza e do poder da arquitetura de Tim Berners-Lee para a web reside em sua
simplicidade: os sites eram feitos de páginas de hipertexto que podiam ser conectadas a outras
informações na rede mediante um conduto básico: o link. Imagine que estamos em 1995 e você
decidiu postar uma breve crítica de um novo restaurante no bairro Back Bay, em Boston, em
sua home page, como dizíamos na época. Ao postar essa crítica, você introduz uma nova
informação no ecossistema da web. Como zooxantelas que captam a energia do sol, pega uma
informação gerada originalmente fora do ambiente (nas redes neurais de seu próprio cérebro)
e a agrega aos recursos informacionais disponíveis na rede.
A questão é: o que acontecia naquela época com essa informação depois que você a
adicionava ao sistema? Você podia conectá-la à home page do próprio restaurante, se por
sorte ele tivesse uma naquelas priscas eras. Desse momento em diante, seu site estaria
conectado a essa outra página, e as pessoas que o visitassem poderiam seguir essa trilha com
um simples clique do mouse. Num sentido básico, ao levar até o site original do restaurante,
você estaria reciclando a informação armazenada ali, tornando sua crítica mais informativa.
Outro amante de comida poderia encontrá-la por acaso e criar um link a partir do site dele, ou
encaminhar a URL da sua crítica a alguns amigos numa mensagem de e-mail. Na maioria dos
casos, porém, a informação adicionada ao sistema permaneceria presa à sua página original,
como um cacto solitário esperando que um punhado de insetos o encontrasse.
Agora salte direto para o presente. Sentado no mesmo restaurante, tendo acabado de
saborear uma deliciosa vichyssoise, você passa a mão no celular e compõe uma avaliação
entusiástica da sopa em 140 caracteres, com um link para o site do restaurante, e posta no
Twitter antes mesmo que a conta chegue à mesa. Tal como antes, você adiciona nova
informação ao ecossistema da web com esse tweet. Mas o que acontece com ela depois que
você aperta para enviar em seu telefone?
Em primeiro lugar, circula pelo ecossistema de uma maneira impensável em 1995.
Segundos depois que você a compôs, a mensagem chega a todos os seus seguidores no Twitter,
em alguns casos enviada diretamente para os celulares deles. Graças à convenção do re-
tweeting, adotada de maneira espontânea pelos usuários, esse tweet original sobre a
vichyssoise é facilmente encaminhado a outros amantes da boa comida na rede. Mas esse é
apenas o começo da jornada. Com os dados geográficos anexados à postagem pelo seu celular
dotado de GPS, a rede social do mundo real Foursquare distribui o tweet sobre a sopa para
todos os seus usuários que tenham visitado recentemente bares, restaurantes ou outros lugares
públicos nas imediações. (Até cafés!) O tweet pipoca imediatamente na forma de uma
“tachinha” nos inúmeros Twittermaps criados pelos programadores nos últimos anos. A
plataforma hiperlocal de notícias Outside.in (que ajudei a criar há alguns anos) analisa os
dados geográficos, detecta o nome do restaurante e o anexa no mesmo instante a páginas
dedicadas à discussão do próprio restaurante, àquelas que cobrem todas as notícias e
comentários sobre o bairro Back Bay e às dedicadas ao cenário gastronômico de Boston. Um
jornal da cidade que construiu páginas de notícias específicas dos bairros usando a plataforma
aberta de edição do Outside.in exibe esse tweet numa página dedicada a comentários sobre
comida em Back Bay. O Google detecta o link para o website do restaurante e o registra como
um “voto” que endossa a qualidade dessa página, o que faz com que ela ascenda na página de
resultados quando as pessoas fazem uma busca com o nome dela. O tweet aparece até na caixa
de entrada do e-mail do dono do restaurante, que estabeleceu um Google Alert para informá-lo
automaticamente quando o nome de seu restaurante for mencionado. Em muitas dessas páginas
nos sites de jornal, no Google – aparecem anúncios locais de outros estabelecimentos nas
redondezas, atraídos como mariposas pela chama brilhante dos dados geográficos embutidos
no tweet.
A maior parte de toda essa sequência se desdobra em minutos, sem que você tenha de
pensar em qualquer outra coisa além de compor aqueles 140 caracteres e se lembrar de
apertar o botão para enviar.
Não se trata aqui da velha história de que vivemos numa era conectada, em que a
informação flui com mais rapidez do que nunca. A informação não apenas flui nesse sistema; é
reciclada e usada para novos fins, transformada por uma rede diversificada de outras espécies
no ecossistema, cada qual com sua função distinta. Você escreve um tweet sobre o que comeu
no almoço – o pecado original da banalidade do Twitter – e dentro de minutos essa
informação é utilizada para auxiliar um número incrível de tarefas: vizinhos estabelecendo
novas conexões pessoais, gastrônomos em busca de um delicioso prato de sopa de batata com
alho-poró, donos de restaurante recebendo um feedback franco de seus clientes, o Google
organizando toda a informação do mundo, jornais aperfeiçoando sua cobertura dos bairros a
um custo mais baixo e estabelecimentos locais procurando atrair a atenção das pessoas em sua
comunidade imediata. Nada mau para 140 caracteres.
Mas o que importa, é claro, é que esses 140 caracteres tiveram ajuda. A cada passo de sua
jornada pisavam em camadas de plataformas empilhadas. A simplicidade de enviar uma
mensagem para uma rede social de seguidores depende da API e da base de dados subjacente
do Twitter; o fato de ela chegar no mesmo instante a telefones celulares como mensagem de
texto se deve ao protocolo de comunicação SMS (assim como à rede de antenas de celular e
satélites); o site Outside.in distribui seus dados sobre bairros usando a plataforma aberta RSS;
os dados geográficos embutidos no tweet original baseiam-se na tecnologia de inteligência
militar do GPS adaptada; todos os Twittermaps envolvem chamadas de API para o serviço de
mapas do Google; e, é claro, a operação inteira é sustentada pela base de corais e zooxantelas
de protocolos subjacentes, como HTTP e TCP/IP. Todos esses serviços e padrões foram
essenciais para a teia de informação que se beneficiou daqueles 140 caracteres, mas nenhum
deles exigiu um acordo de desenvolvimento de negócios, ou uma taxa de licença, ou mesmo
um antiquado aperto de mãos. Você pode construir sobre todos eles sem pedir permissão, e
quando não é preciso pedir permissão a inovação floresce. Quando Guier, Weiffenbach e
McClure projetavam seu sistema para ajudar submarinos americanos a lançar mísseis Polaris
contra a União Soviética, nunca lhes passou pela cabeça que um dia alguém usaria aquela
plataforma para tecer elogios a um prato de sopa de batata com alho-poró para estranhos que
estivessem nas imediações. Plataformas empilhadas são assim: você pensa que está lutando na
Guerra Fria e descobre que, na realidade, está ajudando pessoas a descobrir onde almoçar.
De maneira irônica, o benefício real das plataformas empilhadas reside no conhecimento
que não precisamos mais ter. Não temos de saber como enviar sinais para satélites ou analisar
dados geográficos para fazer aquele tweet circular por todo o ecossistema da web. Miles
Davis não precisou construir um trompete de pistons ou inventar a escala dórica de ré para
gravar Kind of Blue. Não é necessário que a ave canora abrigada num ninho de pica-pau saiba
como furar um buraco num tronco de choupo, nem como derrubar uma árvore de mais de trinta
metros de altura. Esse é o poder generativo das plataformas abertas. A ave canora não arca
com o custo de furar e derrubar madeira porque o conhecimento de como fazer essas coisas
foi abertamente fornecido por outras espécies na cadeia. Basta-lhe saber gorjear.c
a Página ou aplicação da web que usa e combina dados, apresentações ou funcionalidades de duas ou mais fontes para criar

novos serviços. (N.T.)

b O mesmo padrão aparece nas florestas pluviais, exatamente por haver tantos organismos explorando cada minúsculo nicho do

ciclo de nutrientes. Essa eficiência é uma das razões por que abrir clareiras em florestas tropicais é um gesto tão míope: os
ciclos de nutrientes de seus ecossistemas são tão estreitos que o solo em geral é muito pobre para a agricultura – toda a energia
disponível foi captada antes de atingir a terra.

c Gorjear é to tweet em inglês. (N.T.)

Conclusão
O quarto quadrante
Numa área do Brooklyn chamada Williamsburg, na esquina um tanto desolada da Grand Street
com a Morgan Avenue, ergue-se um prédio de cinco andares, construído no estilo românico
adulterado que os arquitetos industriais apreciavam um século atrás. Hoje ele serve para uma
mescla de usos: jovens de vinte e poucos anos dividindo lofts nas franjas de uma das áreas
mais descoladas de Nova York, em meio a um punhado de pequenas empresas, a maioria na
área de informática. Há cem anos, o prédio teve um único ocupante: a Sackett-Wilhelm
Lithography Company. Quando paramos diante da porta da frente na Grand Street, ou
examinamos as trancas nas janelas do primeiro andar e as pichações nas antigas plataformas
de carga e descarga, nada indica a natureza histórica do lugar. Mas ele é histórico: a Sackett-
Wilhelm Lithography Company abrigou a primeira versão eficiente de uma máquina que faria
mais para transformar os padrões de povoamento dos seres humanos que qualquer outra
invenção do século XX, exceto talvez o automóvel.
Em 1902, a companhia possuía um lucrativo e crescente negócio de impressão de
publicações em cores, como a popular revista de humor Judge. Mas via-se diante de um
problema exasperante: o ar. Pequenas alterações na umidade podiam complicar o processo de
impressão em vários níveis: o papel se expandia ao absorver moléculas de água que flutuavam
no ar da fábrica; a tinta fluía em velocidades diferentes e demorava mais a secar. Dias
excepcionalmente úmidos podiam acarretar enorme atraso em toda a produção, tornando
difícil para os executivos da Sackett-Wilhelm cumprir os prazos de entrega prometidos aos
clientes.
Desde a descoberta do fogo, o ser humano vinha moderando a temperatura do ar de maneira
artificial. O século XIX havia testemunhado uma crescente tendência a sistemas mecânicos de
aquecimento. Alguns projetos exóticos tinham tentado refrescar o interior de prédios, mas
todos envolviam o resfriamento do ar com imensas quantidades de gelo. (O Madison Square
Theater em Manhattan usava quatro toneladas de gelo por dia para tornar as noites de verão
suportáveis para seus frequentadores.) Mas nenhuma dessas tentativas resolvia o problema da
umidade. Após duas ondas sucessivas de calor nos verões de 1900 e 1901, os proprietários da
Sackett-Wilhelm entraram em contato com o escritório da Buffalo Forge Company,
especializada em sistemas mecânicos de aquecimento para a grande indústria, em Nova York.
Eles eram especialistas em tornar o ar mais quente. Seriam capazes de torná-lo mais seco?
Eles tiveram sorte, porque o fundador da Buffalo Forge Company, William F. Wendt,
cedendo aos apelos de um ambicioso engenheiro elétrico de 25 anos chamado Willis Carrier,
havia acabado de criar um “programa de pesquisa” em que o jovem poderia empreender
projetos mais especulativos. O laboratório de Carrier era o lugar perfeito para o
enfrentamento de um problema como a desumidificação do ar, e ele se lançou no projeto com
entusiasmo. Após experimentar vários esquemas sugeridos pelos colegas, Carrier seguiu os
próprios instintos e construiu um aparelho no qual a água fria passava através de uma
serpentina, que usualmente transportava vapor. Usando tabelas de ponto de condensação
fornecidas pelo Weather Bureau, construiu um sistema que esfriava o ar até a temperatura de
condensação que produziria a umidade de 55% que a companhia Sackett-Wilhelm considerava
ideal. No final do verão de 1902, um sistema projetado por Carrier estava em funcionamento
na litografia. Ele extraía água de um poço artesiano e um esfriamento adicional era
proporcionado por uma máquina de refrigerar de amoníaco. O efeito total de esfriamento num
dia quente de verão equivalia ao derretimento de quase 50 mil quilos de gelo num único
período de 24 horas.
Nos anos seguintes, Carrier continuou tentando aperfeiçoar seu sistema. O aparelho da
Sackett-Wilhelm fora um sucesso, mas as serpentinas de aço tendiam a enferrujar com o uso
regular. Uma noite, enquanto esperava um trem na Filadélfia, observando um forte nevoeiro
avançar pela plataforma, Carrier teve um súbito lampejo. Seu sistema de condicionamento de
ar poderia ser uma máquina para produzir nevoeiros em miniatura: puxando ar através de um
fino spray de água dentro do aparelho, ele poderia usar a própria água como superfície de
condensação. Graças àquelas resistentes ligações de hidrogênio, as moléculas de vapor de
água no spray extrairiam a umidade do ar, tornando-o mais seco e eliminando o problema da
ferrugem. (Como disse Carrier em sua autobiografia: “Água não enferruja.”) Carrier requereu
uma patente por seu “Aparelho para tratamento do ar” em setembro de 1904, que lhe foi
concedida no segundo dia de 1906. Pouco tempo depois, com um grupo de engenheiros
empresariais da Buffalo Forge, Carrier desligou-se da empresa e fundou a Carrier Engineering
Corporation, dedicada exclusivamente à fabricação de aparelhos de ar-condicionado. À
medida que os condicionadores de ar passaram de curiosidade a item de luxo, transformando-
se por fim numa necessidade da classe média, a empresa fez de Carrier um homem rico. Em
2007, a Carrier Corporation, agora parte da United Technologies, arrecadou 15 bilhões de
dólares em vendas. Graças à brilhante ideia de seu fundador, a segunda metade do século XX
viu uma migração em massa dentro dos Estados Unidos em direção aos climas das regiões
Sul, Sudoeste e Sudeste, que haviam sido quase intoleráveis antes da adoção generalizada do
ar-condicionado. Não é exagero dizer que a ideia de Carrier teve por efeito final o rearranjo
do mapa social e político do país.
A HISTÓRIA DE CARRIER é o mito arquetípico da inovação moderna. Um indivíduo engenhoso,
trabalhando num laboratório privado de pesquisa, impelido pela ambição e a promessa de
grande riqueza, tem uma ideia brilhante num súbito lampejo e o mundo muda. Sim, a história
de Carrier é ligeiramente mais complicada do que essa versão caricata sugere. A princípio ele
estava mais interessado na umidade que na temperatura; a solução final levou vários anos para
se consolidar; e alguns de seus recursos técnicos baseavam-se em ideias de predecessores.
Mas essas objeções são irrelevantes. O caso de Carrier encaixa-se no molde clássico do
empreendedor genial. Faltam-lhe quase todos os padrões que vimos nos capítulos anteriores:
não há redes líquidas (nevoeiro à parte); não há exaptações em cafés; não há erros brilhantes.
E termina com a triunfante obtenção de uma patente.
Tudo isso leva à pergunta inevitável: Willis Carrier é ou não uma anomalia?
A questão tem implicações políticas e sociais reais, porque a doxa do capitalismo de
mercado como motor de inovação apoiou-se por muito tempo em histórias como a do
milagroso aparelho de refrigeração de Willis Carrier, como uma pedra angular de sua fé.a Sob
muitos aspectos, essas crenças faziam sentido, porque as alternativas implícitas eram as
economias planejadas do socialismo e do comunismo. As economias dirigidas pelo Estado
eram fundamentalmente hierarquias, não redes. Elas consolidavam o poder de tomar decisões
num sistema de comando de cima para baixo, o que significava que novas ideias tinham de ser
aprovadas pelas autoridades antes que pudessem começar a circular pela sociedade. Os
mercados, em contraposição, permitiam que boas ideias brotassem em qualquer lugar no
sistema. No moderno linguajar tecnológico, os mercados permitiam à inovação florescer nas
bordas da rede. As economias planejadas eram mais parecidas com os antigos sistemas de
computação de grande porte que antecederam a internet, em que cada participante tinha de
obter autorização de uma máquina central para fazer um novo trabalho. Em 1940, quando
Friedrich von Hayek propôs sua influente argumentação sobre a importância dos sinais de
preço em economias de mercado, estava observando um fenômeno relacionado: o mecanismo
descentralizado de estabelecimento de preços do mercado permite a um empresário estimar o
valor relativo de sua inovação. Se uma pessoa descobre uma engenhoca interessante, não
precisa convencer uma comissão do governo do quanto ela vale. Basta ter alguém que a
compre.
Instituições e estruturas legais inteiras – sem falar em uma vasta torre de sabedoria
convencional – foram construídas em torno do modelo de inovação de Carrier. Mas e se ele
for uma exceção e não a regra?
Há três abordagens principais para a solução de uma questão tão complexa como essa.
Podemos mergulhar fundo numa única história e tentar convencer nosso público de que ela
representa uma verdade social mais ampla. (Foi a estratégia que adotei ao contar as histórias
de John Snow e Joseph Priestley – e dos ambientes de inovação que moldaram seu trabalho –
em meus dois livros anteriores.) A vantagem dessa abordagem é nos permitir examinar um
estudo de caso em detalhes exaustivos. A desvantagem, claro, é que nosso público tem de
acreditar que o estudo de caso que escolhemos é realmente representativo de uma verdade
mais ampla. A segunda abordagem, que adotei nos capítulos anteriores deste livro, é construir
uma argumentação em torno de várias anedotas, pinçadas de diferentes contextos e períodos
históricos. A abordagem anedótica sacrifica o detalhe em prol da amplitude. Mas ela também
corre o risco de ser acusada de tendenciosa. Se houver uma centena de Willis Carriers para
cada Tim Berners-Lee, reunir histórias deste último num livro não prova de fato coisa alguma
(na verdade, pode ser enganoso).
Para escapar das distorções potenciais das abordagens do estudo de caso e anedótica, é
preciso examinar todo o campo da inovação através de uma única lente. Não há como saber se
Willis Carrier é uma exceção estudando os detalhes de sua biografia. É preciso uma visão
mais ampla. Façamos então um experimento com os dados disponíveis sobre a história da
inovação. Tomemos cerca de duzentas das inovações e descobertas científicas mais
importantes dos últimos seiscentos anos, começando com a prensa de tipos móveis de
Gutenberg: todo tipo de coisa, da teoria da relatividade de Einstein à invenção do ar-
condicionado e ao nascimento da World Wide Web. Vamos marcar cada descoberta em algum
lugar de um dos quatro quadrantes deste diagrama:
Vamos classificar toda inovação que tenha envolvido uma equipe pequena e coordenada no
seio de uma organização – ou, melhor ainda, um único inventor – como “individual”, e como
“em rede” todas aquelas que se desenvolveram por meio de processos coletivos, distribuídos,
com um grande número de grupos trabalhando no mesmo problema. Inventores que planejaram
lucrar diretamente com as vendas ou o licenciamento de sua criação devem ser classificados
como “mercado”; os que desejaram que suas ideias circulassem livremente na esfera da
informação pertencem ao lado do “não mercado”. O resultado são quatro quadrantes: o
primeiro relacionado à empresa privada ou ao empreendedor isolado; o segundo a um
mercado em que diversas empresas interagem; o terceiro ao cientista amador ou diletante, que
compartilha suas ideias livremente; e, por fim, o quarto quadrante, que corresponde a
ambientes de código aberto ou acadêmicos, nos quais as ideias podem servir de base a outras
e ser reimaginadas em grandes redes colaborativas.
Adotando essa perspectiva de longo prazo, podemos começar a responder à nossa questão
inicial: em que medida o modelo de inovação de Willis Carrier é dominante?b Qual quadrado
tem o histórico mais impressionante em matéria de geração de boas ideias?
Para nos orientarmos um pouco, nosso principal ocupante do primeiro quadrante –
individual baseado no mercado – é o próprio Carrier, que conduziu sozinho a invenção do
condicionador de ar e tinha claras aspirações comerciais para seu aparelho. (Gutenberg deve
ser inserido aí também). Um exemplo de inovação de mercado em rede seria o tubo de vácuo,
cuja criação envolveu uma rede descentralizada com dezenas de participantes fundamentais,
incluindo Lee de Forest, que trabalharam quase todos como empreendedores interessados em
patentes ou cientistas pesquisadores no âmbito de corporações maiores. A criação da World
Wide Web por Tim Berners-Lee pertence ao quadrante individual, não baseado no mercado,
ao passo que a própria internet pertence ao quarto quadrante, dado o vasto número de
indivíduos e organizações do setor público envolvido na sua criação.
Cabe notar que essas classificações não refletem a natureza cumulativa de quase toda
inovação. Berners-Lee precisou da plataforma aberta da internet para que sua criação do
hipertexto decolasse, motivo pelo qual os muitos indivíduos que construíram a Arpanet e o
TCP/IP deveriam ser vistos como colaboradores fundamentais da web. Se essas plataformas
tivessem sido mais proprietárias – digamos, cobrando taxas de licença pelo privilégio de usá-
las como base – é bem possível que Berners-Lee não tivesse se dado o trabalho de criar a
web, uma vez que esse foi um projeto paralelo sobre o qual seus superiores quase nada
sabiam.
É da natureza das boas ideias erguerem-se nos ombros de gigantes que as precederam, o
que significa que, em certa medida, toda inovação importante depende fundamentalmente de
uma rede. Para ficar claro, porém, convém não borrar a linha entre “indivíduo” e “rede”
incluindo na discussão as inovações anteriores que inspiraram ou sustentaram a nova geração
de ideias. Sim, é importante que Gutenberg tenha tomado emprestada a tecnologia da prensa
de parafuso dos vinicultores, mas não podemos dizer que sua prensa de tipos móveis foi uma
inovação coletiva da mesma maneira que, por exemplo, a internet foi. Por isso Gutenberg e
Berners-Lee são classificados no lado individual do espectro.
Não há nenhuma fórmula matemática confiável para o estabelecimento dessas
classificações, e até certo ponto todas elas têm um componente de subjetividade. Mas acredito
que, vistas em conjunto, elas revelam um padrão interessante – interessante o bastante, eu
diria, para que se tolere um pequeno ruído nos dados. Estamos acostumados a ver certos
desenvolvimentos históricos – principalmente demográficos – nesse formato condensado de
lapso de tempo. Observamos o crescimento de cidades, mercados ou populações nacionais em
gráficos em que cada momento mede um século. Esses exames baseados em lapsos de tempo
põem a nu verdades sobre as quais levantamentos no tempo presente ou narrativas individuais
não podem lançar luz de maneira apropriada. (O Ensaio sobre os princípios da população de
Malthus, que tanto inspirou Darwin e Wallace, ofereceu um dos primeiros vislumbres desse
efeito especial.) Raras vezes, porém, medimos mudanças culturais dessa maneira. Assim,
grande parte da história das ideias assemelha-se ao trabalho de Darwin como naturalista
durante os longos anos que precederam a publicação de A origem das espécies: analisar as
espécies individuais, definir suas características essenciais e colocá-las na caixa apropriada.
Essa é uma ótima abordagem para compreender por que uma ideia específica surgiu num
determinado momento no tempo. Mas, se quisermos enfrentar a questão um elo adiante na
cadeia – como boas ideias tendem a surgir –, temos de atacar o problema de um ângulo
diferente. Há momentos para se contar cracas. Porém, às vezes precisamos afastar o zoom e
adotar a visão mais de longo alcance.
Ao escolher essa abordagem, estou exaptando uma técnica que o historiador literário
Franco Moretti chama de “leitura distante”. Numa série de livros e ensaios influentes
publicados ao longo da década passada, Moretti rompeu com a abordagem tradicional do
Departamento de Literatura da “close reading”, em que textos literários individuais são
analisados em exaustivo detalhe. Não importa se a leitura em questão é um tributo à moda
antiga aos talentos singulares de um artista ou uma desconstrução politizada – podemos ler o
texto em minúcia para revelar o gênio do autor, ou sua homofobia latente, mas em ambos os
casos estamos fazendo uma leitura atenta, em que cada frase é um potencial dado em nossa
análise. (“No fundo”, escreve Moretti, “é um exercício teológico – o tratamento muito solene
de um número muito pequeno de textos levados muito a sério.”) A leitura distante adota uma
visão de satélite da paisagem literária, procurando padrões mais vastos na história das
histórias que contamos uns aos outros. Em uma análise tipicamente inventiva, Moretti rastreou
a evolução dos subgêneros nos romances populares britânicos de 1740 a 1915, uma imensa
taxonomia de formas narrativas – romances de espionagem, picarescos, góticos, mistério,
histórias náuticas e outras tantas formas distintas. Representou num gráfico o tempo de vida de
cada subgênero como uma espécie dominante no ecossistema literário britânico. O resultado
está na página seguinte.
Quando adotamos a abordagem distante para a leitura de romances, somos capazes de ver
padrões que simplesmente não são visíveis na escala de parágrafos e páginas, ou mesmo de
livros inteiros. Podemos ler uma dúzia de silver-fork novelsc e Bildungsromans e ainda assim
não perceber o fato mais notável revelado pelo gráfico de Moretti: que a diversidade de
formas tem um equilíbrio impressionante entre si, devido a seus tempos de vida
misteriosamente semelhantes, o que ele atribui à rotatividade geracional subjacente. A cada
intervalo de 25 a trinta anos, uma nova fornada de gêneros torna-se dominante, ao mesmo
tempo que uma nova geração de leitores busca novas convenções literárias. Se você estiver
tentando entender o significado de uma obra individual, deve lê-la em detalhe. Mas, se estiver
interessado no comportamento global do sistema literário – seus próprios padrões de
inovação –, às vezes terá de ler a uma grande distância.
No estudo da inovação científica ou tecnológica, o equivalente da leitura atenta é a
biografia meticulosa do grande inventor ou a história de uma única tecnologia – por exemplo,
o rádio ou o computador pessoal. Por mais valiosas que sejam, essas abordagens têm suas
limitações. A leitura detalhada nos deixa com as idiossincrasias de cada indivíduo ou
invenção, um colorido local – mas não com as leis gerais. Quando consideramos a história da
inovação à distância, o que perdemos em detalhe ganhamos em perspectiva. A classificação
de duzentas boas ideias em quatro amplos quadrantes torna sem dúvida mais difícil aprender
algo específico sobre cada inovação individual. Porém, nos permite responder à nossa
questão inicial: que tipos de ambientes tornam a inovação possível?
Como a inovação está sujeita a mudanças históricas – muitas das quais são elas próprias
resultado de influentes inovações na transmissão da informação –, os quatro quadrantes
exibem formas distintas em períodos históricos diferentes. Vamos partir dessa visão das ideias
revolucionárias de 1400 a 1600, começando com a prensa de Gutenberg e continuando até os
primórdios do Iluminismo (ver página seguinte).
Esse é o formato que as inovações da época do Renascimento assumem, vistas de uma
grande distância (conceitual). A maior parte delas se agrupa no terceiro quadrante: não
mercado/individual. Um punhado de exceções se distribui de maneira bastante uniforme pelos
outros três quadrantes. Esse é o padrão que se forma quando as redes de informação são lentas
e não confiáveis, e as convenções econômicas empresariais estão pouco desenvolvidas. É
difícil compartilhar ideias quando a imprensa e o sistema postal ainda são novidades e, na
ausência de um mercado robusto de compradores e investidores, não há incentivo suficiente
para comercializá-las. Por isso a era é dominada por artistas solistas: investigadores
amadores, em geral abastados, que se dedicam às suas obsessões pessoais. Como não é de
surpreender, esse período marca o nascimento da noção moderna do gênio inventivo, o
visionário desgarrado que, de alguma maneira, enxerga além do horizonte que limita seus
contemporâneos – Da Vinci, Copérnico, Galileu. Alguns desses solistas (dos quais Galileu foi
o mais famoso) trabalharam fora de grupos mais amplos porque sua pesquisa ameaçava de
maneira significativa os poderes estabelecidos da época. As poucas inovações que de fato
emergiram de redes – os relógios portáteis de mola, que surgiram pela primeira vez em
Nuremberg em 1480, e o sistema de contabilidade de dupla entrada, desenvolvido por
negociantes italianos – têm suas origens geográficas em cidades, onde as redes de informação
eram mais desenvolvidas. Os empreendedores solitários do primeiro quadrante, que
construíam seus produtos em segredo para assegurar os ganhos finais que propiciariam,
revelam-se praticamente inexistentes. Gutenberg foi uma exceção, não a regra.
Examinando os dois séculos seguintes, veremos que os padrões mudam de maneira
espetacular (ver página seguinte).
A invenção solitária, amadora (quadrante três) cede grande parte de sua liderança ao poder
ascendente das redes e das trocas comerciais (quadrante quatro). A mudança mais
extraordinária situa-se ao longo do eixo horizontal, numa migração em massa das descobertas
individuais (à esquerda) para os insights criativos em grupo (à direita). Durante o
Renascimento, menos de 10% das inovações ocorrem em rede; dois séculos depois, a maioria
das grandes inovações surge em ambientes colaborativos. Múltiplos desenvolvimentos
provocam essa mudança, a começar pela prensa de Gutenberg, que passa a ter um impacto
importante sobre a pesquisa um século e meio depois da chegada da primeira Bíblia às
bancas, à medida que ideias científicas vão sendo armazenadas e compartilhadas na forma de
livros e panfletos. Os sistemas postais, tão centrais para a ciência do Iluminismo, florescem
por toda a Europa; as densidades populacionais aumentam nos centros urbanos; cafés e
instituições formais como a Royal Society criam novos centros para a colaboração intelectual.
Muitos desses centros de inovação existem fora do mercado. As grandes mentes do período
Newton, Franklin, Priestley, Hooke, Jefferson, Locke, Lavoisier, Lineu – tinham pouca
esperança de recompensa financeira por suas ideias, e faziam tudo o que estava em seu
alcance para lhes dar uma circulação mais ampla. Mesmo assim, é possível perceber um
movimento vertical rumo a incentivos de mercado. Quando o capitalismo industrial surge na
Inglaterra no século XVIII, novas estruturas econômicas tornam os negócios de risco
potencialmente mais lucrativos: compensações sedutoras atraem inovadores para a empresa
privada, e a transformação das leis de patentes inglesas em código no início desse século
imprime alguma confiança de que boas ideias não serão roubadas com impunidade. Apesar
dessa nova proteção, a maior parte das inovações comerciais durante esse período assume
uma forma colaborativa, com muitos indivíduos e empresas acrescentando melhorias e
refinamentos ao produto. Os livros de história gostam de condensar esses processos
evolucionários mais lentos em eurecas instantâneos de um único inventor, mas as tecnologias
essenciais que potencializaram a Revolução Industrial foram, em sua maioria, exemplos do
que os estudiosos chamam de “invenção coletiva”. Os livros didáticos referem-se
informalmente a James Watt como o inventor da máquina a vapor, mas na verdade Watt foi um
em meio a diversos inovadores que a aperfeiçoaram no curso do século XVIII.
FAÇAMOS UMA BREVE PAUSA no ápice da idade moderna e arrisquemos algumas apostas quanto
ao padrão que se formará nos dois últimos séculos do milênio. Creio que a maioria de nós
espera ver uma espetacular consolidação da atividade inovadora no primeiro quadrante, pois
o capitalismo entra em seu período maduro, que abarca as eras da produção em massa e da
sociedade de consumo. Tem-se a impressão de que todos os elementos preveem uma explosão
de atividade no primeiro quadrante: um público cada vez mais próspero desejando gastar
dinheiro em novas engenhocas; imposição vigorosa dos direitos de propriedade intelectual;
surgimento de laboratórios de pesquisa e desenvolvimento nas grandes empresas; e um
crescente grupo de empresas de capital privado disposto a financiar empreendimentos
especulativos. Se o mercado competitivo do capitalismo moderno é o grande motor de
inovação de nosso tempo, o primeiro quadrante deveria, por direito, dominar os dois últimos
séculos de atividade.
O padrão que aparece, porém, é outro (ver abaixo).
Contra todas as probabilidades, o primeiro quadrante se revela o mais vazio da grade.
Willis Carrier, afinal de contas, é uma exceção. No setor privado, a descoberta proprietária
realizada num laboratório fechado torna-se uma raridade. Para cada Alfred Nobel, que
inventou a dinamite em segredo nos subúrbios de Estocolmo, há meia dúzia de criações
coletivas como o tubo de vácuo ou a televisão, cuja existência dependeu de várias empresas
movidas pelo lucro, que conseguiram criar um novo produto importante por meio de redes
descentralizadas. Reza a lenda que Edison inventou a lâmpada elétrica, mas na verdade ela
surgiu através de uma complexa rede de interações entre Edison e seus rivais, cada um
adicionando peças essenciais ao quebra-cabeça ao longo do processo. A invenção coletiva
não é uma fantasia socialista. Empreendedores como Edison e De Forest foram muito
motivados pela possibilidade de compensações financeiras e tentaram patentear tudo que
puderam. Mas muitas vezes a utilidade de usar as ideias de outras pessoas como base
suplantou a exclusividade de construir algo a partir do zero. Podiam-se desenvolver pequenas
ideias numa sala fechada, sem acesso às intuições e insights dos concorrentes. No entanto,
quando se pretendia fazer uma nova incursão de vulto no possível adjacente, era preciso ter
companhia.
Mais impressionante ainda, porém, é a explosão de atividade no quarto quadrante.
Por que tantas boas ideias prosperaram no quarto quadrante, apesar da falta de incentivos
econômicos? Talvez porque estes tenham uma relação muito mais complexa com o
desenvolvimento e a adoção de boas ideias do que em geral imaginamos. A promessa de um
lucro imenso estimula as pessoas a procurar descobrir inovações úteis, mas ao mesmo tempo
as obriga a protegê-las. Os economistas definem “mercados eficientes” como aqueles em que
a informação está uniformemente distribuída entre todos os compradores e vendedores no
espaço. Em geral se considera a eficiência uma meta universal para qualquer economia – a
menos que ela comercie ideias. Se as ideias fossem completamente liberadas, os empresários
não poderiam lucrar com suas inovações, porque os concorrentes as adotariam de imediato.
Assim, no que diz respeito à inovação, construímos de maneira deliberada mercados
ineficientes: ambientes que protegem direitos autorais, patentes e segredos industriais, além
de mil outras barreiras que erigimos para manter ideias promissoras longe do conhecimento
dos outros.
Essa ineficiência deliberada não existe no quarto quadrante. Nesses ambientes não
comerciais e descentralizados não há lucros enormes para motivar os participantes, mas sua
abertura cria outras oportunidades poderosas para o florescimento de boas ideias. Todos os
padrões de inovação que observamos nos capítulos anteriores – redes líquidas, intuições
lentas, serendipidade, ruído, exaptação, plataformas emergentes – se adaptam melhor aos
ambientes abertos, nos quais as ideias fluem por canais não regulados. Em ambientes mais
controlados, onde o movimento natural das ideias é rigorosamente coibido, tais padrões são
sufocados. Uma intuição lenta não encontra com facilidade seu caminho até outra intuição que
poderia completá-la se houver uma tarifa a ser paga cada vez que ela tenta estabelecer uma
nova conexão serendipitosa; dificilmente ocorrem exaptações entre disciplinas diferentes caso
haja sentinelas vigiando suas fronteiras. Em ambientes abertos, no entanto, é fácil esses
padrões de inovação ganharem raízes e se multiplicarem.
Como toda realidade social complexa, a criação de ambientes propícios à inovação é uma
questão de escolha. Se todas as outras coisas permanecerem iguais, os incentivos financeiros
irão de fato estimular a inovação. O problema é que todas as outras coisas nunca são iguais.
Quando introduzimos recompensas financeiras num sistema, surgem barreiras e sigilo, e os
padrões abertos de inovação passam a ter mais dificuldade para operar sua mágica. A
pergunta, portanto, é: qual é o equilíbrio certo? É sem dúvida concebível que a promessa de
tirar a sorte grande seja tão irresistível que mais do que compense as ineficiências
introduzidas pela lei da propriedade intelectual e pelos laboratórios de P&D fechados. Em
geral essa foi a suposição básica na maior parte das discussões recentes sobre as raízes da
inovação, uma suposição baseada no histórico de inovação do livre mercado durante esse
período. Como as economias capitalistas se provaram mais inovadoras que as economias
socialistas e comunistas, dizia essa versão dos fatos, as ineficiências deliberadas da
abordagem baseada no mercado deviam ter mais benefícios que custos.
Mas, como vimos, essa é uma falsa comparação. Não se trata de comparar o desempenho
do mercado com o das economias planejadas. A comparação que se impõe é entre o mercado
e o quarto quadrante. À medida que a grande empresa privada se desenvolvia nos dois últimos
séculos, uma imagem especular dela cresceu em paralelo no setor público: a universidade
moderna voltada para a pesquisa. Hoje, a maior parte da pesquisa acadêmica tem a
abordagem do quarto quadrante: novas ideias são publicadas com o objetivo de permitir a
outros participantes aprimorá-las e usá-las como base, sem quaisquer restrições à sua
circulação além do devido reconhecimento de sua origem. Não se trata de pura anarquia, é
claro. Você não pode simplesmente surrupiar a ideia de um colega sem lhe dar o devido
crédito, mas há uma diferença fundamental entre processar por violação de patente e pedir
uma nota de rodapé. Os pesquisadores acadêmicos obviamente recebem salários, e ideias de
sucesso podem levar a cátedras muito cobiçadas, mas as recompensas econômicas são
minúsculas se comparadas às do setor privado. E, o que é decisivo, tais recompensas não
dependem da introdução de uma ineficiência artificial na rede de informação. É provável que
um historiador que desenvolve uma teoria brilhante sobre as origens da Revolução Industrial
obtenha uma cátedra numa escola da Ivy League, mas a própria teoria pode circular livremente
através do ambiente, onde está sujeita a ser contestada, ampliada, exaptada e reciclada de
inúmeras maneiras. O sistema universitário pode ser um negócio de grande escala hoje em dia,
e as patentes por certo desempenham um papel importante em certos campos especializados,
mas em geral a universidade permanece um sistema dedicado a produzir e preservar
informação para as gerações presentes e futuras.
As universidades têm a reputação de serem torres de marfim, isoladas do mundo real, mas
é inegável que a maioria das ideias paradigmáticas surgidas na ciência e na tecnologia durante
o século XX tem raízes na pesquisa acadêmica. Isso é obviamente verdadeiro no tocante às
ciências “puras”, como a física teórica, mas também no que diz respeito a linhas de pesquisa
que à primeira vista parecem ter aplicações mais francamente comerciais. O contraceptivo
oral, por exemplo, gerou bilhões de dólares para a Big Pharma na última metade do século
XX, porém a maior parte da pesquisa decisiva que levou a seu desenvolvimento foi feita nas
terras comunais intelectuais dos laboratórios de Harvard, Princeton e Stanford. Na linguagem
do capítulo anterior, redes abertas de pesquisadores acadêmicos criam com frequência
plataformas emergentes em que o desenvolvimento comercial se torna possível. É provável
que a próxima década veja uma onda de produtos farmacêuticos que a ciência genômica
tornará possível, mas essa plataforma científica subjacente – ou seja, a capacidade de
sequenciar e mapear o DNA – foi quase inteiramente desenvolvida por um grupo
descentralizado de cientistas acadêmicos trabalhando fora do setor privado nas décadas de
1960 e 70. Esse é um padrão que vemos a todo momento na era moderna: a inovação do
quarto quadrante cria uma nova plataforma aberta na qual entidades comerciais podem se
basear depois, seja para dar nova cara e aprimorar a descoberta original, seja desenvolvendo
inovações sobre a plataforma subjacente.
A inovação do quarto quadrante foi ajudada também por outro desenvolvimento
fundamental: o maior fluxo de informação. O transbordamento da informação precisou da
densidade geográfica das cidades no Renascimento, e o sistema postal tornou possível a
formação de pequenas teias disseminadas de criatividade na era do Iluminismo. Mas a internet
de fato reduziu os custos do compartilhamento de boas ideias a zero. Na época de Galileu,
todos os benefícios do transbordamento de informação eram tão potentes quanto hoje, mas era
muito mais difícil criar o tipo de rede líquida em que colisões serendipitosas e exaptações
podiam ocorrer. A conectividade da vida moderna significa que enfrentamos o problema
oposto: é muito mais difícil impedir que a informação transborde do que pô-la em circulação.
A consequência disso é que as empresas do setor privado decididas a proteger seus bens
intelectuais têm de investir tempo e dinheiro na construção de barreiras de escassez artificial.
Os participantes do quarto quadrante não têm esses custos: podem se concentrar na descoberta
de nova ideias, não na construção de fortalezas em torno das velhas. E, como essas ideias
podem circular livremente através da esfera da informação, outras mentes na rede podem
aprimorá-las e expandi-las.
Não temos um vocabulário político pronto para o quarto quadrante, em particular para as
formas não institucionais de colaboração que se desenvolveram em torno da comunidade de
código aberto. Como esses sistemas abertos não dependem dos incentivos convencionais do
capitalismo e resistem às restrições usuais da propriedade intelectual, a mente tende a situá-
los automaticamente no lado do socialismo. No entanto, eles estão tão longe das economias
estatais centralizadas que Marx e Engels ajudaram a inventar quanto da ganância do
capitalismo. Embora não sejam em si produto de incentivos de mercado, criam muitas vezes
ambientes em que empresas privadas prosperam, um fenômeno ao qual Lawrence Lessig alude
com seu conceito de “economia híbrida”, que mescla elementos das redes abertas das terras
comunais intelectuais com os muros e tarifas mais proprietários da esfera privada.
Nada disso implica que o mercado seja inimigo da inovação, ou que a competição entre
empresas concorrentes não conduza com frequência a novos produtos úteis. (Afinal, o segundo
quadrante está repleto de inúmeras ideias brilhantes que mudaram nossas vidas para melhor.)
E burocracias inchadas continuam sendo sumidouros da inovação. Mas, felizmente para nós, a
escolha não está entre mercados descentralizados e estados de comando e controle. Grande
parte da história do progresso intelectual nos últimos séculos ocorreu num espaço menos
formal entre esses dois regimes: no seminário da pós-graduação, no café, na casa do diletante
e no quadro de avisos digital. O quarto quadrante deveria ser um lembrete de que existe mais
de uma fórmula para a inovação. As maravilhas da vida moderna não se originaram
exclusivamente do choque proprietário entre empresas privadas. Surgiram também de redes
abertas.
ALGUNS MESES DEPOIS que Darwin publicou A origem das espécies em 1859, Karl Marx
escreveu uma carta para Friedrich Engels que incluía algumas linhas endossando o
radicalismo biológico de Darwin. “Embora desenvolvido no cru estilo inglês, este é o livro
que contém a base na história natural para nossa concepção.” O “cru estilo inglês” era
evidentemente a estranha relutância de Darwin em relacionar suas ideias científicas com a
dialética hegeliana. (Hoje muitos veem isso com um dos pontos fortes de Darwin como
escritor.) Sarcasmos à parte, Marx e Engels foram claramente revigorados pela controvérsia
que Darwin desencadeara e o enxergaram como um espírito afim numa era que parecia à beira
de múltiplas revoluções – tanto na ciência quanto na sociedade. Não está claro se Darwin
nutriu os mesmos sentimentos por seus admiradores prussianos. Marx propôs dedicar o
segundo volume de O capital a Darwin, que objetou: “Eu preferiria que a parte ou o volume
não fosse dedicada a mim (embora lhe agradeça pela homenagem que pretendeu me fazer),
pois isso iria, em certa medida, sugerir minha aprovação de toda a obra, da qual não tenho
conhecimento.”
De um ponto de vista científico, Marx e Engels foram astutos ao tomar partido de Darwin
tão cedo no debate sobre sua “perigosa” ideia. Mas não poderiam ter se enganado mais
redondamente em suas previsões sobre o papel que a teoria desempenharia na arena político-
econômica. Eles anteviram, de maneira acertada, que se fariam analogias entre a
“sobrevivência dos mais aptos” de Darwin e a seleção competitiva das economias capitalistas
de livre mercado, mas estavam convencidos de que elas seriam propostas como críticas ao
capitalismo. Em 1865, Engels escreveu para um amigo: “Nada desacredita tanto o
desenvolvimento burguês moderno quanto o fato de que ele ainda não conseguiu ir além das
formas econômicas do mundo animal.”
Como se viu, ocorreu exatamente o oposto. As teorias de Darwin foram invocadas
inúmeras vezes no século XX em defesa do sistema de livre mercado. O alinhamento com o
mundo animal não desacreditou os mercados, como Engels previra. Ao contrário, os fez
parecer algo natural. Se a Mãe Natureza produziu um planeta tão esplendidamente diverso
através de um algoritmo de competição implacável entre agentes egoístas, por que nossos
sistemas econômicos não haveriam de seguir as mesmas regras?
A verdadeira história da natureza, porém, não se reduz à competição implacável entre
agentes egoístas, como o próprio Darwin percebeu. A origem das espécies termina com uma
das passagens mais famosas na história da ciência, cujas palavras fazem eco ao verbete do
diário que ele escrevera ao deixar as ilhas Cocos mais de vinte anos antes:
É interessante contemplar uma ribanceira emaranhada, forrada com muitas plantas de várias espécies, com aves a cantar
nos arbustos, diversos insetos a esvoaçar por toda parte e minhocas a rastejar pela terra úmida, e refletir que essas formas
intrincadamente construídas, tão diferentes entre si e em tão complexa dependência umas das outras, foram todas
produzidas por leis que operam à nossa volta. ... Dessa maneira, é da guerra da natureza, da fome e da morte que o mais
excelso objeto que somos capazes de conceber, a saber, a produção dos animais elevados, decorre diretamente. Há uma
grandeza nessa visão da vida...”
As palavras de Darwin oscilam entre duas metáforas estruturantes que governam toda a sua
obra: as complexas interdependências da ribanceira emaranhada e a guerra da natureza; as
conexões simbióticas de um ecossistema e a sobrevivência dos mais aptos. A caricatura
difundida da teoria de Darwin enfatiza a luta competitiva acima de tudo. Contudo, muitas das
descobertas que sua teoria tornou possíveis revelaram as forças colaborativas e conectivas em
ação no mundo natural.
Temos convivido com uma caricatura semelhante em nossas pressuposições sobre a
inovação cultural. Se olharmos para os últimos cinco séculos a partir da perspectiva
distanciada, um fato salta aos olhos de imediato: a competição baseada no mercado não tem
nenhum monopólio da inovação. A competição e o lucro de fato nos motivam a transformar
boas ideias em produtos acabados, mas, o mais das vezes, as ideias em si vêm de outro lugar.
Seja qual for sua política, o quarto quadrante tem sido um extraordinário espaço de
criatividade e insight humanos. Mesmo sem as compensações econômicas da escassez
artificial, os ambientes do quarto quadrante desempenharam um papel de enorme importância
no cultivo e circulação de boas ideias – agora mais do que nunca. Na linguagem de Darwin, as
conexões abertas da ribanceira emaranhada foram tão generativas quanto a guerra da natureza.
Stephen Jay Gould defende essa ideia com vigor na alegoria de sua coleção de sandálias: “A
cunha da competição tem sido, desde Darwin, o argumento canônico para o progresso em
tempos normais”, escreve ele. “Mas quero afirmar que a roda da mudança funcional súbita e
imprevisível (o princípio da transformação de pneus em sandálias) é a principal fonte do que
chamamos de progresso em todas as escalas.” O empreendedor de Nairóbi vendendo
sandálias na feira pode de fato competir com outros sapateiros, mas o que torna seu comércio
possível é o ferro-velho cheio de pneus à espera de ser livremente convertidos em calçados, e
o fato de que a boa ideia de converter pneus em sandálias pode ser transmitida de um
sapateiro para outro pela simples observação, sem quaisquer acordos de licenciamento que
restrinjam o fluxo.
EM 1813, UM DONO DE MOINHO DE BOSTON, Isaac McPherson, viu-se mergulhado numa longa e
frustrante disputa por uma patente com um inventor da Filadélfia chamado Oliver Evans, que
havia registrado um moinho de cereais automatizado vários anos antes. A engenhosidade de
Evans só era igualada por seu amor ao litígio. Ele era conhecido por impor agressivamente
suas patentes e foi um dos primeiros a tirar partido dos novos poderes restritivos do sistema
federal de patentes após sua criação em 1790. A originalidade da invenção patenteada por
Evans era muito discutível; o sistema do moinho baseava-se em elevadores de caçamba,
esteiras transportadoras e parafusos arquimedianos – inovações que eram de domínio público
havia muito tempo. Quando Evans processou McPherson por violar sua patente, o industrial de
Boston decidiu recorrer ao primeiro diretor do escritório de patentes dos Estados Unidos, um
ex-político e também ele um inventor, que agora morava na zona rural da Virgínia. Assim, no
verão de 1813, McPherson escreveu uma carta a Thomas Jefferson, pedindo sua interpretação
da reivindicação de Oliver Evans.
Jefferson respondeu no dia 13 de agosto. Ao ler a carta hoje, a amplitude da sua
inteligência não deixa de ser surpreendente. Seu foco se estreita em detalhes extremamente
técnicos sobre as especificidades da invenção de Evans, para se alargar depois em
comentários sobre a longa pré-história das mesmas. (“O parafuso de Arquimedes é, no
mínimo, tão antigo quanto a idade desse matemático, que morreu 2 mil anos atrás. Diodorus
Siculus fala sobre isso, L.i., p.21, e L.v., p.217, da edição Stevens de 1559, fólio; e Vitruvius,
xii.”) Ele analisa a legislação pertinente com o olhar aguçado de jurista, opinando sobre as
seções que lhe parecem fundamentalmente equivocadas. Mas os trechos mais sensacionais
surgem quando Jefferson passa a filosofar sobre a natureza das próprias ideias:
A propriedade estável é uma dádiva da lei social, e é estabelecida tardiamente no progresso da sociedade. Seria curioso,
portanto, se uma ideia, fermentação fugidia de um cérebro individual, pudesse, por direito natural, ser reivindicada como
propriedade exclusiva e estável. Se a natureza tornou uma única coisa menos suscetível de propriedade exclusiva que todas
as outras, foi a ação do poder pensante chamada ideia, que um indivíduo só pode possuir enquanto a guarda para si; no
momento em que é divulgada, porém, ela se impõe à posse de todos, e o receptor não pode se despojar dela. Seu caráter
peculiar, também, é que ninguém a possui menos pelo fato de todos os demais a possuírem na totalidade. Aquele que recebe
uma ideia de mim ganha instrução sem reduzir a minha; assim como aquele que acende sua vela na minha recebe luz sem
me obscurecer. Que as ideias devam se espalhar livremente de uma pessoa para outra no planeta, para a instrução moral e
mútua do homem e a melhoria de sua condição, parece ter sido peculiar e benignamente projetado pela natureza, quando ela
as fez, como o fogo, que se expande por todo espaço sem que sua densidade se reduza em nenhum ponto, e como o ar que
respiramos, e no qual nos movemos e temos nosso ser físico, incapaz de confinamento ou apropriação exclusiva. As
invenções não podem, então, por natureza, ser objeto de propriedade.
As ideias, afirma Jefferson, têm uma atração quase gravitacional pelo quarto quadrante. O
estado natural delas é fluxo, transbordamento e conexão. É a sociedade que as mantém
agrilhoadas.
Quer dizer que temos de acabar com a lei da propriedade intelectual? Claro que não. O
histórico de inovações do quarto quadrante não significa que deveríamos abolir as patentes e
permitir que todas as formas de informação circulem livremente. Mas deveria desmentir a
ortodoxia reinante segundo a qual sem a escassez artificial da propriedade intelectual a
inovação cessaria pouco a pouco. Há muitas razões compreensíveis para que a lei torne mais
fácil que pessoas ou organizações inovadoras lucrem com suas criações. Podemos decidir,
enquanto sociedade, que as pessoas simplesmente merecem lucrar com suas boas ideias,
sendo por isso necessário introduzir um pouco de escassez artificial para assegurar essas
recompensas. Como alguém que vive da criação de propriedade intelectual, sou mais do que
simpático a esse argumento. Mas afirmar que essas restrições irão por si mesmas, com o
tempo, promover a inovação é completamente diferente.
Como Lawrence Lessig argumentou de maneira bastante convincente ao longo dos anos,
não há nada de “natural” na escassez artificial gerada pela lei de propriedade intelectual.
Essas leis são intervenções deliberadas produzidas pela inteligência humana e impostas quase
inteiramente por poderes não comerciais. O que Jefferson defende na carta a McPherson é
que, se quisermos entrar de fato num debate sobre que sistema é mais “natural”, o livre curso
das ideias sempre levará a melhor sobre a escassez artificial das patentes. As ideias são
intrinsecamente copiáveis, de uma maneira que alimento e combustível não são. É preciso
construir represas para impedir que elas fluam.
A meu ver, a grande questão de nossa época é se as grandes organizações – públicas e
privadas, governos e empresas – podem tirar melhor proveito da turbina de inovação dos
sistemas do quarto quadrante. No âmbito do setor privado, o sucesso de companhias como
Google, Twitter e Amazon – todas as quais, de diferentes maneiras, contribuíram e se
beneficiaram da inovação do quarto quadrante – deixou claro que, pelo menos no mundo do
software, uma pequena abertura leva longe. Suspeito de que essas lições se tornarão cada vez
mais inevitáveis nas próximas décadas. Mas é o setor público que me parece mais
interessante, porque os governos e outras instituições não comerciais por muito tempo
padeceram da ineficiência das burocracias inchadas. Hoje, essas instituições têm uma
oportunidade para alterar de maneira fundamental seu modo de cultivar e promover boas
ideias. Quanto mais o governo pensar sobre si mesmo como uma plataforma aberta em vez de
uma burocracia centralizada, melhor será para todos nós, cidadãos, ativistas e empresários.
A maravilhosa ironia é que essa oportunidade histórica se abre para os governos em parte
graças a uma inovação que eles desencadearam no mundo: a internet, provavelmente o
exemplo mais claro da maneira como a inovação do setor público e a do setor privado podem
se complementar uma à outra. A plataforma generativa da internet (e da web) criou um espaço
em que inúmeras fortunas foram feitas durante os últimos trinta anos, mas ela própria foi
criada pela associação frouxa de cientistas da informática no mundo todo, financiados, em
grande parte, pelo governo federal dos Estados Unidos. Existem boas ideias, e há aquelas
boas ideias que tornam mais fácil ter outras boas ideias. O YouTube foi uma boa ideia que se
tornou possível graças às ideias ainda melhores da internet e da web. Não foi por acaso que
essas plataformas geradoras de ideias foram desenvolvidas fora do setor privado. Plataformas
proprietárias que alcançam massa crítica não são completamente sem precedentes – o
Microsoft Windows teve um grande sucesso, por exemplo, e a plataforma do iPhone da Apple
foi extraordinariamente inovadora em seus três primeiros anos –, mas são caso raros.
Plataformas generativas necessitam de todos os padrões de inovação que vimos nas páginas
anteriores; precisam criar um espaço em que intuições, colisões serendipitosas, exaptações e
reciclagem possam prosperar. É possível criar um espaço assim num jardim murado, mas será
muito melhor se situarmos nossa plataforma numa terra comunal.
TALVEZ “TERRA COMUNAL” NÃO SEJA A EXPRESSÃO CERTA para o ambiente que estamos tentando
imaginar, embora tenha uma longa e consagrada história na legislação sobre a propriedade
intelectual. Há um duplo problema com sua utilização. Em primeiro lugar, foi
convencionalmente usada em oposição à luta competitiva do mercado. As “terras comunais”
originais da Inglaterra rural desapareceram quando foram engolidas pelos cercamentos
privados do capitalismo agrário nos séculos XVII e XVIII. Apesar disso, os ambientes de
inovação que exploramos não são necessariamente hostis à competição e ao lucro. Mais
importante ainda, porém, é que a metáfora das terras comunais não sugere os padrões de
reciclagem, exaptação e recombinação que definem tantos espaços de inovação. Quando se
fala em terreno comunal, pensamos num campo limpo dominado por uma única vegetação para
servir de pasto. Não pensamos num ecossistema. A terra comunal é uma monocultura, não uma
ribanceira emaranhada.
Prefiro outra metáfora tomada da natureza: o recife. Basta observar um recife de coral (ou
uma floresta pluvial) por alguns minutos para ver que a competição por recursos abunda nesse
espaço, como Darwin bem notou. Mas não é essa a fonte de sua incrível biodiversidade. A
luta pela existência é universal na natureza. Os poucos habitantes de um ecossistema desértico
são, em tudo e por tudo, tão competitivos quanto seus equivalentes num recife de coral. O que
torna o recife tão inventivo não é a luta entre os organismos, mas o modo como eles
aprenderam a colaborar – o coral, a zooxantela e o peixe-papagaio tomando emprestado e
reinventando o trabalho uns dos outros. Esta é a explicação final do paradoxo de Darwin: o
recife abriu tantas portas para o possível adjacente por causa da maneira como compartilha.
O recife nos ajuda a compreender nossos outros enigmas iniciais: a inovação desenfreada
das cidades e da web. Também elas são ambientes que conectam e misturam de maneira
compulsiva aquele que é o mais valioso dos recursos: a informação. Como a web, a cidade é
uma plataforma que muitas vezes torna o comércio privado possível, mas ela própria está fora
do mercado. Fazemos negócios na grande cidade, mas ela pertence a todos. (“O ar da cidade
liberta”, como diz o velho adágio.) As ideias colidem, emergem, recombinam-se; novas
empresas encontram abrigo nas estruturas abandonadas por antigos hospedeiros; eixos
informais permitem que diferentes disciplinas façam empréstimos umas das outras. São esses
os espaços que há muito sustentam a inovação, desde aqueles primeiros povoamentos
mesopotâmicos, 8 mil anos atrás, até as camadas invisíveis de software que sustentam a web
nos nossos dias.
As ideias surgem em abundância, como disse Poincaré. Elas surgem em redes líquidas em
que a conexão é mais valorizada que a proteção. Assim, se quisermos construir ambientes que
gerem boas ideias – quer eles se situem em escolas, empresas, governos ou em nossas vidas
pessoais –, precisamos manter essa história em mente, e não recair nos pressupostos fáceis
segundo os quais mercados competitivos são a única fonte confiável de boas ideias. Sim, o
mercado foi um grande motor de inovação. Mas o mesmo pode ser do dito recife.
Sei que a maioria de nós não pode influenciar diretamente na determinação de quais
macroestruturas de informação e organização econômica prevalecem na sociedade mais
ampla, embora cada um influencie esse resultado de maneira indireta, mediante um ato básico
de escolher entre um emprego no setor privado ou no setor público. Mas essa é a beleza da
perspectiva do zoom longo: os padrões retornam em outras escalas. Talvez não sejamos
capazes de transformar nosso governo num recife de coral, mas podemos criar ambientes
semelhantes no âmbito da vida cotidiana: nos nossos locais de trabalho; no modo como
consumimos mídia; na maneira como aumentamos nossa memória. Os padrões são simples,
mas, se adotados conjuntamente, ajudam a criar um todo mais sábio que a soma de suas partes.
Faça uma caminhada; cultive intuições; anote tudo, mas mantenha suas pastas em desordem;
abrace a serendipidade; cometa erros produtivos; cultive diversos hobbies; frequente cafés e
outras redes líquidas; siga os links; permita que outros se baseiem em suas ideias; tome
emprestado, recicle, reinvente. Construa uma ribanceira emaranhada.
a A inovação, é claro, não é a única razão de uma parte tão grande do mundo ter desafiado as previsões do Manifesto

comunista e abraçado o modo de vida capitalista. Economistas e historiadores sociais documentaram múltiplos fatores que
dirigiram a marcha do mercado: as economias capitalistas apresentavam um histórico melhor de aumentos de longo prazo do
PIB, os atores econômicos tinham mais liberdade para fazer escolhas individuais. Embora o interesse econômico pessoal seja
uma força motivadora inegável para o ser humano, poucas defesas das virtudes econômicas do capitalismo deixaram de
mencionar sua força proteica. Até seus críticos reconheceram a tendência do mercado à novidade e à inovação, como na
famosa teoria da “destruição criativa” de Joseph Schumpeter.

b Esta estrutura foi adaptada do livro de Yochai Benkler The Wealth of Networks. Segundo Benkler, temos vasta experiência

com três das quatro combinações possíveis. As empresas privadas são centralizadas e baseadas no mercado. O próprio
mercado é descentralizado e, obviamente, baseado no mercado. As economias planejadas são centralizadas e não baseadas no
mercado. Mas o quadrado mágico é o quarto: o dos ambientes descentralizados, não baseados no mercado. Essa é uma
combinação que não se encaixa facilmente nos compartimentos usuais do capitalismo e do socialismo. No entanto, nos últimos
anos, esse quadrante tem sido uma estufa de inovação, graças em grande parte à arquitetura aberta da internet.

c Romances voltados para a descrição deslumbrada da vida das classes altas, em geral escritos pela classe média. (N.T.)

Apêndice:
Cronologia de inovações fundamentais, 1400-2000
Contabilidade de dupla entrada (1300-1400): Codificado pela primeira vez pelo frei franciscano e matemático Luca Pacioli
em 1494, o método da dupla entrada já vinha sendo usado por pelo menos dois séculos por banqueiros e negociantes italianos.
Há alguns indícios de que ele foi desenvolvido por empresários islâmicos, que o transmitiram aos italianos por meio dos centros
comerciais de Veneza e Gênova.

Prensa de tipos móveis (1440): Embora alguns elementos, incluindo o conceito de tipo móvel, remontem a inventores
chineses e coreanos mais antigos, o processo de impressão que combinava a prensa de parafuso e o tipo móvel foi criado por
Johannes Gutenberg por volta de 1440.

Lente côncava (1451): Há milhares de anos, o homem utiliza lentes para ampliar imagens e acender fogueiras, mas o primeiro
uso de uma lente côncava para tratar a miopia é atribuído ao cardeal Nicolau de Cusa, polímata alemão.

Paraquedas (1483): Leonardo da Vinci esboçou o projeto original de um paraquedas em 1483 na margem de um caderno. O
primeiro teste físico do invento ocorreu em 1783, quando Louis-Sébastien Lenormand saltou do Observatório de Montpelier na
França e, com a ajuda de seu paraquedas primitivo, pousou incólume. Em 2000, uma réplica exata do paraquedas de Da Vinci
foi construída, testada e provou funcionar.

Globo terrestre (1492): Martin Behaim, cartógrafo nascido em Nuremberg, construiu o primeiro globo terrestre no início da
década de 1490, após retornar de longas viagens pela África Ocidental. Chamou-o de Erdapfel, que se traduz por “maçã da
Terra”.

Rolimãs (1497): Os rolimãs foram concebidos e esboçados por Leonardo da Vinci em 1497 como método para reduzir a
fricção; a primeira patente para eles foi concedida a Philip Vaughan em 1794.

Relógios portáteis (1500): Um dos exemplos canônicos de invenção coletiva, os relógios portáteis foram desenvolvidos no
início do século XVI em Nuremberg por um grupo de relojoeiros liderado por certo Peter Henlein, que criou o primeiro relógio
leve. O relógio de Henlein era portátil, mas não muito preciso; aperfeiçoamentos posteriores por seus colegas de Nuremberg
conferiram maior pontualidade ao dispositivo.

Rotação da terra em torno do sol (1514): Nicolau Copérnico redigiu pela primeira vez sua teoria “heliocêntrica” do sistema
solar na forma de um pequeno panfleto por volta de 1514, mas não publicou formalmente a ideia por mais de vinte anos,
temendo a controvérsia que desencadearia. Nesse período, a notícia de sua teoria radical vazou e começou a se espalhar entre
as mentes esclarecidas da Europa, mas a primeira publicação oficial veio em seu texto póstumo, Sobre as revoluções das
esferas celestes, em 1543.

Símbolos de raiz quadrada, mais e menos (1525): O matemático alemão Christoph Rudolff inventou os símbolos
matemáticos modernos de “+”, “−” e “√” em Coss, de 1525, o primeiro manual completo de álgebra em alemão.

Equações cúbicas e números complexos (1530-1540): Os matemáticos do Renascimento islâmico publicaram vários
artigos importantes sobre a compreensão das equações cúbicas – juntamente com a noção de números complexos –, essenciais
para a determinação da área e do volume dos objetos. A técnica moderna para resolvê-las, porém, está associada de maneira
mais notável ao matemático e engenheiro italiano Niccolò Tartaglia, que venceu um famoso concurso em 1530, chamando
atenção para sua abordagem. Dois outros italianos da época, Scipione del Ferro e seu discípulo Antonio Fiore, também
contribuíram para a resolução das equações de terceiro grau.

Respiração pulmonar (1535): Após estudar o tamanho da artéria pulmonar como aluno de medicina na Universidade de
Paris, o radical religioso espanhol Miguel Servet fez a primeira defesa convincente da ideia de que a aeração do sangue ocorria
nos pulmões.

Éter (1540): O botânico alemão Valerius Cordus descobriu e descreveu um método radicalmente novo para a síntese do éter

em 1540, chamando-o de “o doce óleo de vitríolo”. Por volta da mesma época, o médico suíço Paracelso descobriu as
propriedades anestesiantes da substância.

Turbina a vapor (1551): O brilhante polímata turco Taqi al-Din descreveu uma turbina a vapor que funcionava, projetada para
acionar um espeto giratório, em sua obra de 1551 com o maravilhoso título Os métodos sublimes das máquinas espirituais.

Lápis (1560): Em meados da década de 1560, os habitantes de uma pequena aldeia na região de Cúmbria, na Inglaterra,
encontraram um enorme depósito de grafite. Primeiro usaram a substância para marcar seu gado e suas ovelhas e por fim
ocorreu-lhes a ideia de inserir o grafite num invólucro de madeira. O lápis levaria mais duzentos para se completar com a
invenção da borracha.

Projeção de Mercator (1569): O cartógrafo flamengo Gerard Mercator desenvolveu a projeção que leva seu nome, uma
representação cartográfica do mundo que permitia aos navegadores seguir loxodromias, ou linhas de rumo, entre dois locais,
sendo assim responsável pelo rumo.

Supernovas e cometas (1572-1577): A observação da formação de uma nova estrela pelo nobre dinamarquês Tycho Brahe
em 1572, e a prova detalhada que forneceu de que a supernova não estava mudando de posição com relação a outras estrelas,
solapou a ortodoxia reinante, segundo a qual o céu era imutável. Alguns anos mais tarde, observações igualmente precisas de
um cometa por Brahe mostraram que o objeto estava muito além da lua, não sendo portanto parte da atmosfera da Terra.

Máquina de tricô (1589): O clérigo inglês William Lee criou a primeira versão operante de uma máquina mecânica de tecer
que permitiu à indústria têxtil imitar os movimentos do tricô manual. Após a morte do inventor, um de seus assistentes introduziu
uma série de aperfeiçoamentos que aumentaram muito a funcionalidade da engenhoca.

Microscópio composto (1590): Embora não haja pleno consenso acerca do inventor do microscópio composto, a maioria dos
historiadores atribui sua autoria ao fabricante de óculos holandês Zacharias Janssen e seu filho Hans, ou ao óptico alemão Hans
Lippershey. Em 1609 Galileu reformou o projeto original de Janssen, conferindo maior eficiência ao aparelho. Nos anos 1670,
Antoni van Leeuwenhoek aplicou pela primeira vez o microscópio ao campo da biologia.

Descarga de vaso sanitário (1596): Um dispositivo de descarga foi inventado no final do século XVI por sir John Harrington,
que instalou uma versão para sua madrinha, a rainha Elizabeth, no Richmond Palace. Mas o invento só decolou no final do
século XVIII, quando o relojoeiro Alexander Cumings e o marceneiro Joseph Bramah reivindicaram duas patentes separadas
de uma versão aperfeiçoada do projeto de Harrington.

Magnetismo planetário (1600): O cientista inglês William Gilbert percebeu que a própria Terra era um magneto, descoberta
publicada pela primeira vez em seu tratado “Sobre os ímãs” em 1600. Gilbert concluiu que era a natureza magnética da Terra
que permitia à bússola ajudar os navegadores. Ao longo da história, a natureza dos ímãs havia sido estudada, entre outros, por
Aristóteles e pelos chineses antigos.

Telescópio (1600-1610): Exemplo clássico de invenção coletiva, os primeiros telescópios e lunetas começaram a aparecer na
Europa na primeira década do século XVII. Em 1608, foram solicitadas duas patentes para projetos desenvolvidos na Holanda;
e em 1609 Galileu estava usando um dispositivo construído por ele, com capacidade de ampliação de vinte vezes, para observar
as estrelas, o que lhe permitiu descobrir as luas de Júpiter.

Órbitas elípticas (1605-1609): O astrônomo e matemático alemão Johannes Kepler foi o primeiro a documentar a órbita
elíptica traçada pelos planetas em torno do Sol, embora tenha construído suas equações analisando dados colhidos por Tycho
Brahe, seu amigo e empregador ocasional.

Luas de Júpiter (1610): Com a ajuda de um telescópio, Galileu Galilei observou pela primeira vez os satélites que orbitam em
torno de Júpiter, provando assim o princípio fundamental do sistema coperniciano de que o universo não girava em torno da
Terra. Outro cientista, Simon Marius, afirmou ter descoberto as luas cinco semanas antes de Galileu, mas nunca publicou essas
observações.

Fecho de pederneira (1610): O cortesão francês Marin le Bourgeoys apresentou o primeiro mecanismo de fecho de
pederneira plenamente desenvolvido ao rei Luís XIII em 1610, e o dispositivo passou a ser usual em armas de fogo até o início
do século XIX. Mas a descoberta de Marin le Bourgeoys incluiu muitas inovações nos mecanismos de disparo, da trava de
mosquete ao snaphance.

Manchas solares (1610): As manchas solares, pontos magnéticos escuros na superfície do Sol, foram observadas pela
primeira vez de maneira quase simultânea por vários astrônomos com o uso de telescópios. Sua descoberta é atribuída
alternadamente a Galileu Galilei, Thomas Harriot e Johannes e David Fabricius.

Logaritmos (1614): Num esforço para simplificar o processo de multiplicação de números grandes, o matemático John Napier
concebeu os logaritmos de maneira a expressar um número como uma base elevada a uma potência, por exemplo, 100 como
10², ou 10 × 10. Mais tarde os logaritmos desempenharam um papel essencial na ciência e na engenharia.

Circulação sanguínea (1628): O médico inglês William Harvey teorizou corretamente sobre o modo como o sangue se movia
através do corpo humano, bombeado pelo coração e percorrendo um ciclo perpetuamente, refutando assim argumentações
anteriores em defesa da existência de dois sistemas de circulação separados.

Escala de Vernier (1631): A escala de Vernier, inventada pelo matemático francês Pierre Vernier, pode ser usada em conjunto
com uma escala maior para medir com precisão unidades de espaço extremamente pequenas. Teve vasto emprego em sistemas
de navegação.

Marés oceânicas (1632): Seguindo os passos dos antigos, Galileu Galilei ousou propor uma relação entre as marés oceânicas
e o Sol. Johannes Kepler teorizou corretamente que o fenômeno era criado pela relação da Terra com a Lua, e Isaac Newton
forneceu uma explicação completa à comunidade científica em 1687.

Régua de cálculo (1632): Atribui-se em geral a William Oughtred a invenção da primeira versão da régua de cálculo – duas
escalas logarítmicas paralelas, uma podendo deslizar em relação à outra – para conduzir cálculos avançados de maneira fácil e
rápida. Oughtred aperfeiçoou o projeto de um modelo mais básico desenvolvido por Edmund Gunter, bem como concepções
anteriores de Galileu Galilei e John Napier.

Lei da queda dos corpos (1634): Durante pelo menos duzentos anos, o consenso aristotélico sustentou que corpos mais
pesados caem mais depressa que os mais leves, até que Galileu planejou vários experimentos engenhosos e formulou uma
equação matemática para descrever o que hoje chamamos de aceleração uniforme. Embora vários relatos de observações
sejam anteriores ao trabalho de Galileu, foi ele que apresentou a prova definitiva.

Geometria analítica (1637): O filósofo e matemático francês René Descartes inventou o sistema hoje conhecido como
geometria analítica como uma maneira de exprimir formas geométricas e propriedades com um sistema de coordenadas.
Traduzindo estruturas geométricas, tanto bidimensionais quanto tridimensionais, em representações numéricas, os matemáticos
podiam estudá-las e investigá-las algebricamente. Mais tarde a geometria analítica seria uma das bases do cálculo desenvolvido
por Isaac Newton.

Barômetro (1643): O barômetro, instrumento destinado a medir a pressão do ar, nasceu dos esforços do físico italiano
Evangelista Torricelli para secundar seu mentor, Galileu, numa tentativa de ajudar mineiros a bombear água de poços. Ao
trabalhar com mercúrio, líquido mais pesado que a água, Torricelli descobriu que variações de um dia para o outro na altura do
mercúrio preso num tubo deviam-se a mudanças na atmosfera do ar. Alguns historiadores, contudo, creem que o matemático
Gasparo Berti pode ter inventado o barômetro inadvertidamente alguns anos antes.

Calculadora mecânica (1645): Devemos ao matemático e filósofo francês Blaise Pascal o invento hoje conhecido como
calculadora de Pascal, um dos mais importantes precursores da calculadora moderna. O instrumento podia somar e subtrair
mediante o uso de rodas de metal giratórias em que estavam gravados os números de 0 a 9. Embora Pascal tenha sido o
primeiro a apresentar sua invenção ao público, em pleno funcionamento, um dispositivo semelhante havia sido concebido e
desenvolvido pelo alemão Wilhelm Schickard, com base num trabalho de John Napier.

Bomba de vácuo (1654): Como o barômetro, a bomba de vácuo resultou dos esforços de cientistas para aperfeiçoar uma
bomba de sucção. Por meio de uma série de experimentos, Otto von Guericke descobriu que era possível extrair ar ou água de
um recipiente lacrado criando vácuo. Ele demonstrou esse princípio perante o imperador Fernando III, demonstrando que dois
cavalos não conseguiam separar duas abóbadas metálicas ocas entre as quais fora criado um vácuo. Von Guericke baseouse no
trabalho de Evangelista Torricelli, e seu próprio trabalho foi aperfeiçoado por Robert Boyle e Robert Hooke.

Relógio de pêndulo (1656): Mais uma vez tomando por base as ideias de Galileu, o cientista holandês Christiaan Huygens
inventou o relógio mais preciso até então, utilizando a oscilação regular de um pêndulo pesado, ligeiramente regulado por um
dispositivo mecânico.

Relógios com mola de balanço (1660): Representando uma enorme melhoria na precisão dos relógios anteriores, um
mecanismo de mola de balanço controlava a velocidade das diferentes peças de um relógio com a ajuda de um regulador,
assegurando que todo o mecanismo permanecesse tão regular quanto possível. A invenção é atribuída tanto a Robert Hooke
quanto a Christiaan Huygens – Thomas Tompion construiu o regulador do tempo mais eficiente por volta de 1680.

Lei de Boyle (1662): A lei de Boyle, desenvolvida pelo cientista Robert Boyle, determina que, dada uma temperatura fixa e
um sistema fechado, a pressão e o volume de um gás permanecerão inversamente proporcionais; isto é, quando um diminui, o
outro aumenta na mesma proporção. O assistente de Boyle, Robert Hooke, o auxiliou na descoberta dessa lei. O químico
francês Edme Mariotte descobriu o mesmo princípio mais ou menos na mesma época, mas Boyle o publicou primeiro.

Espectro solar (1665): Corrigindo noções anteriores de que os prismas coloriam a luz, sir Isaac Newton demonstrou por meio
de uma série de experimentos que um raio de sol irradiado através de um prisma não era colorido por ele; o raio continha cores
e apenas era dividido em suas partes constituintes. Ao isolar uma cor expressa por um prisma e irradiá-la através de outro,
Newton mostrou que a cor permanecia constante, e o prisma não afetava o tom.

Micro-organismos (1674-1680): Graças em parte aos aperfeiçoamentos feitos por ele próprio na tecnologia do microscópio,
o cientista holandês Antoni Philips van Leeuwenhoek foi a primeira pessoa a observar diretamente organismos unicelulares,
chamados na época de “animálculos”.

Velocidade da luz (primeira medida quantitativa) (1676): Embora Galileu tivesse demonstrado que a luz viaja mais
rapidamente que o som, o astrônomo dinamarquês Olaus Roemer, ao tentar explicar disparidades em suas observações de
eclipses, percebeu que elas se deviam ao tempo que a luz levava para viajar pelo espaço. Por meio de cálculos astronômicos
avançados, Roemer foi capaz de chegar a uma estimativa da velocidade da luz não muito distante da atual.

Lei de Hooke (1676): Também conhecida com lei da elasticidade. O cientista inglês Robert Hooke descobriu que o
deslocamento ou a deformação de um objeto era proporcional à quantidade de força exercida sobre ele – em outras palavras,
uma mola se estica numa medida proporcional ao grau de pressão exercido sobre ela, antes de retornar à sua forma original.

Panela de pressão (1679): O físico francês Denis Papin inventou o que chamou de digestor a vapor – um cilindro
hermeticamente fechado contendo líquido, que, quando aquecido, criava pressão dentro da unidade fechada. Com isso, o ponto
de ebulição do líquido era elevado, permitindo tempos de cozimento mais rápidos.

Cálculo (1684, 1693): Embora os princípios do cálculo moderno tivessem sido notados ao longo dos séculos, a maioria dos
historiadores atribui a Isaac Newton e Gottfried Wilhelm Leibniz a sistematização dos métodos e princípios numa escala mais
ampla, até então nunca alcançada. Descrito de maneira geral como um ramo da matemática que explica os princípios da física,
o cálculo teve sua invenção disputada entre Newton e Leibniz, mas a história mostrou depois que os dois matemáticos
chegaram, de maneira independente, às mesmas conclusões, ainda que adotando sistemas de notação diferentes.

Lei da gravitação universal (1686): Embora a história da maçã que caiu na cabeça de Newton talvez seja o exemplo
canônico da inspiração individual, as verdadeiras origens da lei são muito mais obscuras, e incluem uma disputa entre Robert
Hooke e Newton sobre quem teria sido o primeiro a observar a relação do inverso do quadrado que governava a atração
gravitacional entre dois objetos.

Três leis do movimento e órbitas dos cometas (1687, 1705): As três leis do movimento, de Newton, foram publicadas
pela primeira vez em seu revolucionário Philosophiae Naturalis Principia Mathematica em julho de 1687. Edmund Halley,
amigo e editor de Newton, se basearia depois nessas leis para produzir a primeira previsão precisa da órbita de um cometa em
torno da Terra.

Piano (década de 1700): Contratado pela corte dos Médici, Bartolomeo Cristofori procurou aperfeiçoar o cravo e o
clavicórdio, criando um instrumento semelhante que permitisse tanto controle expressivo quanto um espectro maior de volume.
Chamou-o de “pianoforte”, palavra depois encurtada para “piano”.

Diapasão (1711): Projetado pelo músico britânico John Shore, o diapasão produzia um tom muito puro, pelo qual instrumentos
podiam ser afinados com precisão.

Máquina a vapor (1712): Desenvolvendo as invenções anteriores e mais primitivas de Denis Papin e Thomas Savery, o
ferreiro inglês Thomas Newcomen utilizou a pressão atmosférica para propelir um pistom para cima e para baixo mediante a
condensação do vapor, permitindo a uma máquina bombear água de poços. Foi o primeiro dispositivo desse tipo comercialmente

bem-sucedido.

Termômetro de mercúrio (1714): Embora Galileu Galilei e Isaac Newton tenham ambos concebido termômetros
rudimentares, o físico alemão Daniel Gabriel Fahrenheit inventou o primeiro termômetro de mercúrio plenamente eficiente: um
tubo de vidro contendo mercúrio que registrava a temperatura conforme o grau de calor aplicado a ele, demarcando as
temperaturas tanto de fervura quanto de congelamento da água.

Octante (1730): Inventado mais ou menos ao mesmo tempo, mas de maneira independente, por Thomas Godfrey e John
Hadley, o octante era um instrumento náutico que abarcava 45 graus e, com a ajuda de espelhos e de um pequeno telescópio
presos a ele, permitia a marinheiros orientar-se no mar.

Lançadeira volante (1733): Invenção que ajudou a estimular Revolução Industrial, a lançadeira volante era um dispositivo que
acelerava o processo de tecelagem com tear e exigia menos mão de obra. Só se tornou amplamente utilizada após a morte de
seu inventor, John Kay.

Taxonomia lineana (1735): Embora o esquema taxonômico moderno para a organização da vida ainda tenha o nome do
botânico e zoólogo sueco Carlos Lineu, o modelo que ele propôs se baseava em sistemas de classificação que vinham se
desenvolvendo havia centenas de anos. Mas Lineu fez de fato várias adições essenciais, a mais importante das quais é o uso de
uma estrutura binomial para dar nome a cada organismo, como em Homo sapiens.

Cronômetro (1735): Inúmeras versões do cronômetro foram desenvolvidas desde o início do século XVI, mas o instrumento
mais completo foi criado pelo carpinteiro Thomas Harrison. Ao fornecer uma representação precisa do tempo num local
específico, o cronômetro permitia aos navegadores determinar a longitude e a latitude no mar.

Para-raios (1750): Benjamin Franklin propôs a ideia de um para-raios pela primeira vez numa carta escrita em 1750. Suas
descrições foram por fim traduzidas para o francês, e o projeto foi de fato submetido a um primeiro teste na França em 1752.

Spinning jenny (1764): Um velho debate questiona se James Hargreaves foi o verdadeiro inventor da spinning jenny,
máquina de fiar de múltiplos fusos que aumentou enormemente a eficiência da indústria do algodão. Há indícios de que
Hargreaves estava apenas aperfeiçoando o projeto de um artesão chamado Thomas Highs. O que está claro, no entanto, é que,
após a produção do primeiro modelo de Hargreaves, seu projeto foi muito aprimorado no curso dos anos por tecelões
espalhados por todo o norte da Inglaterra.

Água gaseificada (1767): O clérigo Joseph Priestley descobriu que, impregnando a água artificialmente com dióxido de
carbono, podia criar uma bebida efervescente, conhecida hoje como água gaseificada. Embora Priestley nunca tenha tirado
proveito das oportunidades comerciais proporcionadas por seu invento, muitos de seus sucessores tiraram.

Fotossíntese (1770-1800): Mais comumente associado ao físico austríaco Jan Ingenhousz, o mecanismo da fotossíntese foi
descoberto de maneira paulatina ao longo de um período de trinta anos, a partir de 1770, com uma série de experimentos e
ensaios de Joseph Priestley. O ciclo de consumo de dióxido de carbono e liberação de oxigênio desencadeado pela luz solar só
foi plenamente formulado em meados dos anos 1790 pelo naturalista suíço Jean Senebier.

Respiração vegetal (1772-1773): Embora Joseph Priestley seja convencionalmente associado ao isolamento do oxigênio,
merece reconhecimento pela descoberta da respiração das plantas, por volta de 1773, para a qual colaborou mediante
correspondência com o bom amigo Benjamin Franklin.

Oxigênio (1772-1776): Numa grande história de colaboração científica e rivalidade, o oxigênio foi isolado por três cientistas
em meados dos anos 1770: o químico sueco Carl Wilhelm Scheele; o polímata britânico Joseph Priestley, que o chamou de “ar
desflogisticado”, segundo a inexata teoria reinante do flogístico; e Antoine Lavoisier, que deu nome ao elemento.

Lentes bifocais (circa 1780): Embora não se conheça a data exata de sua invenção, em meados dos anos 1780, Benjamin
Franklin comentava em cartas para amigos a satisfação que lhe dava sua “invenção de óculos duplos, que, servindo para objetos
tanto distantes quanto próximos, tornam meus olhos tão úteis para mim quanto foram um dia”.

Barco a vapor (1780-1810): Convencionalmente apontado como o inventor do barco a vapor, Robert Fulton, na verdade, foi
apenas o primeiro a transformá-lo num sucesso comercial. Vários barcos a vapor operantes haviam sido construídos por
engenheiros como John Fitch e James Rumsey durante as duas décadas precedentes.

Balão de ar quente tripulado (1783): Os balões de ar quente remontam à cultura chinesa do século I d.C., mas o primeiro
voo tripulado foi planejado pelos empresários franceses Joseph-Michel e Jacques-Etienne Montgolfier.

Via láctea (1785): Muitos astrônomos e cientistas, entre os quais Abū Rayhān al- Bīrūnī e Galileu, contribuíram para a noção
da Via Láctea como um conjunto de estrelas, mas a primeira tentativa de mapear a forma da galáxia foi feita por William
Herschel e sua irmã Caroline em 1785.

Tear a vapor e descaroçador de algodão (1785, 1793): O clérigo inglês Edmund Cartwright patenteou um projeto de tear
movido a vapor em 1785, mas, como o descaroçador de algodão de Eli Whitney, a máquina dependeu de muitos
aperfeiçoamentos posteriores, feitos por outros engenheiros, para revolucionar a indústria têxtil.

Vacina contra a varíola (1796): O processo de inocular pequenas doses de vírus da varíola em seres humanos, em geral
usando crostas da pele da vítima, foi amplamente praticado na China, na Pérsia e na África após 1500. Mas o cientista britânico
Edward Jenner foi o primeiro a conceber uma vacina baseada num vírus semelhante, de varíola bovina, que produzia imunidade
à varíola com mortalidade muito menor.

Litografia (1796): Empenhado em encontrar uma maneira barata de distribuir seus escritos, o dramaturgo Alois Senefelder
descobriu que podia gravar numa placa de cobre usando ácido e agulha. Aperfeiçoou esse método usando a mesma ideia
fundamental e chamou-o de “impressão na pedra”. Logo o viu espalhar-se pela Europa e pelos Estados Unidos.

Bateria elétrica (1800): O físico italiano conde Alessandro Volta criou a primeira bateria com discos de zinco e cobre,
inspirado numa discussão com o médico e investigador Luigi Galvani, que acreditava que o tecido animal produzia eletricidade.

Teoria atômica (1800-1810): Embora profundamente inspirada na revolução na química encabeçada por Antoine Lavoisier, a
primeira demonstração rigorosa de que os elementos eram compostos por átomos únicos de caráter distinto foi proposta pelo
químico inglês John Dalton, na primeira década do século XIX.

Moléculas (1800-1810): A noção de que os átomos formam unidades compostas maiores, a mais elementar das quais é uma
molécula, foi formulada nas décadas em torno de 1800 e se valeu das teorias relacionadas do químico francês Joseph Proust, de
John Dalton e do conde italiano Avogadro.

Ponte suspensa (1800-1830): Embora muitos aperfeiçoamentos decisivos lhe tenham sido acrescentados durante a primeira
metade do século XIX, a primeira ponte suspensa com tamanho suficiente para dar passagem a pessoas e cavalos foi a Jacob’s
Creek Bridge, construída no início do século XIX por James Finley, juiz e engenheiro amador americano.

Locomotiva a vapor (1805): Nas últimas décadas do século XVIII, muitos engenheiros construíram veículos movidos a vapor,
alguns destinados a rodar em estradas, outros sobre trilhos. Mas os historiadores consideram em geral que o trem projetado por
Richard Trevithick em 1805, no País de Gales, foi a primeira locomotiva a vapor a funcionar perfeitamente.

Cartões perfurados (1805): Costuma-se creditar a ideia de usar cartões perfurados para programar teares mecânicos a
Joseph Marie Jacquard, mas já no início do século XVIII vários tecelões, entre os quais Basile Bouchon e Jean Falcon, haviam
feito amplas experiências de controle de fios de urdidura por meio de cartões perfurados.

Espectroscópio (1814): O óptico alemão Joseph von Fraunhofer inventou o espectroscópio, instrumento que mede as
propriedades da luz, para estudar as linhas escuras que ocorrem em várias formas de espectros. Mais tarde veio a descobrir
que essas linhas são áreas do espectro em que a luz é absorvida.

Estetoscópio (1816): Um físico francês chamado René Laennec inventou o estetoscópio após improvisar um, com um rolo de
papel, ao tratar de uma mulher que sofria de problemas cardíacos.

Bicicleta (1817-1863): O primeiro veículo governável de duas rodas foi projetado por um barão alemão chamado Karl von
Drais em 1817 e imitado por dúzias de empresários em toda a Europa na década seguinte. Pedais e correntes de transmissão,
entretanto, só foram acrescentados nos anos 1860.

Braille (1821): Louis Braille, um cego francês de quinze anos, criou o braille – uma forma tátil de leitura – aperfeiçoando um
sistema mais rudimentar de texto tátil feito de pontos salientes (escrita noturna) concebido pelo capitão do Exército Charles
Barbier.

Motor elétrico (1821-1850): Mais de uma dúzia de cientistas e empresários contribuíram para o projeto do motor elétrico na
primeira metade do século XIX, a começar pelo químico e físico inglês Michael Faraday, que demonstrou em 1821 um sistema
para converter energia elétrica em energia mecânica.

Segunda lei da termodinâmica (1824): A segunda lei da termodinâmica, que se desenvolveu ao longo dos anos nas mãos de
vários cientistas, entre os quais Sadi Carnot e Rudolf Clausius, exprime a teoria da entropia universal, que invalida a
possibilidade de máquinas de movimento perpétuo.

Uniformitarianismo geológico (1830): A ideia de que o estado geológico da Terra baseava-se em forças constantes que
atuam em escalas de tempo muito longas é em geral atribuída à obra Princípios de geologia, de Charles Lyell, publicada em
1830, embora o próprio termo venha de uma crítica a esse livro escrita por William Whewell. As ideias de Lyell formariam
posteriormente a plataforma na qual Darwin baseou sua teoria biológica da evolução.

Clorofórmio (1831): O clorofórmio, um composto orgânico incolor, foi descoberto mais ou menos ao mesmo tempo por três
diferentes cientistas em três países: Eugene Soubeiran (França), Samuel Guthrie (Estados Unidos) e Justus von Liebig
(Alemanha). Era usado no tratamento da asma e como uma poderosa alternativa ao éter como anestésico.

Geladeira (1834): Após adquirir a patente de um sistema de refrigeração por compressão de vapor, o engenheiro mecânico
Jacob Perkins construiu a primeira geladeira em 1834, embora uma máquina de refrigeração anterior tivesse sido concebida
pelo inventor americano Oliver Evans em 1805.

Revólver (1836): Aperfeiçoando o fecho de pederneira usado como mecanismo de disparo, em 1836 o inventor americano
Samuel Colt projetou e patenteou o revólver, uma arma de mão dotada de um tambor giratório com várias câmaras para balas.

Computador programável (1837): Embora nunca o tenha construído, Charles Babbage esboçou os princípios básicos do
computador programável – incluindo as noções do que hoje chamamos de software, CPU e memória – em sua lendária
“máquina analítica”, cuja descrição publicou pela primeira vez em 1837. Ada Lovelace, filha de Lord Byron, escreveu o
primeiro algoritmo de computador para a máquina.

Telégrafo (1838): Num esforço para melhorar modelos desajeitados de telégrafo que utilizavam cinco fios, o inventor Samuel
Morse e seu assistente Alfred Vail criaram um modelo de um só fio, que usava sinais elétricos para deslocar um eletromagneto
num padrão de pontos e traços impresso sobre papel, conhecido como código Morse.

Fotografia (1839): A maioria dos historiadores atribui ao químico francês Louis Daguerre o desenvolvimento do primeiro
processo fotográfico prático, que envolvia a fixação de imagens mediante a exposição à luz de placas de cobre revestidas com
uma substância química. Os métodos de Daguerre foram profundamente influenciados pelas inovações de outro francês, Joseph
Nicephore Niépce.

Borracha vulcanizada (1839): Após anos de tentativa e erro, Charles Goodyear descobriu a borracha vulcanizada – que,
diferentemente da borracha natural, mantém sua forma mesmo quando exposta a pressão e calor – quase por acidente, e
passou o resto da vida lutando para receber royalties sobre o produto. Não muito depois da descoberta de Goodyear, Thomas
Hancock levou a melhor sobre ele e obteve a patente.

Máquina de costura (1845): A invenção da moderna e prática máquina de costura deveu-se em grande parte às inovações
individuais de dois americanos, o mecânico Elias Howe, que desenvolveu o mecanismo de pesponto duplo da máquina, e o
inventor Isaac Singer, que introduziu o movimento vertical da agulha. Os dois homens entrariam em conflito pelo mérito da
invenção.

Nitroglicerina (1846): Trabalhando como assistente do professor J.T. Pelouze, Ascanio Sobrero foi o primeiro a descobrir e
sintetizar a nitroglicerina. Ciente de seu potencial explosivo, Sobrero desaconselhou o uso imprudente da substância química e
por vezes chegou lamentar tê-la descoberto.

Zero absoluto (1848): Com base no trabalho de cientistas anteriores sobre a temperatura, Kelvin desenvolveu o zero absoluto,
que constitui o ponto mais baixo da escala Kelvin, representando a temperatura em que toda matéria cessa de se mover –
aproximadamente −273,15°C.

Ferro-gusa/fabricação do aço (1850-1860): Foi o inventor americano Henry Bessemer quem descobriu o primeiro método
para a produção em massa de aço, embora o processo ainda tenha sido aperfeiçoado por muitos anos. Mediante a oxidação do

ferro-gusa, Bessemer foi capaz de fabricar aço de qualidade relativamente alta em grandes quantidades, com o que acabou
auxiliando a construção de arranha-céus.

Elevador (1853): Apesar de já existirem versões rudimentares de “ascensores” desde a Idade Média, o inventor americano
Elisha Otis estimulou o amplo uso público dessas máquinas em 1853 ao desenvolver um freio de segurança, após a introdução
de elevadores a vapor e hidráulicos por volta de 1850.

Aspirina (1897): As propriedades analgésicas da casca do salgueiro, cuja qualidade medicinal resultava da salicina nela
presente, foram compreendidas e prescritas desde os tempos de Hipócrates, mas o uso da droga era prejudicado por seus
efeitos colaterais, sobretudo dores abdominais. O químico francês Charles Gerhardt descobriu que a adição de sódio e cloreto
de acetila aliviava a irritação intestinal, contribuindo para um medicamento melhor.

Bico de Bunsen (1856): O químico alemão Robert Bunsen desenvolveu seu bico de gás para realizar experimentos sobre
emissões espectrais de elementos, pois ainda não existia tecnologia disponível para isso. Frustrado com os fracos bicos da
época, Bunsen produziu um com uma chama incrivelmente quente e quase invisível, o bico de laboratório comum que muitos
usam até hoje.

Pote com tampa de rosca revestida de borracha (1858): Aperfeiçoando os potes ineficientes usados na época, o funileiro
John L. Mason inventou um tipo de pote que um dia receberia seu nome, o Mason jar. Caracterizados por uma tampa de rosca
revestida de borracha que lhes conferia uma vedação hermética, esses potes tornaram-se essenciais para a conservação de
produtos perecíveis.

Bateria de chumbo-ácido (1859): O físico francês Gaston Planté inventou a primeira bateria recarregável ao fazer
experiências com o poder condutor de chapas laminadas de chumbo e ácido sulfúrico.

Seleção natural (1859): A seleção natural foi formulada pela primeira vez por Charles Darwin no final dos anos 1830. Ele só
publicou suas ideias, porém, em 1859, no livro A origem das espécies, após ser estimulado por teorias muito semelhantes
desenvolvidas de maneira independente pelo naturalista britânico Alfred Russel Wallace.

Metralhadora Gatling (1861): Movido pela crença de que uma metralhadora giratória provocaria menos derramamento de
sangue nos campos de batalha, pela redução do número de soldados necessários, o inventor Richard Gatling criou a
metralhadora Gatling, uma arma movida a manivela, montada sobre duas rodas, que disparava de maneira contínua e rápida.

Aspirador de pó (1861): Embora muitos inventores tenham criado versões do que hoje conhecemos como aspirador de pó no
fim do século XIX e início do século XX, foi Ives W. McGaffey quem patenteou o primeiro deles em 1861. Também conhecido
como “máquina de varrer”, funcionava manualmente e destacava-se por sua capacidade de limpar tapetes.

Plástico (1862): O metalúrgico britânico Alexander Parkes desenvolveu o primeiro plástico comercial de vulto feito pelo
homem – um material sintético de celulose e tratado com ácido nítrico – e o lançou na Feira Mundial de Londres em 1862. O
material foi aperfeiçoado ao longo dos séculos XIX e XX.

Teoria dos germes (1862): A ideia de que os germes transmitiam doenças contagiosas não era nova e já havia sido proposta
antes. Apesar disso, o químico francês Louis Pasteur foi um dos primeiros a desenvolver experimentos para provar a teoria dos
germes de maneira conclusiva.

Dinamite (1863): Em busca de desenvolver métodos mais eficientes para explodir rochas, o industrial sueco Alfred Nobel
inventou, com base em experimentos com nitroglicerina, um detonador que usava um choque forte para provocar explosões e
patenteou-o em 1863.

Tabela periódica (1864): Em 1864, o químico russo Dmitri Mendeleev desenvolveu uma ideia anterior do químico britânico
John Newlands de que os elementos químicos podiam ser organizados num padrão segundo suas massas atômicas. Construiu
assim uma tabela mais completa, que os agrupava em função de suas propriedades físicas e químicas.

Descoberta da estrutura do benzeno (1865): Após a descoberta do benzeno em 1825, os químicos alemães Joseph
Loschmidt e August Kekulé von Stradonitz teorizaram a estrutura molecular desse hidrocarboneto – um anel de seis átomos de
carbono com ligações simples e duplas alternadas. A descoberta de Kekulé foi inspirada por seu lendário sonho com a serpente
que engolia a própria cauda.

Hereditariedade (1865): A ideia de que os pais transmitem certas qualidades à prole foi proposta por Gregor Mendel, um
monge agostiniano e cientista, com base em seu trabalho com plantas. No início do século XX seus princípios foram sintetizados
numa teoria mais ampla da genética por Thomas Hunt Morgan.

Máquina de escrever (1868): Após a invenção de uma máquina tipográfica ineficiente em 1829, o inventor americano
Christopher Latham Sholes, com a ajuda de seus colegas, patenteou a primeira máquina de escrever em 1868, propondo o
sistema de barras de tipo e o arranjo qwerty das teclas, para evitar emperramentos.

Telefone (1876): A patente para a invenção do telefone foi intensamente disputada, levando a uma corrida de última hora até o
escritório de patentes entre o engenheiro Alexander Graham Bell e o engenheiro elétrico Elisha Gray. Bell por fim obteve a
patente do aparelho que transmitia sinais de voz eletricamente.

Enzimas (1878): Batizadas pelo médico alemão Wilhelm Kühne em 1878, as enzimas – proteínas que atuam como
catalisadores de reações químicas, acelerando o processo – foram compreendidas de maneira mais completa graças aos
estudos do químico alemão Eduard Buchner e do químico francês Louis Pasteur.

Lâmpada elétrica (1879): Considera-se muitas vezes que, ao usar a eletricidade para aquecer um filamento, fazendo-o brilhar
e criar luz, Thomas Alva Edison inventou a lâmpada elétrica, que substituiu a lâmpada a gás como principal fonte de iluminação.
Mas o trabalho de Edison baseou-se nos projetos de pelo menos meia dúzia de outros inventores precedentes, entre os quais
Joseph Swan e William Sawyer.

Divisão celular (1879): A descoberta da divisão celular, processo entre os eucariotos em que uma célula-mãe se divide em
células-filhas, conhecido como mitose, foi um feito conjunto do biólogo alemão Walther Flemming, do botânico polonês-alemão
Eduard Strasburger e do zoólogo e embriologista belga Edouard van Beneden.

Sismógrafo (1880): Contratados pelo governo japonês para estudar tremores e terremotos, três cientistas britânicos
trabalharam na criação de um aparelho que pudesse medir e classificar a intensidade dos terremotos. Dos três, é a John Milne
que em geral é atribuído o maior mérito pela invenção do aparelho, que se caracteriza pelo uso de um pêndulo e hoje é
conhecido como sismógrafo horizontal.

Incubadora para bebês (1881): Inspirado pelo uso de uma chocadeira para pintos, o obstetra francês Étienne Stéphane
Tarnier introduziu o uso regular de incubadoras para bebês – berços aquecidos para recém-nascidos – em hospitais. Os projetos
iniciais para essas incubadoras foram concebidos pelo cirurgião francês Jean-Louis-Paul Denucé e pelo ginecologista alemão
Carl Credé.

Máquina de solda (1885): Os inventores russos Nikolai Bernardos e Stanislav Olszewski criaram a primeira máquina de solda
por arco elétrico em 1885, embora o princípio subjacente à soldagem – de que se pode usar a aplicação de calor para unir peças
metálicas – fosse conhecido e utilizado havia séculos.

Motocicleta (1885): O inventor alemão Gottlieb Daimler deu um novo uso ao motor de combustão interna de Nikolaus Otto
conectando-o a uma bicicleta, que passou a ser movida a gasolina, e não a força humana. Um veículo com motor a vapor e
parecido com uma motocicleta moderna foi inventado 1867.

Automóvel (1885): Por volta do mesmo ano, 1885, o engenheiro alemão Gottlieb Daimler e o engenheiro e empresário
também alemão Wilhelm Maybach criaram um automóvel de quatro rodas com motor de quatro tempos, e o engenheiro alemão
Karl Benz, a quem a maioria dos historiadores atribui a invenção efetiva do automóvel moderno, projetou um carro movido por
um motor de combustão interna e gasolina.

Motor de indução (1885): O físico italiano Galileo Ferraris e o inventor austríaco Nikola Tesla requereram patentes no
mesmo ano para o motor de indução, um motor de corrente alternada movido a força eletromagnética.

Calculadora (1885): Após séculos de tentativas de desenvolver uma calculadora confiável, o inventor americano William
Seward Burroughs criou em 1885 uma “máquina de calcular” que constituiu a base para todos os aperfeiçoamentos futuros nas
calculadoras.

Lente de contato (1887): Embora se diga que Leonardo da Vinci esboçou os primeiros projetos para lentes oculares
corretivas, o soprador de vidros F.A. Muller foi o primeiro a conceber lentes que reproduziriam a forma do olho humano e
melhorariam a visão. Com a ajuda de seus assistentes, o físico alemão Adolf Eugen Fick aperfeiçoou o projeto, criando lentes

que se adaptavam ao olho de maneira mais confortável que qualquer versão anterior.

Eletrocardiograma (ECG) (1887): O eletrocardiograma evoluiu a partir de uma série de desenvolvimentos, mas talvez a
contribuição mais importante tenha sido a de Augustus Waller em 1887. Waller foi o primeiro cientista a levar um ECG a
público, prendendo um eletrômetro a um projetor.

Câmera cinematográfica (1888): O inventor americano Thomas Edison patenteou uma das primeiras versões de câmera
cinematográfica – que chamou de “cinetoscópio” –, mas seu aparelho era fortemente inspirado num trabalho semelhante
desenvolvido pelo fotógrafo inglês Eadweard Muybridge e nas descobertas de outros experimentadores com o meio fotográfico
no final do século XIX.

Mitocôndrias (1890): O patologista alemão Richard Altmann é em geral considerado o primeiro a descobrir as mitocôndrias –
organelas a que as células devem a maior parte de sua energia química –, por postular que elas eram unidades fundamentais da
atividade celular. Muitos cientistas continuaram a dar grandes passos na compreensão das mitocôndrias ao longo de todo o
século XX.

Bobina de Tesla (1891): O inventor tcheco Nikola Tesla inventou a bobina de Tesla, um transformador de alta frequência que
cria quantidades extremamente grandes de voltagem. O invento teve aplicações comerciais na iluminação e na
radiotransmissão.

Rádio (1896): Tradicionalmente, atribui-se a invenção do rádio moderno ao engenheiro italiano Guglielmo Marconi, que usou
ondas de rádio para criar um sistema de telegrafia sem fio (ele obteve uma patente pela criação em 1896), mas as contribuições
de Nikola Tesla, Karl Ferdinand Braun e Heinrich Hertz, entre outros, foram essenciais para o projeto final.

Radioatividade (1896): Sistematizando as descobertas feitas pouco antes pelo físico alemão Wilhelm Röntgen e pelo físico
francês Henri Becquerel, a química polonesa Marie Curie e seu marido, Pierre Curie, elaboraram uma teoria da radioatividade,
que descreve a desintegração espontânea de núcleos atômicos.

Elétron (1897): O físico britânico J.J. Thomson, auxiliado por dois colegas, o irlandês John Townsend e o também britânico
H.A. Wilson, descobriu o elétron quando fazia experimentos com raios catódicos, sugerindo que eles eram compostos por
partículas menores que átomos carregadas negativamente, que chamou de corpúsculos; mais tarde elas receberam o nome de
elétrons.

Tipos sanguíneos (1901): Em 1901, o médico austríaco Karl Landsteiner publicou resultados de estudos, demonstrando a
existência de quatro tipos sanguíneos diferentes – que se distinguiam pela presença de anticorpos e antígenos específicos.
Sustentou que a transfusão sanguínea entre dois indivíduos só podia ter sucesso se eles compartilhassem o mesmo tipo de
sangue.

Ar-condicionado (1902): Numa tentativa de sanar as dificuldades de uma oficina litográfica com os efeitos da variação da
temperatura e da umidade sobre o papel, Willis Haviland Carrier concebeu uma maneira de inverter o processo de aquecimento
para criar ar frio, controlando assim o grau de umidade no ar. Carrier fundaria depois uma empresa de condicionadores de ar e
logo lançaria novos modelos para uso doméstico.

Estratosfera (1902): Dois meteorologistas, o alemão Richard Assmann e o francês Léon Teisserenc de Bort, são
considerados responsáveis pela descoberta da estratosfera, a segunda camada da atmosfera da Terra, em 1902.

Avião movido a motor (1903): Inspirados pelos esforços do engenheiro aéreo alemão Otto Lilienthal, os irmãos Wright
fizeram experiências com os padrões de voo de pipas e em 1903 desenvolveram o primeiro avião movido a motor capaz de
fazer um voo sustentado.a

Vitaminas (1905): Embora as pessoas soubessem havia séculos que a ingestão de certos alimentos podia prevenir doenças, o
médico inglês William Fletcher descobriu em 1905 que o arroz integral, em contraposição ao refinado, ajudava a criar imunidade
ao beribéri, o que o levou a acreditar que aquele arroz continha nutrientes cuja ausência na dieta de uma pessoa a tornava mais
suscetível a doenças.

Hormônios (1905): Confirmando trabalho científico anterior sobre secreções internas no corpo humano, os fisiologistas
ingleses Ernest Henry Starling e William Maddock Bayliss demonstraram que um agente químico liberado numa parte do corpo
podia, através da corrente sanguínea, afetar o funcionamento de outra parte. A descoberta dos hormônios conduziria mais tarde

à invenção dos contraceptivos orais e também da insulina.

Equivalência massa-energia (1905): O físico teórico Albert Einstein afirmou num artigo publicado em 1905 que a massa de
um corpo é equivalente a seu conteúdo energético, o que é expresso na famosa equação E = mc², isto é, a energia é igual à
massa vezes a velocidade da luz ao quadrado.

Relatividade especial (1905): A teoria da relatividade especial – desenvolvida por Einstein em 1905 – diz respeito ao
movimento e ao comportamento de partículas que se deslocam em velocidade próxima à da luz. Baseia-se em dois postulados:
que a velocidade da luz é a mesma, seja qual for a velocidade do observador, e que as leis da física são constantes quando
observadas de qualquer referencial inercial, isto é, não em aceleração.

Núcleo da terra (1906): O sismólogo irlandês Richard Oldham deduziu que o núcleo da Terra era feito de uma matéria menos
densa e mais líquida que a rocha que o circunda ao investigar por que as ondas de terremoto se moviam mais lentamente
através do núcleo do que do manto.

Neurotransmissores (1906): O médico espanhol Santiago Ramón y Cajal revolucionou as teorias da estrutura do sistema
nervoso no início do século XX, auxiliado por métodos desenvolvidos pelo físico italiano Camillo Golgi. A teoria de Cajal,
segundo a qual o sistema nervoso era composto de bilhões de minúsculos centros nervosos – que viriam a ser conhecidos como
neurônios –, levou à descoberta dos neurotransmissores, substâncias químicas que retransmitem mensagens através de
sinapses.

Máquina de lavar (1908): O engenheiro americano Alva John Fisher fabricou a primeira máquina de lavar elétrica anexando
um motor ao modelo tradicional de lavadora de roupa a manivela. A Hurley Machine Company, sediada em Chicago,
apresentou o produto em 1908.

Genes em cromossomos (1910): Os experimentos do embriologista americano Thomas Hunt Morgan com mutações
genéticas de Drosophila melanogaster, a mosquinha-das-frutas, levou-o a descobrir, com sua equipe de alunos da
Universidade Columbia, que a hereditariedade era governada em parte por genes transportados por cromossomos.

Supercondutividade (1911): Em 1911, o físico holandês Heike Kamerlingh Onnes testou o comportamento e as propriedades
de metais como o chumbo, o estanho e o mercúrio quando imersos em temperaturas de hélio líquido, e descobriu que eles
perdiam toda a resistência quando esfriados a níveis criogênicos. Essa qualidade tornou-se conhecida como supercondutividade.

Raios cósmicos (1913): O trabalho de muitos cientistas no início do século XX culminou na descoberta dos raios cósmicos –
partículas vindas do espaço que atravessam a atmosfera e bombardeiam a Terra. Embora o físico alemão Werner Kolhörster
tenha recebido um prêmio Nobel por seu trabalho e sua pesquisa no campo nascente, seus experimentos foram fortemente
baseados em descobertas anteriores de Victor Hess e Theodor Wulf.

Papel do elétron na ligação química (1913): O físico dinamarquês Niels Bohr propôs seu modelo do elétron (levemente
baseado no modelo do químico britânico Ernest Rutherford) em 1913, postulando que os elétrons traçam órbitas padronizadas
em torno do núcleo de um átomo. Propôs ainda que a composição química de um elemento resulta do número de elétrons na
órbita do átomo. A descoberta de Bohr revelou o papel fundamental do elétron na ligação química.

Deriva continental (1915): Em 1915, o meteorologista e geólogo alemão Alfred Wegener publicou um livro em que afirmava
que todos os continentes do nosso planeta haviam sido um dia parte de uma enorme massa de terra chamada Pangeia, que
havia se dividido lentamente ao longo do tempo. De início rejeitadas, nos anos 1960 as ideias de Wegener já haviam se tornado
universalmente aceitas.

Linha de montagem em cadeia (1913): Em 1913, anunciando a era da produção em massa, a Ford Motor Company instituiu
uma linha de montagem em cadeia para fabricar automóveis, sob a liderança de Ford; o método baixava o preço dos carros e
acelerava sua produção. A inspiração para a linha de montagem veio de abatedouros do meio-oeste no século XIX.

Teoria da relatividade geral (1915): O físico teórico Albert Einstein sustentou em 1915 que a matéria curva o espaço e o
tempo, o que permite às grandes massas desviar a luz. Um dos aspectos seminais dessa teoria foi a ideia de que a atração da
gravidade num sentido era equivalente à força de aceleração no sentido oposto. A teoria de Einstein foi provada em 1919 num
estudo de eclipses solares.

Helicóptero (1920): Muitos fracassaram, mas modelos promissores de helicópteros primitivos precederam o tipo criado pelo

inventor argentino Raúl Pateras Pescara. O helicóptero de Pescara foi o primeiro a alcançar passo cíclico, ou controle das
palhetas do rotor, e ele quebrou o recorde mundial em 1924 ao voar cerca de oitocentos metros em pouco mais de quatro
minutos.

Mecânica quântica (1925): O campo da mecânica quântica, a física das escalas atômica e subatômica, teve origem por volta
de 1925, quando Werner Heisenberg publicou seu primeiro artigo sobre o assunto. Mas sua criação se deveu em grande parte
aos esforços de muitos pensadores inovadores, entre os quais Einstein, Bohr e Planck, que trabalharam da década de 1900 à de

Motor de foguete a propelente líquido (1926): Superando as críticas à sua crença no futuro dos foguetes, o físico
americano Robert H. Goddard contribuiu para a fundação do campo em 1926, quando lançou o primeiro foguete movido a
combustível líquido numa plantação de repolhos na Nova Inglaterra.

Princípio da incerteza (1927): Apresentado pela primeira vez numa carta em 1927, o princípio da incerteza do físico alemão
Werner Heisenberg declarava que quanto mais exatamente se sabe a posição de uma partícula atômica, menos precisamente se
pode conhecer seu momento linear. Interpretado de diversas maneiras, teve como implicação mais influente a ideia de que o ato
de observação transforma seu próprio objeto.

Televisão (1927): O inventor americano Philo Farnsworth requereu uma patente para o primeiro aparelho de televisão
completo em 1927, embora muitos engenheiros e inventores tivessem sido responsáveis, no curso do século anterior, pelos
desenvolvimentos tecnológicos (tubo de raios catódicos, tubo de vácuo Audion) que levaram a esse estágio.

Penicilina (1928): Embora desde a Antiguidade curandeiros soubessem que mofos podiam ser usados no tratamento de
infecções, foi um famoso erro cometido no laboratório do biólogo escocês Alexander Fleming que fez por fim a penicilina
chamar a atenção como um antibiótico milagroso. A descoberta ocorreu quando esporos de um fungo, Penicillium notatum,
flutuaram e caíram numa placa de Petri contendo uma cultura de bactérias, dando ensejo à observação de Fleming de que os
esporos estavam inibindo o crescimento das bactérias.

Expansão do universo (1929): Quando trabalhava num observatório na Califórnia, o astrônomo americano Edwin Hubble
determinou que o universo estava se expandindo. Chegou a essa conclusão ao medir os desvios para o vermelho (alterações na
frequência dos fótons) de galáxias distantes e descobrir que elas estavam se afastando umas das outras numa taxa proporcional
à distância que as separava.

Motor a jato (1930): O mérito pela invenção do motor a jato é compartilhado entre o engenheiro alemão Hans von Ohain e o
oficial da Força Aérea Real britânica Frank Whittle, que desenvolveram de maneira independente o modelo do motor, propelido
por ar comprimido inflamado e baseado nos princípios da Terceira Lei de Newton.

Nêutron (1932): O físico britânico James Chadwick descobriu o nêutron – uma partícula subatômica de carga elétrica nula –
em 1932, dando um dos primeiros passos para o desenvolvimento da bomba atômica.

Radar (1935): Baseando-se em pesquisas anteriores usando ondas de rádio para detectar trovoadas, o meteorologista escocês
Robert Watson-Watt empregou com sucesso um radar de ondas curtas para detectar um bombardeiro no ar em 1935,
descoberta que se provaria muito útil durante a Batalha da Grã-Bretanha.

Gravador de fita (1935): Companhias alemãs de tecnologia foram as primeiras a produzir gravadores de fita no início dos anos

Em 1935, o engenheiro de origem alemã Semi Joseph Begun desenvolveu o primeiro gravador de fita para consumo geral,
um Sound Mirror, com base em sua pesquisa sobre gravação magnética e usando papel e plástico especialmente revestidos.
Nylon (1937): Quando chefiava o departamento de pesquisa da DuPont, o químico americano Wallace Carothers desenvolveu
o nylon – uma fibra têxtil sintética chamada de “fibra milagrosa” –, em parte para criar uma alternativa à seda, de difícil
obtenção na época, em razão de relações comerciais abaladas com o Japão.

Ecossistema (1935): Cunhado em 1935, o termo “ecossistema” foi claramente definido pelo químico britânico Arthur Tansley
como um sistema natural em que todos os elementos físicos e orgânicos coexistem e funcionam como uma unidade mais ou
menos completa.

Ciclo de Krebs (1937): O ciclo de Krebs, mecanismo químico pelo qual o sistema respiratório de uma célula funciona, foi
formulado pelo bioquímico alemão Hans Krebs em 1937. Ele baseou-se em amplos avanços, realizados por múltiplos cientistas

ao longo da década anterior, na compreensão do modo como as células convertem nutrientes em energia.

Reator atômico (1938): O físico italiano Enrico Fermi e o físico húngaro Leo Szilard criaram o primeiro reator nuclear nos
anos 1930, com base em estudos conduzidos por Fermi e seus colegas sobre o decaimento beta e a teoria dos nêutrons.

Computador (1944): Muitos atribuem ao engenheiro alemão Konrad Zuse a invenção do primeiro computador moderno
totalmente funcional, com base num sistema binário, em 1944. É também possível, contudo, atribuir a Charles Babbage, Alan
Turing e John Vincent Ansoff a criação de várias formas de computadores.

DNA como material genético (1944): A ideia de que o DNA carrega material genético foi primeiramente estabelecida em
1944 pelo famoso experimento Avery-MacLeodMcCarthy, o qual demonstrou que, dado que o DNA podia causar a
transformação de bactérias, era possível atribuir-lhe um importante papel na transmissão hereditária dos genes.

Forno de micro-ondas (1946): O engenheiro americano Percy Spencer descobriu a possibilidade de criar um forno de micro-
ondas de maneira um tanto acidental. Quando construía um magnétron para a Raytheon Corporation, ele viu uma barra de
chocolate derreter em um experimento com radiação eletromagnética.

Transistor (1947): Contratados para aperfeiçoar o tubo de vácuo, o físico teórico e experimental Bill Shockley e os físicos
Walter Brattain e John Bardeen fizeram experimentos com semicondutores nos Laboratórios Bell, produzindo finalmente um
transistor confiável, capaz de amplificar e mudar sinais eletrônicos.

Datação por radiocarbono (1949): Quando trabalhava na Universidade de Chicago, o físico americano Willard Libby
desenvolveu com colegas a datação por radiocarbono. O método, que permite determinar a idade de substâncias orgânicas com
base na quantidade de carbono-14 presente no material, revolucionou o campo da arqueologia.

Marca-passo artificial (1950): Embora algumas versões primitivas de marca-passos cardíacos artificiais tivessem sido
projetadas antes de 1950, atribui-se em geral ao engenheiro canadense John Hopps a invenção do aparelho, que usa impulsos
elétricos para regular e simular os padrões normais de batimento do coração. Marca-passos internos só foram desenvolvidos
em 1958.

Contraceptivo oral (1951): Um grupo de cientistas frouxamente relacionados, entre os quais destaca-se o professor de
Harvard John Rock, desenvolveu a pílula anticoncepcional no início dos anos 1950, por meio de pesquisas financiadas em parte
pela advogada americana Margaret Sanger, uma defensora do controle da natalidade. À frente de um grupo da companhia
farmacêutica Syntex, o químico americano Carl Djerassi trabalhou no desenvolvimento de um hormônio esteroide, a cortisona,
que levou por fim à síntese da noretindrona, uma progestina que se tornou parte fundamental do primeiro contraceptivo oral de
sucesso.

Simulação da origem da vida (1953): Num esforço para compreender as condições que levaram ao surgimento da vida na
Terra, dois americanos, o químico Stanley Miller e o físico-químico Harold Urey, criaram um sistema fechado, incluindo os
elementos que supunham ter estado presentes na atmosfera primitiva, como hidrogênio, metano e água. Miller e Urey
descobriram que, nessas condições, aminoácidos podiam ser facilmente produzidos.

Hélice dupla (1953): Baseando-se em estudos anteriores dos nucleotídios no DNA, dois biólogos moleculares, o americano
James D. Watson e o britânico Francis Crick, fizeram experimentos com modelos de diferentes combinações de nucleotídios
usando papel e arame, e por fim se decidiram pelos fios de nucleotídios entrelaçados, duais, que hoje reconhecemos como a
hélice dupla.

Videocassete (1956): A invenção do VCR, ou gravador de videocassete, é atribuída em geral ao engenheiro americano
Charles Paulson Ginsburg, que desenvolveu o aparelho quando trabalhava na Ampex Corporation, com a aplicação de sinais de
alta frequência a uma fita magnética.

Laser (1958): Quando trabalhavam nos Laboratórios Bell, os físicos americanos Arthur L. Schawlow e Charles H. Townes
iniciaram uma investigação intensiva das radiações infravermelhas e das visíveis, desenvolvendo o que chamaram de maser, e
que mais tarde se transformaria no laser, do inglês “light amplification by stimulated emission of radiation” – isto é,
“amplificação da luz por emissão estimulada de radiação”.

GPS (1958): O GPS – ou Sistema de Posicionamento Global –, um sistema de navegação que usa satélites como pontos de
referência para calcular posições geográficas, foi desenvolvido pelo engenheiro americano Ivan Getting e sua equipe na

Raytheon Corporation, por ordem do Departamento de Defesa dos Estados Unidos, após o trabalho inicial de Guier e
Weiffenbach no rastreamento da órbita do Sputnik em 1957.

Radiação cósmica de fundo em micro-ondas (1965): Quando trabalhavam com sistemas receptores nos Laboratórios Bell,
os astrônomos americanos Arno Penzias e Robert Woodrow Wilson ficaram desconcertados com um som que não conseguiam
identificar, e que por fim compreenderam ser a radiação cósmica de fundo em microondas, um rastro de rádio remanescente do
Big Bang.

Pulsares (1967): Os pulsares – estrelas de nêutrons pulsantes que parecem piscar – foram observados e descobertos em 1967
por Jocelyn Bell Burnell, uma estudante de pós-graduação que trabalhava sob a coordenação do astrônomo britânico Antony
Hewish. Mais tarde Hewish receberia um prêmio Nobel.

RNA também genético (1967): Refletindo a descoberta anterior de que o DNA transportava material genético, o
microbiologista americano Carl Woese teorizou em 1967 que o RNA, ácido ribonucleico, podia armazenar informações como
genes, e talvez tivesse desempenhado um papel no desenvolvimento da vida primitiva e pré-celular.

Enzimas de restrição (1968): Isoladas pela primeira vez em 1968 pelos geneticistas H.O. Smith, K.W. Wilcox e T.J. Kelly na
Universidade Johns Hopkins, as enzimas de restrição, encontradas em bactérias, podem cortar DNA em sequências
específicas, abrindo caminho assim para as futuras moléculas de DNA recombinante.

Interface gráfica do usuário (IGU) (1968-1974): O uso de metáforas visuais para representar dados numa tela de
computador, junto com o conceito de um mouse para movimentar o cursor, remonta a um lendário programa demonstrativo
criado pelo professor de Stanford Douglas Engelbart. Elementos da IGU eram evidentes também no programa Sketchpad, de
Ivan Sutherland, lançado em 1963. A ideia foi aprimorada e expandida no laboratório Xerox PARC no início dos anos 1970.

Internet (1970-1975): Auxiliado por muitos outros cientistas da computação, o americano Vinton Cerf projetou e criou o
modelo original da internet, baseando-se em pesquisas e experimentos com redes de troca de pacotes de informação que
desenvolvera anteriormente sob o patrocínio da Advanced Research Projects Agency do Departamento de Defesa dos Estados
Unidos.

Tomografia axial computadorizada (1971): Graças a uma bolsa fornecida pelo Departamento de Saúde e Serviços Sociais da
Inglaterra, o engenheiro elétrico britânico Godfrey Hounsfield concebeu e projetou o primeiro aparelho de tomografia axial
computadorizada, que enviava feixes de raios X através do corpo humano, produzindo algo próximo de uma imagem
tridimensional.

Ressonância magnética (1974): Com base nas descobertas dos primeiros inventores das imagens por ressonância magnética,
Raymond Damadian descobriu que tecidos animais cancerosos e não cancerosos resultam em imagens de intensidades
diferentes.

Endorfinas (1975): As endorfinas, ou endomorfinas, foram descobertas mais ou menos na mesma época por duas equipes de
pesquisadores que trabalhavam de maneira independente. Foram descritas pela primeira vez quando o cientista americano John
Hughes e o biólogo alemão radicado na Inglaterra Hans Kosterlitz publicaram os resultados de um estudo em que removeram
uma molécula de aminoácido do cérebro de um porco, acreditando que isso estimularia investigações sobre os receptores
cerebrais para morfina.

Computador pessoal (1976): Trabalhando numa lendária garagem, dois jovens empreendedores que haviam abandonado a
universidade, Steve Wozniak e Steve Jobs, projetaram um dos primeiros computadores pessoais – o Apple I – em 1976. Foi o
primeiro computador com uma única placa de circuito, embora muitos modelos importantes, entre os quais o Altair, o tenham
precedido.

Oncogenes (1976): Fazendo avançar a compreensão do câncer e do processo de formação de tumores malignos, o
imunobiologista americano J. Michael Bishop e o biólogo celular Harold Varmus descobriram o primeiro oncogene humano em

Splicing de RNA (1977): O bioquímico britânico Richard J. Roberts e o americano Phillip A. Sharp compartilharam o mérito e
o prêmio Nobel por suas descobertas independentes do splicing de genes – a remoção de íntrons –, embora tenha surgido
alguma controvérsia acerca do não reconhecimento do trabalho dos colegas de Roberts.

Reino archaea (1977): Percebendo que muitos organismos não se encaixavam nas categorias tradicionais de planta ou animal,
o microbiologista americano Carl Woese e colegas postularam um novo reino de seres vivos, que chamaram de
archaebacteria, abreviado como archaea, para englobar bactérias e fungos.

Aquecimento global (1970-1980): Ao longo de todo o século XX foram propostas teorias sugerindo que o acúmulo de
dióxido de carbono poderia resultar num planeta mais quente. Porém, a ciência do aquecimento global só alcançou massa crítica
nos anos 1970 e 80, quando uma ampla rede de cientistas, trabalhando em diversos campos, começou a rastrear e criar modelos
de mudanças na atmosfera da Terra.

Extinção K-T (1980): Em 1980, com base em evidências geológicas substanciais, os cientistas Luis e Walter Alvarez, pai e
filho, teorizaram que 65 milhões de anos atrás (entre os períodos Cretáceo e Terciário, ou K-T), um asteroide gigantesco colidiu
com a Terra, matando a população de dinossauros.

DNA forense (1984): O geneticista britânico Alec Jeffreys descobriu a impressão digital genética por acaso, quando
observava a radiografia de um experimento que parecia mostrar as variações no DNA da família de seu técnico. Logo Jeffreys
compreendeu que a impressão digital do DNA poderia ser usada para identificar indivíduos pelo código genético. Diversos
outros cientistas apuraram essa abordagem antes que ela pudesse ser utilizada em casos criminais.

Aceleração do universo (1988): Com base em observações de estrelas criadas por explosões de estrelas anãs brancas, a
equipe de cientistas High-Z Supernova, liderada pelos astrônomos Adam Riess e Brian Schmidt, determinou que o universo
estava se expandindo numa taxa crescente.

World Wide Web (1989-1992): O engenheiro de software britânico Tim Berners-Lee projetou o programa para a World Wide
Web de maneira quase completamente independente quando trabalhava no Cern (Laboratório Europeu para Física de
Partículas), numa tentativa de criar um “caderno de hipertexto”, inspirado pela lembrança de uma enciclopédia que conhecera
quando menino.

Explosões de raios gama (1997): As explosões de raios gama – clarões de raios gama vindos das profundezas do espaço
cósmico – foram observadas pela primeira vez em 1967 por satélites militares americanos que buscavam provas da ocorrência
de testes nucleares secretos. As explosões deixaram os cientistas perplexos, incertos quanto à sua natureza ou origem até 1997,
quando o satélite ítalo-holandês BeppoSAX foi capaz de determinar a posição da explosão, levando os cientistas a compreender
que os raios eram causados por emissões residuais de raios X.

a Em 1906, com o aeroplano 14 Bis, o brasileiro Alberto Santos-Dumont tornou-se o primeiro homem a realizar um voo

completo, em que um veículo movido a gasolina decolou com os próprios meios. Foi também o primeiro voo homologado da
história da aviação. (N.E.)

Notas e leitura adicional
Sobre inovação
Existe uma vasta literatura sobre a questão da inovação, em particular nos campos científico e tecnológico. Tentei incluir um
amplo levantamento dessas obras na bibliografia, mas várias delas tiveram uma influência desproporcional em minha
argumentação e meu método neste livro. A origem do gênio, de Dean Keith Simonton, e Darwin on Man, de Howard Gruber,
adotam, de maneira explícita, uma abordagem darwiniana à inovação e a utilizam para interpretar o gênio inconfundível do
próprio Darwin. The Act of Creation, de Arthur Koestler, e A estrutura das revoluções científicas, de Thomas Kuhn,
continuam sendo plataformas essenciais para a compreensão de novas ideias. The Rise of the Creative Class, de Richard
Florida, considera a criatividade num contexto urbano. Smart World, de Richard Ogle, explora o contexto intelectual e físico da
formação das ideias, como faz Mentes extraordinárias, de Howard Gardner. Diffusion of Innovations, de Everett M.
Rogers, é o estudo canônico do modo como as boas ideias se espalham pelas organizações e pela sociedade. Flow and
Creativity, de Mihaly Csikszentmihalyi, explora os estados psicológicos de intensa criatividade. O poder da inovação de grupo e
do “usuário final” foi documentado de maneira convincente por Eric von Hippel em Democratizing Innovation e por Amar
Bhidé em Venturesome Economy. E muitos de nossos clichês sobre as origens das boas ideias são deliciosamente
desmascarados em Mitos da inovação de Scott Berkun.

Introdução: Recife, cidade, web (p.7 a 24)
O relato da viagem de Darwin às ilhas Cocos foi tomado da narrativa dele mesmo em A viagem do Beagle, bem como de
parte da correspondência incluída em Autobiografia – Charles Darwin 1809-1882 e em Charles Darwin’s Beagle Diary,
de R.D. Keynes. A conexão entre as teorias de Darwin sobre a formação de recifes de coral e seus insights posteriores
relativos ao mecanismo da seleção natural é discutida por Howard Gruber em Darwin on Man. O estudo original sobre
escalamento superlinear em ambientes urbanos está disponível em “Growth, Innovation, Scaling, and the Pace of Life in Cities”,
de Bettencourt et al. Uma cuidadosa introdução à lei de Kleiber e sua aplicação à cultura urbana voltada para leigos pode ser
encontrada em “Of Mice and Elephants: A Matter of Scale”, de George Johnson. Para uma história completa do
desenvolvimento da televisão digital, ver Defining Vision, de Joel Brinkley. Um informativo gráfico das taxas de adoção de
tecnologia nos Estados Unidos pode ser encontrado em http://www. nytimes.com/imagepages/2008/02/10/opinion/
100p.graphic.ready.html. “The Gurus of YouTube”, de John Cloud, traz uma história da fundação da empresa. Para uma síntese
interessante dos poderes “generativos” da web, ver The Future of the Internet – And How to Stop It, de Jonathan Zittrain.
Para mais informações sobre a evolução das interfaces de software, ver Tools for Thought de Howard Rheingold e o meu
Cultura da interface. A noção de “padrões” de inovação baseia-se livremente no conceito de padrões e metapadrões
desenvolvido por Gregory Bateson em Mente e natureza: a unidade necessária. A abordagem do “zoom longo” é discutida
em mais detalhes nos apêndices de meus livros anteriores Everything Bad Is Good for You e A invenção do ar. A ideia tem
raízes na noção de “consiliência” de Edward O. Wilson e foi parcialmente inspirada por uma figura da civilização em “camadas
de ritmo” que encontrei pela primeira vez em How Buildings Learn, de Stewart Brand.

1. O possível adjacente (p.25 a 40)
Para uma história da incubadora, ver “The Incubator and the Medical Discovery of the Premature Infant”, de Jeffrey Baker. O
site Neonatology na web (http://www. neonatology.org/) mantém um excelente arquivo sobre a história das incubadoras e
outras tecnologias neonatais. Para mais sobre a abordagem inovadora da Design That Matters, ver “Better by Design”, de
Timothy Prestero. Informação adicional sobre a incubadora NeoNurture pode ser encontrada em designthatmatters.org. A
teoria do possível adjacente de Kauffman está esboçada em seu livro Investigations. As causas sociais da descoberta múltipla
simultânea estão delineadas no artigo de Ogburn e Thomas, “Are Inventions Inevitable?” O fenômeno é também discutido em
profundidade em Creativity in Science, de Dean Keith Simonton. Para mais sobre a descoberta do oxigênio, ver A estrutura
das revoluções científicas, de Kuhn, World on Fire, de Joe Jackson, e meu próprio A invenção do ar. A tentativa de Charles
Babbage de construir o primeiro computador é narrada por Doron Swade em The Difference Engine. A história da Apollo 13
é contada por Jim Lovell e Jeffrey Kluger em Lost Moon.

2. Redes líquidas (p.41 a 59)
Sobre a importância do carbono e da água em estado líquido para as origens da vida, recomendo várias fontes: uma coletânea
de ensaios organizada por J. William Schopf intitulada Life’s Origin; a criativa “biografia” da água de Philip Ball, Life’s Matrix;
e o ensaio de Carl Zimmer publicado na Science, “Evolutionary Roots: On the Origin of Life on Earth”. O experimento original
de Miller e Urey foi publicado na Science sob o título “A Production of Amino Acids Under Possible Primitive Earth
Conditions”. A vida baseada no silício aparece em diversas obras de ficção científica, como no conto “Uma odisseia marciana”,
de Stanley Weinbaum, e na forma de Horta, uma criatura baseada em silício que aparece no 26o episódio da série original de
Jornada nas estrelas. As teorias de Chris Langton sobre o poder generativo das redes líquidas são desenvolvidas em seu
ensaio “Life at the Edge of Chaos”. Exposições esclarecedoras de sua obra aparecem tanto em Caos, de James Gleick, como
em Out of Control, de Kevin Kelly. A Wikipédia em inglês mantém uma excelente “linha do tempo das inovações” (“timeline
of innovations”), que forneceu um ponto de partida útil para os gráficos da inovação histórica incluídos neste livro. Sobre o
surgimento das primeiras cidades renascentistas e as inovações, Os jogos das trocas de Braudel continua a ser o texto
canônico. A história da contabilidade de dupla entrada é contada por John Richard Edwards em A History of Financial
Accounting. Para mais detalhes sobre o poder da tomada de decisão coletiva, ver A sabedoria das multidões, de James
Surowiecki; Smart Mobs, de Howard Rheingold; Here Comes Everybody, de Clay Shirky; e Out of Control, de Kevin Kelly.
A crítica de Jaron Lanier à “mente colmeia” aparece em seu livro Gadget: você não é um aplicativo e, numa forma mais
curta, no ensaio “Digital Maoism”. Para saber mais sobre a pesquisa de Kevin Dunbar, ver “What Scientific Thinking Reveals
About the Nature of Cognition”. A abordagem de Malcolm Gladwell sobre o futuro jacobsiano do planejamento do ambiente de
trabalho foi publicada na New Yorker no ensaio “Designs for Working”. Stewart Brand dedica um capítulo de How Buildings
Learn à abordagem “promíscua” do Building 20. O MIT tem um website que inclui reminiscências sobre o prédio em
http://libraries.mit.edu/archives/mithistory/building20/ quotes.html.

3. A intuição lenta (p.60 a 72)
As falhas do serviço secreto em torno do memorando Phoenix e da investigação sobre Moussaoui são discutidas no 9/11
Commission Report e em Breakdown, de Bill Gertz. Uma transcrição da carta do agente de campo Coleen Rowley de
Mineápolis ao diretor do FBI, Mueller, detalhando as conexões malogradas que conduziram aos ataques de 11 de Setembro está
disponível em http://www.time.com/time/covers/1101020603/ memo.html. O website http://www.historycommons.org/ contém
um arquivo exaustivo de documentos e reportagens relacionados ao 11 de Setembro, inclusive a linha do tempo mais abrangente
que encontrei dos meses de verão que precederam o ataque. A pesquisa de António Damásio sobre as avaliações instantâneas
do “cérebro emocional” pode ser encontrada em sua engenhosa obra O erro de Descartes. Os julgamentos instantâneos são
também investigados em Blink: a decisão num piscar de olhos, de Gladwell, e em O momento decisivo, de Jonah Lehrer.
Para mais informações sobre a intuição lenta de Priestley, ver meu livro A invenção do ar. Bill Buxton, o principal cientista da
Microsoft, escreve sobre o modelo da intuição lenta na tecnologia num ensaio publicado na BusinessWeek, “The Long Nose of
Innovation”. Darwin on Man, de Howard Gruber, é ao mesmo tempo o estudo canônico da jornada intelectual de Darwin até a
ideia de seleção natural e uma das obras mais perspicazes sobre a criatividade científica já escritas. Imagens do livro de
citações de Erasmus Darwin podem ser encontradas em http://www.revolutionaryplayers.org.uk/. O guia de autoajuda de John
Mason sobre livros de citações apareceu em seu Treatise on Knowledge. O ensaio de Robert Darnton, “Extraordinary
Commonplaces”, na New York Review of Books, fornece uma exposição erudita sobre o impacto dos livros de citações na
imaginação literária na era do Iluminismo. Em Weaving the Web, Tim Berners-Lee conta como inventou a web e expõe suas
ideias para a melhoria da plataforma atual. Scott Berkun, autor de Mitos da inovação, tem uma interessante análise do
programa de “tempo livre para inovação” do Google em seu blog em http://www.scottberkun.com/blog/2008/ thoughts-on-
googles-20-time/.

4. Serendipidade (p.83 a 108)
Para saber mais sobre a batalha entre as interpretações química e elétrica da atividade cerebral, bem como para material
adicional sobre o sonho de Loewi, ver The War of the Soups and the Sparks, de Eliot Valenstein. Consiliência: a unidade
do conhecimento, de Edward O. Wilson, discute as revelações intelectuais do sonho, com referência específica à visão do
Uróboro por Kekulé. O experimento de Ullrich Wagner está documentado no ensaio “Sleep Inspires Insight”, publicado na
Nature. O estudo feito por Robert Thatcher de alternância de fases pode ser encontrado em “Intelligence and EEG Phase
Reset” da revista NeuroImage. Para mais sobre serendipidade neurológica, ver o ensaio “Disorderly Genius”, de David
Robson, na New Scientist. A citação de William James sobre a natureza caótica da “ordem mais elevada das mentes” aparece
em Great Men, Great Thoughts, and the Environment. Para uma síntese interessante e provocativa da evolução da

reprodução sexual, ver Red Queen, de Matt Ridley, e Por que o sexo é divertido?, de Jared Diamond. A discussão da
serendipidade por John Barth foi tomada de seu romance The Last Voyage of Somebody the Sailor. Henri Poincaré narra
suas epifanias prosaicas no ensaio Science and Method. Uma lista surpreendentemente longa de ensaios tem sustentado que a
web reduz nossas oportunidades de fazer descobertas serendipitosas; entre eles estão “The Endangered Joy of Serendipity”, de
William McKeen, e “Serendipity, Lost in the Digital Deluge”, de Damon Darlin. Cass Sunstein discutiu sua noção de uma
arquitetura da serendipidade em Going to Extremes, e, com Richard Thaler, em Nudge: o empurrão para a escolha certa. A
técnica de brainstorming de Alex Osborn foi introduzida em seu livro O poder criador da mente. Para uma discussão dos
problemas do brainstorming e a criatividade de grupo em geral, ver “Illusion of Group Productivity”, de B.A. Nistad, publicado
no European Journal of Social Psychology. Para mais informações sobre laboratórios de P&D abertos, ver Wikinomics, de
Don Tapscott e Anthony D. Williams.

Erro (p.109 a 124)
Para saber mais sobre a extraordinária carreira de Lee de Forest como inventor (e, mais tarde na vida, como habitante de
Hollywood) ver sua autobiografia, Father of Radio. O ensaio de W. Rupert Maclaurin, “The Process of Technological
Innovation”, também contém uma análise reveladora da invenção resultante de erros do tríodo. Informação adicional sobre a
invenção do marca-passo por Wilson Greatbatch pode ser encontrada em “Making Hearts Beat”, de John Adam. A referência
de Will Stanley Jevons aos “erros da grande mente” aparece em seu “Principles of Science”. Para mais sobre o potencial
generativo do erro, ver o esplêndido livro Being Wrong, de Kathryn Schulz. Discuti a relação entre os paradigmas científicos de
Kuhn e a abordagem do zoom longo em meu livro A invenção do ar. Para uma excelente discussão da pesquisa de Dunbar e a
descoberta acidental da radiação cósmica de fundo, ver o ensaio “Accept Defeat”, de Jonah Lehrer, publicado na Wired. Uma
boa introdução à pesquisa de Charlan Nemeth pode ser encontrada em seus ensaios “Differential Contributions of Majority and
Minority Influence” e “Dissent as Driving Cognition, Attitudes, and Judgments”. Para uma amostra das estatísticas referentes a
associações livres, ver Word Association Norms, de Palermo. Uma discussão da teoria errônea da pangênese, proposta por
Darwin, pode ser encontrada em The Plausibility of Life, de Kirschner e Gerhart. Uma visão geral de como a taxa de
mutação genética humana era calculada pode ser encontrada num artigo de Elie Dolgin na Nature News, “Human Mutation
Rate Revealed”. Para mais detalhes sobre a pesquisa de Susan Rosenberg sobre estresse e taxas de mutação, ver seu ensaio
“Microbiology and Evolution: Modulating Mutation Rates in the Wild”, na Science. Para mais sobre o movimento “fail fast”,
ver o ensaio de Doug Hall na BusinessWeek “Fail Fast, Fail Cheap” e o de Timothy Prestero “Better by Design”.

6. Exaptação (p.125 a 145)
A invenção da imprensa por Gutenberg é narrada por John Man em Gutenberg. Vali-me também dos insights sobre a revolução
de Gutenberg que aparecem em Smart World, de Richard Ogle e em Printing Press as an Agent of Change, de Elizabeth
Eisenstein. O conceito de exaptação de Gould e Vrba surgiu pela primeira vez no ensaio “Exaptation – A Missing Term in the
Science of Form”, publicado na revista Paleobiology. Para mais sobre o conceito, ver Adaptations, Exaptations, and
Spandrels, de Buss et al. Para saber mais sobre a história do Google, ver A busca, de John Battelle. Franco Moretti discute a
exaptação cultural no ensaio “Sobre a evolução literária”, incluído em seu Signos e estilos da modernidade. The Act of
Creation de Koestler contém muitos exemplos de pensamento exaptativo, embora não use o termo explicitamente, já que o livro
é anterior ao ensaio de Gould e Vrba. Para mais detalhes sobre subculturas urbanas, ver os ensaios de Claude Fischer “Toward
a Subcultural Theory of Urbanism” e “The Subcultural Theory of Urbanism: A Twentieth-Year Assessment”. Morte e vida de
grandes cidades e The Economy of Cities, de Jane Jacobs, contêm muitos insights semelhantes sobre a capacidade das
grandes cidades de cultivar pequenos agrupamentos de interesses. (Chris Anderson discute isso no contexto de sua teoria em A
cauda longa.) Sobre o conceito do “terceiro lugar”, ver The Great Good Place de Ray Oldenburg. Para mais detalhes sobre
as inovações dos cafés britânicos, ver Social Life of Coffee, de Brian Cowan, História do mundo em seis copos, de Tom
Standage, e o meu A invenção do ar. O salão de Freud em Viena é descrito no contexto na inovação em Mentes
extraordinárias, de Howard Gardner. A pesquisa de Martin Ruef aparece em seu ensaio “Strong Ties, Weak Ties and
Islands”, publicado originalmente em Industrial and Corporate Change. Sobre a análise das redes sociais e da inovação
organizacional de Ronald Burt, ver seu “Social Contagion and Innovation” e Social Origins of Good Ideas. Richard Ogle faz
uma fascinante análise da criatividade exaptativa de Watson e Crick em Smart World. Quanto aos projetos e processos de
desenvolvimento da Apple, ver, “How Apple Does It”, de Lev Grossman. Howard Gruber descreve suas “redes de
empreendimentos” no ensaio “The Evolving Systems Approach to Creative Work”. Para saber mais sobre os diversos
interesses intelectuais de John Snow, ver Cholera, Chloroform, and the Science of Medicine, de Peter Vinten-Johansen, e o
meu O mapa fantasma.

7. Plataformas (p.146 a 175)
A teoria uniformitarianista de Charles Lyell está resumida em seus Principles of Geology. Para mais sobre a reação de Lyell à
ideia de Darwin, ver a correspondência incluída na Autobiografia deste último. Sobre o conceito de espécies-chave, ver
“Conversation on Refining the Concept of Keystone Species”, de R.T. Paine, publicado em Conservation Biology. O conceito
de construtores de ecossistemas é introduzido por Clive Jones em “Organisms as Ecosystem Engineers”. Para uma deliciosa
história das origens do GPS, ver o relato em primeira pessoa de William Guier e George Weiffenbach, “Genesis of Satellite
Navigation”. Franco Moretti publicou várias obras importantes que tratam da história dos gêneros e recursos narrativos, entre
as quais The Way of the World e Graphs, Maps, Trees. Para o histórico de inovações da plataforma do Twitter, ver meu
ensaio “How Twitter Will Change the Way We Live”, publicado na revista Time. Como muitos sucessos na web, a plataforma
de inovação do Twitter baseia-se em duas contribuições decisivas de seus usuários: a inovação do “usuário final” e o consumo
“ousado”. Para saber mais sobre esses conceitos, ver Democratizing Innovation, de Eric von Hippel, e Venturesome
Economy, de Amar Bhidé. Sobre a política das plataformas colaborativas, ver Here Comes Everybody, de Clay Shirky. Tim
O’Reilly discute a ideia de governo como plataforma numa coluna da Forbes intitulada “Gov 2.0: The Promise of Innovation”.
Uma descrição do recife artificial Redbird pode ser encontrada num artigo de Ian Urbina publicado no New York Times,
“Growing Pains for a Deep-Sea Home Built of Subway Cars”. Para mais sobre a visão de Jacobs de bairros como plataformas
emergentes, ver meu livro Emergência. A pesquisa sobre os corais de Claudio Richter é descrita num artigo de John Roach na
National Geographic, “Rich Coral Reefs in Nutrient-Poor Water: Paradox Explained?” Sobre a tecnologia do Calera, ver o
artigo de David Biello na Scientific American “Cement from CO 2 : A Concrete Cure for Global Warming?” Discuto a ideia da

web como floresta pluvial numa coluna na Discover, “Why the Web Is Like a Rainforest” e num discurso pronunciado na
conferência SXSW intitulada “Old Growth Media and the Future of News”, cuja transcrição pode ser encontrada em
http://www.stevenberlinjohnson.com.

Conclusão: O quarto quadrante (p.176 a 204)
A autobiografia de Willis Carrier é contada em Father of Air Conditioning. O conceito de “leitura distante” de Moretti é
apresentado em seu Graphs, Maps, Trees. O levantamento das inovações também se baseia na abordagem histriométrica da
inovação desenvolvida por Dean Keith Simonton em Genius, Creativity, and Leadership e Creativity in Science. Yochai
Benkler inclui um gráfico mais complexo de contextos potenciais da inovação em Wealth of Networks. Para a noção de
invenção coletiva, ver “Episodes of Collective Invention”, de Peter B. Meyer. A reação de Marx e Engels à obra de Darwin é
discutida por Gruber em Darwin on Man. Para mais sobre a metáfora da ribanceira emaranhada e sua importância para a
teoria da evolução, ver Tangled Bank, de Carl Zimmer. A disputa de McPherson com Evans e a troca de correspondências
entre o primeiro e Jefferson são discutidas por Joseph Scott Miller no ensaio “Nonobviousness: Looking Back and Looking
Ahead”, incluído na coletânea Intellectual Property and Information Wealth, organizada por Peter K. Yu. Encontrei a citação
de Jefferson pela primeira em Future of Ideas, de Lawrence Lessig. Ao lado de Code e Remix, esse livro é uma leitura
essencial para todos os interessados na noção de um “terra comunal” de informações.

Bibliografia
Adam, John. “Making Hearts Beat”, palestra, Smithsonian Institution, Innovative Lives, 1999.
http://invention.smithsonian.org/centerpieces/ilives/lecture09. html.
Anderson, Chris. The Long Tail: Why the Future of Business Is Selling Less of More. Nova York, Hyperion, 2008. [Ed.bras.:
A cauda longa: do mercado de massa para o mercado de nicho. Rio de Janeiro, Campus, 2006.]
Baker, Jeffrey P. “The Incubator and the Medical Discovery of the Premature Infant”, Journal of Perinatology, vol.20, n.5,
2000, p.321-8.
Ball, Philip. Life’s Matrix: A Biography of Water. Nova York, Farrar, Straus, and Giroux, 2000.
Barth, John. The Last Voyage of Somebody the Sailor. Boston, Little, Brown, 1991.
Bateson, Gregory. Mind and Nature: A Necessary Unity. Cresskill, N.J., Hampton Press, 2002. [Ed.bras.: Mente e natureza:
a união necessária. Rio de Janeiro, Francisco Alves, 1986.]
Battelle, John. The Search: How Google and Its Rivals Rewrote the Rules of Business and Transformed Our Culture.
Nova York, Portfolio, 2006. [Ed.bras.: A busca. Rio de Janeiro, Campus, 2005.]
Baumol, William J. The Free-Market Innovation Machine: Analyzing the Growth Miracle of Capitalism. Princeton,
Princeton University Press, 2002.
Benkler, Yochai. The Wealth of Networks: How Social Production Transforms Markets and Freedom. New Haven, Yale
University Press, 2006.
Berkun, Scott. The Myths of Innovation. Sebastopol, Calif., O’Reilly, 2007. [Ed.bras.: Mitos da inovação. Rio de Janeiro, Alta
Books, 2007.]
Berners-Lee, Tim. Weaving the Web: The Original Design and Ultimate Destiny of the World Wide Web by Its Inventor.
Nova York, HarperCollins, 1999.
Bettencourt, L., J. Lobo, D. Helbing, C. Kühnert e G.B. West. “Growth, Innovation, Scaling, and the Pace of Life in Cities”,
Proceedings of the National Academy of Sciences, vol.104, n.17, 2007, 7301-6.
Bhidé, Amar. The Venturesome Economy. Princeton, Princeton University Press, 2008.
Biello, David. “Cement from CO 2 : A Concrete Cure for Global Warming?”, Scientific American, 7 de agosto de 2008.

http://tinyurl.com/ygp4o82.
Brand, Stewart. How Buildings Learn: What Happens After They’re Built. Nova York, Penguin Books, 1994.
Braudel, Fernand. A History of Civilizations. Nova York, Penguin Books, 1993.
________.The Perspective of the World. Berkeley, University of California Press, 1992. Vol.3, Civilization and Capitalism
15th-18th Century, 1992. [Ed.bras.: Civilização material, economia e capitalismo: séculos XV-XVIII – O tempo do
mundo, vol.3. São Paulo, Martins Fontes, 2009.]
________.The Wheels of Commerce. Berkeley, University of California Press, 1992. Vol.2, Civilization and Capitalism 15th-
18th Century, 1992. [Ed.bras.: Civilização material, economia e capitalismo: séculos XV-XVIII – Os jogos das trocas,
vol.2. São Paulo, Martins Fontes, 2009.]
Brinkley, Joel. Defining Vision: The Battle for the Future of Television. Nova York, Harcourt Brace, 1997.
Brown, John Seely e Paul Duguid. The Social Life of Information. Boston, Harvard Business School Press, 2002. [Ed.bras.: A
vida social da informação. São Paulo, Makron Books, 2001.]
Burt, Ronald S. “Social Contagion and Innovation: Cohesion Versus Structural Equivalence”, American Journal of Sociology,
vol.92, n.6, 1987, p.1287-335.
________.Social Origins of Good Ideas. Chicago, Universidade de Chicago, 2003.
http://www.uchicago.edu/fac/ronald.burt/research/SOGI.pdf.
Buss, David M., et al. “Adaptations, Exaptations, and Spandrels”, American Psychologist, vol.53, n.5, 1998, p.533-48.
Buxton, Bill. “The Long Nose of Innovation”, BusinessWeek, 2 de janeiro de 2008. http://
http://www.businessweek.com/innovate/content/jan 2008/id2008012_297369.htm.
Carrier, Willis Haviland. Father of Air Conditioning. Garden City, N.Y., Country Life Press, 1952.
Cloud, John. “The Gurus of YouTube”, Time, 16 de dezembro de 2006. http://www.
time.com/time/magazine/article/0,9171,1570721,00.html.
Cowan, Brian William. The Social Life of Coffee: The Emergence of the British Coffeehouse. New Haven, Yale University
Press, 2005.

Cowan, Robin e Nicolas Jonard. “The Dynamics of Collective Invention”, Journal of Economic Behavior and Organization,
vol.52, n.4, 2003, p.513-32.
Csikszentmihalyi, Mihaly. Creativity: Flow and the Psychology of Discovery and Invention. Nova York, HarperPerennial,

________. Flow: The Psychology of Optimal Experience. Nova York, HarperPerennial, 1991.
Dacey, John S., Kathleen Lennon e Lisa B. Fiore. Understanding Creativity: The Interplay of Biological, Psychological,
and Social Factors. São Francisco, Jossey-Bass, 1998.
Damásio, António R. Descartes’ Error: Emotion, Reason, and the Human Brain. Londres, Penguin, 2005. [Ed.bras.: O erro
de Descartes. São Paulo, Companhia das Letras, 2ª ed. 1996.]
Darlin, Damon. “Serendipity, Lost in the Digital Deluge”, The New York Times, 1º de agosto de 2009.
Darnton, Robert. “Extraordinary Commonplaces”, New York Review of Books, vol.47, n.20, 2000, p.82-87.
Darwin, Charles. Voyage of the Beagle. Mineola, N.Y., Dover Publications, 2002.
Darwin, Charles, e Francis, Sir Darwin. The Autobiography of Charles Darwin. Amherst, N.Y., Prometheus Books, 2000.
[Ed.bras.: Darwin: Autobiografia – 1809-1822. Rio de Janeiro, Contraponto, 2009.]
Darwin, Charles, e R.D. Keynes. Charles Darwin’s Beagle Diary. Cambridge, UK, Cambridge University Press, 1988.
[Ed.bras.: O diário do Beagle. Curitiba, Ed. UFPR, 2008.]
De Forest, Lee. Father of Radio: The Autobiography of Lee de Forest. Chicago, Wilcox & Follett, 1950.
De Landa, Manuel. A Thousand Years of Nonlinear History. Nova York, Zone Books, 1997.
Diamond, Jared M. Why Is Sex Fun? The Evolution of Human Sexuality. Nova York, HarperCollins, 1997. [Ed.bras.: Por
que o sexo é divertido? A evolução da sexualidade humana. Rio de Janeiro, Rocco, 1999.]
Dolgin, Elie. “Human Mutation Rate Revealed”, Nature News, 27 de agosto de 2009.
http://www.nature.com/news/2009/090827/full/news.2009.864.html.
Dunbar, Kevin. “How Scientists Build Models: InVivo Science as a Window on the Scientific Mind”, in Lorenzo Magnani, Nancy
J. Nersessian e Paul Thagard (orgs.), Model-based Reasoning in Scientific Discovery. Nova York, Plenum Press, 1999,
p.89-98.
________. “How Scientists Think: On-Line Creativity and Conceptual Change in Science”, in Thomas B. Ward, Stephen M.
Smith e Jyotsna Vaid (orgs.), Creative Thought: An Investigation of Conceptual Structures and Processes. Washington,
D.C., American Psychological Association, 1997, p.461-93.
________. “What Scientific Thinking Reveals About the Nature of Cognition”, in Kevin Crowley, Christian D. Schunn e
Takeshi Okada (orgs.), Designing for Science: Implications from Everyday, Classroom, and Professional Settings.
Mahwah, N.J., Lawrence Erlbaum Associates, 2001.
Edwards, John Richard. A History of Financial Accounting. Londres, Routledge, 1989.
Eisenstein, Elizabeth L. The Printing Press as an Agent of Change. Cambridge, UK, Cambridge University Press, 1980.
Fischer, Claude S. “The Subcultural Theory of Urbanism: A Twentieth-Year Assessment”, American Journal of Sociology,
vol.101, n.3, 1995, p.543-77.
________. “Toward a Subcultural Theory of Urbanism”, American Journal of Sociology, vol.80, n.6, 1975, p.1319-41.
Florida, Richard L. Cities and the Creative Class. Nova York, Routledge, 2005.
________.The Rise of the Creative Class and How It’s Transforming Work, Leisure, Community and Everyday Life. Nova
York, Basic Books, 2004.
Franklin, Benjamin. The Life and Writings of Benjamin Franklin. Filadélfia, McCarty & Davis, vol.2, 1834.
Gardner, Howard. Creating Minds: An Anatomy of Creativity Seen Through the Lives of Freud, Einstein, Picasso,
Stravinsky, Eliot, Graham, and Gandhi. Nova York, Basic Books, 1993. [Ed.bras.: Mentes extraordinárias: perfis de
quatro pessoas excepcionais e um estudo sobre o extraordinário em cada um de nós. Rio de Janeiro, Rocco, 1999.]
Gay, Peter. The Enlightenment: An Interpretation. Nova York, W.W. Norton, 1977.
________.The Enlightenment: The Science of Freedom. Nova York, W.W. Norton, 1977.
Gertz, Bill. Breakdown: The Failure of American Intelligence to Defeat Global Terror. Nova York, Plume, 2003.
Gladwell, Malcolm. Blink: The Power of Thinking Without Thinking. Nova York, Back Bay Books, 2007. [Ed.bras.: Blink: a
decisão num piscar de olhos. Rio de Janeiro, Rocco, 2005.]
________. “Designs for Working”, The New Yorker, 11 de dezembro de 2000, p.60-70.
Gleick, James. Chaos: Making a New Science. Nova York, Penguin Books, 1987. [Ed. bras.: Caos: a criação de uma nova
ciência. Rio de Janeiro, Campus, 1989.]
Gould, Stephen J. e Elisabeth S. Vrba. “Exaptation – A Missing Term in the Science of Form”, Paleobiology, vol.8, n.1, janeiro
de 1982, p.4-15.
Grossman, Lev. “How Apple Does It”, Time, 16 de outubro de 2005.

http://www.time.com/time/magazine/article/0,9171,1118384,00.html.
Gruber, Howard E. “Networks of Enterprise in Creative Scientific Work”, in Barry Gholson et al. (orgs.), Psychology of
Science: Contributions to Metascience. Nova York, Cambridge University Press, 1989, p.246.
________. “The Evolving Systems Approach to Creative Work”, Creativity Research Journal, vol.1, n.1, 1988, p.27-51.
Gruber, Howard E., Charles Darwin e Paul H. Barrett. Darwin on Man: A Psychological Study of Scientific Creativity.
Nova York, Dutton, 1974.
Guier, William H. e George C. Weiffenbach. “Genesis of Satellite Navigation”, Johns Hopkins APL Technical Digest, vol.19,
n.1, 1998, p.15.
Hall, Doug. “Fail Fast, Fail Cheap”, BusinessWeek, 25 de junho de 2007. http://www.
businessweek.com/magazine/content/07_26/b4040436.htm_.
Harkness, Deborah E. The Jewel House: Elizabethan London and the Scientific Revolution. New Haven, Yale University
Press, 2007.
Hausman, Carl R. e Albert Rothenberg. The Creativity Question. Durham, Duke University Press, 1983.
Hippel, Eric von. Democratizing Innovation. Cambridge, Mass., MIT Press, 2005.
Iberall, Arthur S. “A Physics for Studies of Civilization”, in Eugene F. Yates (org.), Self-Organizing Systems: The Emergence
of Order. Nova York, Plenum Press, 1987.
Jackson, Joe. A World on Fire: A Heretic, an Aristocrat, and the Race to Discover Oxygen. Nova York, Penguin, 2007.
Jacobs, Jane. The Nature of Economies. Nova York, Modern Library, 2000. [Ed.bras.: A natureza das economias. São Paulo,
Beca, 2001.]
________.The Economy of Cities. Nova York, Random House, 1969.
________.The Death and Life of Great American Cities. Nova York, Random House, 1961. [Ed.bras.: Morte e vida de
grandes cidades. São Paulo, Martins Fontes, 2009.]
James, William. Great Men, Great Thoughts, and the Environment. Boston, Houghton Mifflin, 1880.
Jastrow, Joseph (org.). Story of Human Error. Manchester, N.H., Ayer Publishing, 1936.
Jefferson, Thomas. The Writings of Thomas Jefferson. Organizado por Albert Ellery Bergh. Washington, D.C., Thomas
Jefferson Memorial Association, vol.1-19, 1905.
Jevons, Will Stanley. “Principles of Science”, Daedalus, vol.87, n.4, 1958, p.148-54.
Johnson, George. “Of Mice and Elephants: A Matter of Scale”, New York Times, 12 de janeiro de 1999.
Johnson, Steven. “How Twitter Will Change the Way We Live”, Time, 5 de junho de 2009.
http://www.time.com/time/business/article/0, 8599,1902604,00.html#ixzz0mu8f4umZ.
Johnson, Steven. The Invention of Air: A Story of Science, Faith, Revolution, and the Birth of America. Nova York,
Riverhead Books, 2008. [Ed.bras.: A invenção do ar: uma saga de ciência, fé, revolução e o nascimento dos Estados
Unidos. Rio de Janeiro, Zahar, 2009.]
________.Everything Bad Is Good for You: How Today’s Popular Culture Is Actually Making Us Smarter. Nova York,
Riverhead Books, 2006.
________. “Why the Web Is Like a Rainforest”, Discover, outubro de 2005. http://discovermagazine.com/2005/oct/emerging-
technology.
________.Emergence: The Connected Lives of Ants, Brains, Cities, and Software. Nova York, Scribner, 2002. [Ed.bras.:
Emergência: a dinâmica da rede em formigas, cérebros, cidades e softwares. Rio de Janeiro, Zahar, 2003.]
________. Interface Culture: How New Technology Transforms the Way We Create and Communicate. São Francisco,
HarperEdge, 1997. [Ed.bras.: Cultura da interface: como o computador transforma nossa maneira de criar e
comunicar. Rio de Janeiro, Zahar, 2001.]
Jones, Clive G., J. H. Lawton e M. Shachak. “Organisms as Ecosystem Engineers”, Oikos, 1994, p.373-86.
Kauffman, Stuart A. Investigations. Nova York, Oxford University Press, 2000.
________. At Home in the Universe: The Search for the Laws of Self-Organization and Complexity. Nova York, Oxford
University Press, 1995.
Kelly, Kevin. Out of Control. Nova York, Addison-Wesley, 1994.
Kirschner, Marc e John Gerhart. The Plausibility of Life: Resolving Darwin’s Dilemma. New Haven, Yale University Press,

Koestler, Arthur. The Act of Creation. Londres, Hutchinson, 1969.
Kostof, Spiro. The City Shaped: Urban Patterns and Meanings Through History. Boston, Little, Brown, 1991.
Kuhn, Thomas S. The Structure of Scientific Revolutions. Chicago, University of Chicago Press, 1970. [Ed.bras.: A estrutura
das revoluções científicas. São Paulo, Perspectiva, 9ª ed., 2006.]
Langton, Christopher G. et al. “Life at the Edge of Chaos”, Artificial Life vol.II, n.10, 1992, p.41-91.

Lanier, Jaron. You Are Not a Gadget: A Manifesto. Waterville, Maine, Thorndike Press, 2010. [Ed.bras.: Gadget: você não é
um aplicativo!. São Paulo, Saraiva, 2010.]
________. “Digital Maoism: The Hazards of the New Online Collectivism”, The Edge, vol.183, 30 de maio de 2006.
Lehrer, Jonah. How We Decide. Boston, Mariner Books, 2010. [Ed.bras.: O momento decisivo. Rio de Janeiro, Best Business,
2010.]
________.”Accept Defeat: The Neuroscience of Screwing Up”, Wired, 21 de dezembro de 2009.
http://www.wired.com/magazine/2009/12/fail_accept_defeat/all/1.
Lessig, Lawrence. Remix: Making Art and Commerce Thrive in the Hybrid Economy. Nova York, Penguin Press, 2008.
________.The Future of Ideas: The Fate of the Commons in a Connected World. Nova York, Random House, 2001.
________.Code, and Other Laws of Cyberspace. Nova York, Basic Books, 1999.
Lovell, Jim e Jeffrey Kluger. Lost Moon: The Perilous Voyage of Apollo 13. Boston, Houghton Mifflin, 1994.
Lyell, Charles, Sir. Principles of Geology: Being an Inquiry How Far the Former Changes of the Earth’s Surface Are
Referable to Causes Now in Operation. Londres, J. Murray, 1835.
Maclaurin, W. Rupert. “The Process of Technological Innovation: The Launching of a New Scientific Industry”, American
Economic Review, vol.40, n.1, 1950, p.90-112.
MacLeod, Christine e Alessandro Nuvolari. “‘The Ingenious Crowd’: A Critical Prosopography of British Inventors, 1650-1850”,
Journal of Economic History, vol.5, 2005, p.66-85.
Man, John. Gutenberg: How One Man Remade the World with Words. Nova York, John Wiley & Sons, 2002.
Margulis, Lynn e Dorion Sagan. Microcosmos: Four Billion Years of Evolution from Our Microbial Ancestors. Berkeley,
University of California Press, 1997. [Ed.bras.: Microcosmos: quatro bilhões de anos de evolução microbiana. São
Paulo, Cultrix, 2004.]
Mason, John. A Treatise on Self Knowledge: Showing the Nature and Benefit of That Important Science, and the Way to
Attain It. Boston, J. Loring, 1833.
McKeen, William. “The Endangered Joy of Serendipity”, St. Petersburg [Flórida] Times, 26 de março de 2006.
Meyer, Peter B. “Episodes of Collective Invention”, U.S. Bureau of Labor Statistics Working Paper WP-368, 2003.
Miller, Stanley L. “A Production of Amino Acids Under Possible Primitive Earth Conditions”, Journal of NIH Research, vol.5,

________. “Production of Some Organic Compounds Under Possible Primitive Earth Conditions”, Journal of the American
Chemical Society, vol.77, n.9, 1955, p.2351-61.
Mills, L. Scott, Michael E. Soulé e Daniel F. Doak. “The Keystone-Species Concept in Ecology and Conservation”, BioScience,
vol.43, n.4, 1993, p.219-24.
Moretti, Franco. Graphs, Maps, Trees: Abstract Models for a Literary History. Nova York, Verso, 2005.
________.Atlas of the European Novel, 1800-1900. Nova York, Verso, 1998.
________.The Way of the World: The Bildungsroman in European Culture. Trad. de Albert Sbragia. Londres, Verso, 1987.
________. Signs Taken for Wonders: Essays in the Sociology of Literary Forms. Nova York, Verso, 1983. [Ed.bras.:
Signos e estilos da modernidade: ensaios sobre a sociologia das formas literárias. Rio de Janeiro, Civilização
Brasileira, 2007.]
Mumford, Lewis. The City in History: Its Origins, Its Transformations and Its Prospects. Nova York, Harcourt, Brace,
Jovanovich, 1961. [Ed.bras.: A cidade na história: suas origens, transformações e perspectivas. São Paulo, Martins
Fontes, 5a ed., 2008.]
National Commission on Terrorist Attacks Upon the United States. The 9/11 Commission Report: Final Report of the
National Commission on Terrorist Attacks Upon the United States. Nova York, W. W. Norton, 2004.
Nemeth, Charlan Jeanne. “Dissent as Driving Cognition, Attitudes, and Judgments”, Social Cognition, vol.13, n.3, 1995, p.273-

Nistad, B.A., Wolfgang Stroebe, Hein F.M. Lodewijkx. “The Illusion of Group Productivity: A Reduction of Failures
Explanation”, European Journal of Social Psychology, vol.36, n.1, janeiro/fevereiro de 2006, p.31-48.
________. “Differential Contributions of Majority and Minority Influence”, Psychological Review, vol.93, n.1, 1986, 23-32.
Ogburn, William F. e Dorothy Thomas. “Are Inventions Inevitable? A Note on Social Evolution”, Political Science Quarterly,
vol.37, n.1, 1922, p.83-98.
Ogle, Richard. Smart World: Breakthrough Creativity and the New Science of Ideas. Boston, Harvard Business School
Press, 2007.
Oldenburg, Ray. The Great Good Place: Cafés, Coffee Shops, Community Centers, Beauty Parlors, General Stores, Bars,
Hangouts, and How They Get You Through the Day. Nova York, Marlowe, 1997.
O’Reilly, Tim. “Gov 2.0: The Promise of Innovation”, Forbes, 10 de agosto de 2009.

http://www.forbes.com/2009/08/10/government-internet-software-technologybreakthroughs-oreilly.html.
Osborn, Alex Faickney. Applied Imagination: Principles and Procedures of Creative Problem Solving. Nova York, Scribner,

[Ed.bras.: O poder criador da mente: princípios e processos do pensamento criador e do brainstorming. São
Paulo, Ibrasa, 1965.]
Paine, R.T. “Conversation on Refining the Concept of Keystone Species”, Conservation Biology, vol.9, n.4, 1995, p.962-64.
Palermo, David Stuart e James J. Jenkins. Word Association Norms: Grade School Through College. Mineápolis, University
of Minnesota Press, 1964.
Pauhus, P.B., M.T. Dzindolet, G. Poletes, e L.M. Camacho. “Perception of Performance in Group Brainstorming: The Illusion of
Group Productivity”, Personality and Social Psychology Bulletin, vol.19, n.1, 1993, p.78.
Paulus, Paul B. e Bernard Arjan Nijstad. Group Creativity: Innovation Through Collaboration. Nova York, Oxford
University Press, 2003.
Poincaré, Henri e George Bruce Halsted. The Foundations of Science; Science and Hypothesis; the Value of Science;
Science and Method. Nova York, Science Press, 1921.
Powell, Walter W. e Stine Grodal. “Networks of Innovators”, Handbook of Innovation, 2005, p.1009-31.
Prestero, Timothy. “Better by Design: How Empathy Can Lead to More Successful Technologies and Services for the Poor
(Discussion of Design Case Narratives: Rickshaw Bank, Solar-Powered Tuki, FGN Pump)”, Innovations: Technology,
Governance, Globalization, vol.5, n.1, 2010, p.79-93.
Priestley, Joseph. Experiments and Observations on Different Kinds of Air and Other Branches of Natural Philosophy,
Connected with the Subject...: Being the Former Six Volumes Abridged and Methodized, with Many Additions.
Birmingham, UK, Thomas Pearson, 1790.
Prigogine, Ilya e Gregoire Nicolis. Exploring Complexity. Nova York, W. H. Freeman, 1989.
Rheingold, Howard. Tools for Thought: The History and Future of Mind-Expanding Technology. Cambridge, Mass., MIT
Press, 2000.
Ridley, Matt. The Red Queen: Sex and the Evolution of Human Nature. Nova York, HarperPerennial, 2003.
________. Genome: The Autobiography of a Species in 23 Chapters. Nova York, Harper-Collins, 1999. [Ed.bras.:
Genoma: autobiografia de uma espécie em 23 capítulos. Rio de Janeiro, Record, 2001.]
Roach, John. “Rich Coral Reefs in Nutrient-Poor Water: Paradox Explained?” National Geographic, 7 de novembro de 2001.
http://news.nationalgeographic.com/news/2001/11/1107_keyholecoral.html.
Robson, David. “Disorderly Genius”, New Scientist, 29 de junho de 2009, p.34-37.
Rogers, Everett M. Diffusion of Innovations. Nova York, Free Press, 1983.
Rosenberg, Susan M., e P. J. Hastings. “Microbiology and Evolution: Modulating Mutation Rates in the Wild”, Science
Signaling, vol.300, n.5624, 2003, p.1382.
Ruef, Martin. “Strong Ties, Weak Ties and Islands: Structural and Cultural Predictors of Organizational Innovation”, Industrial
and Corporate Change, vol.11, n.3, 2002, p.427.
Sawyer, R. Keith. Explaining Creativity: The Science of Human Innovation. Nova York, Oxford University Press, 2006.
Schofield, Robert E. (org.). A Scientific Autobiography of Joseph Priestley (1733-1804): Selected Scientific
Correspondence. Cambridge, Mass., MIT Press, 1966.
Schopf, J. William. Life’s Origin: The Beginnings of Biological Evolution. Berkeley, University of California Press, 2002.
Schulz, Kathryn. Being Wrong: Adventures in the Margin of Error. Nova York, Harper Collins, 2010.
Shapin, Steven. The Scientific Revolution. Chicago, University of Chicago Press, 1996.
Shapin, Steven e Simon Schaffer. Leviathan and the Air-Pump: Hobbes, Boyle, and the Experimental Life. Princeton,
Princeton University Press, 1985.
Shirky, Clay. Here Comes Everybody: The Power of Organizing Without Organizations. Nova York, Penguin Press, 2008.
Simonton, Dean Keith. Creativity in Science: Chance, Logic, Genius, and Zeitgeist. Cambridge, UK, Cambridge University
Press, 2004.
________. Origins of Genius: Darwinian Perspectives on Creativity. Nova York, Oxford University Press, 1999. [Ed.bras.:
A origem do gênio: perspectivas darwinianas sobre a criatividade. Rio de Janeiro, Record, 2002.]
________.Greatness: Who Makes History and Why. Nova York, Guilford, 1994.
________.Genius, Creativity, and Leadership: Historiometric Inquiries. Cambridge, Mass., Harvard University Press,
Standage, Tom. A History of the World in Six Glasses. Nova York, Walker, 2005. [Ed. bras.: História do mundo em 6 copos.
Rio de Janeiro, Zahar, 2005.]
Sternberg, Robert J. Handbook of Creativity. Cambridge, UK, Cambridge University Press, 1999.
Sunstein, Cass R. Going to Extremes: How Like Minds Unite and Divide. Oxford, UK, Oxford University Press, 2009.

Surowiecki, James. The Wisdom of Crowds. Nova York, Anchor, 2005. [Ed.bras.: A sabedoria das multidões. Rio de Janeiro,
Record, 2006.]
Swade, Doron e Charles Babbage. The Difference Engine: Charles Babbage and the Quest to Build the First Computer.
Nova York, Viking, 2001.
Tapscott, Don, e Anthony D. Williams. Wikinomics: How Mass Collaboration Changes Everything. Nova York, Portfolio,

[Ed.bras.: Wikinomics: como a colaboração em massa pode mudar o seu negócio. Rio de Janeiro, Nova Fronteira,
2007.]
Thaler, Richard H. e Cass R. Sunstein. Nudge: Improving Decisions About Health, Wealth, and Happiness. Nova York,
Penguin Books, 2009. [Ed.bras.: Nudge: o empurrão para a escolha certa. Rio de Janeiro, Campus, 2008.]
Thatcher, Robert W., D. M. North e C. J. Biver. “Intelligence and EEG Phase Reset: A Two Compartmental Model of Phase
Shift and Lock”, NeuroImage, vol.42, n.4, 2008. p.1639-53.
Urbina, Ian. “Growing Pains for a Deep-Sea Home Built of Subway Cars”. New York Times, 8 de abril de 2008.
http://www.nytimes.com/2008/04/08/us/08reef.html.
Valenstein, Elliot S. The War of the Soups and the Sparks: The Discovery of Neurotransmitters and the Dispute over How
Nerves Communicate. Nova York, Columbia University Press, 2005.
Vinten-Johansen, Peter et al. Cholera, Chloroform, and the Science of Medicine: A Life of John Snow. Nova York, Oxford
University Press, 2003.
Wagner, Ullrich, Steffen Gais, Hilde Haider, Rolf Verleger e Jan Born. “Sleep Inspires Insight”, Nature, vol.427, n.6972, 2004,
p.352-55.
Waldrop, Mitchell M. Complexity: The Emerging Science at the Edge of Order and Chaos. Nova York, Simon and Schuster,
Weinbaum, Stanley Grauman. A Martian Odyssey and Others. Reading, Pa., Fantasy Press, 1949.
Wilson, Edward O. Consilience: The Unity of Knowledge. Nova York, Knopf, 1998. [Ed. bras.: Consiliência: a unidade do
conhecimento. Rio de Janeiro, Campus, 1999.]
Wright, Robert. NonZero: The Logic of Human Destiny. Nova York, Pantheon Books, 2000. [Ed.bras.: Não zero: a lógica do
destino humano. Rio de Janeiro, Campus, 2001.]
Yu, Peter K. Intellectual Property and Information Wealth: Issues and Practices in the Digital Age. Westport, Conn.,
Praeger Publishers, 2007.
Zimmer, Carl. The Tangled Bank: An Introduction to Evolution. Greenwood Village, Colo., Roberts & Co. Publishers, 2010.
________.”Evolutionary Roots: On the Origin of Life on Earth”, Science, vol.323, n.5911, 2009, p.198.
Zittrain, Jonathan L. The Future of the Internet – And How to Stop It. New Haven, Yale University Press, 2009.

Agradecimentos
Como este é, em parte, um livro sobre o poder criativo das intuições lentas, não deveria
constituir nenhuma surpresa que o tema venha perdurando em minha mente por mais de uma
década, desde que projetei um experimento complexo para meu livro De cabeça aberta, para
escanear meu cérebro num aparelho de ressonância magnética funcional quando ele estava
empenhado em atinar com uma boa ideia. Nos últimos quatro anos, depois que comecei a
trabalhar a sério no projeto, pensei conscientemente neste livro como o volume final de uma
trilogia não oficial que começou com O mapa fantasma e A invenção do ar, ambos dedicados
a ideias que transformaram o mundo e ao ambiente que as tornou possíveis. (Em certo sentido,
este livro pode ser considerado como a teoria latente que se escondia sob aqueles estudos de
caso narrativos mais focalizados.) Por isso, sou grato às muitas reações provocativas e
serendipitosas que recebi de leitores, críticos e ouvintes em relação aos dois livros
anteriores, muitas das quais abriram portas para novas salas que gostei imensamente de
explorar.
Quero estender agradecimentos particulares a várias organizações que me apoiaram
enquanto eu escrevia este livro, a começar por meus colegas no Outside.in, liderados por
Mark Josephson, que toleraram o horário excêntrico de um autor/ diretor executivo com
gentileza e verdadeira amizade. Obrigado à Escola de Jornalismo da Universidade Columbia
por me designar o Hearst New Media Scholar in Residence e me proporcionar um fórum em
que pude falar sobre livros de citações, meus tempos de graduação e o iPad numa única
palestra. Meus agradecimentos ao maravilhoso festival SXSW por me convidar para falar
sobre o ecossistema das notícias na primavera de 2009, quando as ideias para este livro
começavam a se reunir. Meus editores na Time, na Wired, no Wall Street Journal e no New
York Times – em particular Rick Stengel, Alex Star, James Ryerson, Tim O’Brien, Chris
Anderson e Larry Rout – permitiram-me trabalhar com algumas dessas ideias (e frases) em
público e sempre fizeram argutos comentários ao longo do processo. (Meus ex-editores na
Discover, Stephen Petranek e David Grogan, ajudaram-me a cultivar alguns desses temas
quando tive uma coluna na revista alguns anos atrás.)
Como de costume, a equipe da Riverhead me foi de grande ajuda, seja ao acreditar em
minhas ideias em estado embrionário, seja ao me permitir perseguir minhas descobertas
serendipitosas, tanto do Outside.in quanto de Joseph Priestley. Sean McDonald e Geoff Kloske
manifestaram incrível paciência quando minha intuição se revelou ainda mais lenta do que
originalmente previsto, e, quando o livro finalmente começou a ganhar forma, fizeram um
trabalho formidável para transformá-lo num produto acabado. Sou grato também a Matthew
Venzon, Emily Bell, Hal Fessenden, Helen Conford e a meus agentes de palestras no Leigh
Bureau por seu apoio. Minha assistente de pesquisa, Chris Ross, prestou-me enorme ajuda ao
colaborar com nossos mapas da história da inovação. Mais uma vez minha agente, Lydia
Wills, mostrou seu extraordinário talento para estimular as minhas boas ideias e desacreditar
delicadamente as idiotas.
Sou particularmente grato às pessoas que leram partes do manuscrito em rascunho: Brent
Constantz, Charlane Nemeth, Brian Eno, John Wilbanks, e em especial Ray Ozzie, Carl
Zimmer e Scott Berkun, e minha editora favorita, Alexa Robinson. Eles sugeriram muitas
melhorias às ideias contidas neste livro. Os erros que subsistem são de minha inteira
responsabilidade. Cabe a você decidir se eles se provam erros produtivos.
